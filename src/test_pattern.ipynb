{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import train_P as train\n",
    "import dataset as ds\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "import utils\n",
    "import os\n",
    "import conll2brat\n",
    "import glob\n",
    "import codecs\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import evaluate\n",
    "import random\n",
    "import pickle\n",
    "import brat2conll\n",
    "import numpy as np\n",
    "import utils_nlp\n",
    "import distutils.util as distutils_util\n",
    "import configparser\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'pretrained_model_folder':'../model',\n",
    "                      'dataset_text_folder':'../../../ML_EntityData/data/en',\n",
    "                      'character_embedding_dimension':25,\n",
    "                      'character_lstm_hidden_state_dimension':25,\n",
    "                      'check_for_digits_replaced_with_zeros':True,\n",
    "                      'check_for_lowercase':True,\n",
    "                      'debug':False,\n",
    "                      'dropout_rate':0.5,\n",
    "                      'experiment_name':'test',\n",
    "                      'freeze_token_embeddings':False,\n",
    "                      'gradient_clipping_value':5.0,\n",
    "                      'learning_rate':0.005,\n",
    "                      'load_only_pretrained_token_embeddings':False,\n",
    "                      'load_all_pretrained_token_embeddings':False,\n",
    "#                       'main_evaluation_mode':'conll',\n",
    "                      'maximum_number_of_epochs':500,\n",
    "                      'number_of_cpu_threads':8,\n",
    "                      'number_of_gpus':0,\n",
    "                      'optimizer':'sgd',\n",
    "                      'output_folder':'../../../ML_EntityData/output',\n",
    "                      'patience':10,\n",
    "#                       'plot_format':'pdf',\n",
    "                      'reload_character_embeddings':True,\n",
    "                      'reload_character_lstm':True,\n",
    "                      'reload_crf':True,\n",
    "                      'reload_feedforward':True,\n",
    "                      'reload_token_embeddings':True,\n",
    "                      'reload_token_lstm':True,\n",
    "                      'remap_unknown_tokens_to_unk':True,\n",
    "#                       'spacylanguage':'en',\n",
    "                      'tagging_format':'bioes',\n",
    "                      'token_embedding_dimension':100,\n",
    "                      'token_lstm_hidden_state_dimension':100,\n",
    "                      'token_pretrained_embedding_filepath':'../../../ML_EntityData/embedding/en/glove.6B.100d.txt',\n",
    "                      'tokenizer':'spacy',\n",
    "                      'train_model':True,\n",
    "                      'use_character_lstm':True,\n",
    "#                       'use_crf':True,\n",
    "                      'use_pretrained_model':False,\n",
    "                      'verbose':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the validity of BRAT-formatted train set... Done.\n",
      "Checking compatibility between CONLL and BRAT for train_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted valid set... Done.\n",
      "Checking compatibility between CONLL and BRAT for valid_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted test set... Done.\n",
      "Checking compatibility between CONLL and BRAT for test_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Load dataset... done (73.73 seconds)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import utils_data as ds\n",
    "# Load dataset\n",
    "dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters)\n",
    "dataset = ds.DatasetP(verbose=False, debug=False)\n",
    "token_to_vector = dataset.load_dataset(dataset_filepaths, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_characters: Tensor(\"character_embedding/embedded_characters:0\", shape=(?, ?, 25), dtype=float32)\n",
      "embedded_tokens: Tensor(\"token_embedding/embedding_lookup:0\", shape=(?, 100), dtype=float32)\n",
      "token_lstm_input: Tensor(\"concatenate_token_and_character_vectors/token_lstm_input:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop: Tensor(\"dropout/token_lstm_input_drop/mul:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop_expanded: Tensor(\"dropout/token_lstm_input_drop_expanded:0\", shape=(1, ?, 163), dtype=float32)\n",
      "unary_scores_expanded: Tensor(\"crf/unary_scores_expanded:0\", shape=(1, ?, 19), dtype=float32)\n",
      "input_label_indices_flat_batch: Tensor(\"crf/input_label_indices_flat_batch:0\", shape=(1, ?), dtype=int32)\n",
      "sequence_lengths: Tensor(\"crf/sequence_lengths:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from BLSTM_CRF_P import BLSTM_CRF\n",
    "# Create model lstm+crf\n",
    "session_conf = tf.ConfigProto(\n",
    "            intra_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            inter_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            device_count={'CPU': 2, 'GPU': parameters['number_of_gpus']},\n",
    "            allow_soft_placement=True,\n",
    "            # automatically choose an existing and supported device to run the operations in case the specified one doesn't exist\n",
    "            log_device_placement=False\n",
    "        )\n",
    "sess = tf.Session(config=session_conf)\n",
    "\n",
    "with sess.as_default():\n",
    "    # Create model and initialize or load pretrained model\n",
    "    ### Instantiate the model\n",
    "    model = BLSTM_CRF(dataset, token_embedding_dimension=parameters['token_embedding_dimension'],\n",
    "                       character_lstm_hidden_state_dimension=parameters['character_lstm_hidden_state_dimension'],\n",
    "                       token_lstm_hidden_state_dimension=parameters['token_lstm_hidden_state_dimension'],\n",
    "                       character_embedding_dimension=parameters['character_embedding_dimension'],\n",
    "                       gradient_clipping_value=parameters['gradient_clipping_value'],\n",
    "                       learning_rate=parameters['learning_rate'],\n",
    "                       freeze_token_embeddings=parameters['freeze_token_embeddings'],\n",
    "                       optimizer=parameters['optimizer'],\n",
    "                       maximum_number_of_epochs=parameters['maximum_number_of_epochs'])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (0.22 seconds)\n",
      "number_of_token_original_case_found: 14618\n",
      "number_of_token_lowercase_found: 11723\n",
      "number_of_token_digits_replaced_with_zeros_found: 119\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 16\n",
      "number_of_loaded_word_vectors: 26476\n",
      "dataset.vocabulary_size: 28984\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.load_pretrained_token_embeddings(sess, dataset,embedding_filepath=parameters['token_pretrained_embedding_filepath'],\n",
    "                                                       check_lowercase= parameters['check_for_lowercase'],check_digits=parameters['check_for_digits_replaced_with_zeros'],\n",
    "                                                       token_to_vector=token_to_vector)\n",
    "# Initial params_train\n",
    "transition_params_trained = np.random.rand(len(dataset.unique_labels) + 2,len(dataset.unique_labels) + 2)\n",
    "\n",
    "del token_to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "stats_graph_folder, experiment_timestamp = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "        # Initialize and save execution details\n",
    "start_time = time.time()\n",
    "# results = {}\n",
    "# results['epoch'] = {}\n",
    "# results['execution_details'] = {}\n",
    "# results['execution_details']['train_start'] = start_time\n",
    "# results['execution_details']['time_stamp'] = experiment_timestamp\n",
    "# results['execution_details']['early_stop'] = False\n",
    "# results['execution_details']['keyboard_interrupt'] = False\n",
    "# results['execution_details']['num_epochs'] = 0\n",
    "# results['model_options'] = copy.copy(parameters)\n",
    "\n",
    "model_folder = os.path.join(stats_graph_folder, 'model')\n",
    "utils.create_folder_if_not_exists(model_folder)\n",
    "\n",
    "pickle.dump(dataset, open(os.path.join(model_folder, 'dataset.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 0\n",
      "Training completed in 0.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9474    0.9520    0.9497      1041\n",
      "     B-MISC     0.9071    0.9336    0.9202       858\n",
      "      B-ORG     0.9705    0.9412    0.9557      2485\n",
      "      B-PER     0.9657    0.9923    0.9788      4284\n",
      "      E-LOC     0.9457    0.9529    0.9493      1041\n",
      "     E-MISC     0.9106    0.9382    0.9242       858\n",
      "      E-ORG     0.9664    0.9368    0.9514      2485\n",
      "      E-PER     0.9700    0.9965    0.9831      4284\n",
      "      I-LOC     0.8496    0.8276    0.8384       116\n",
      "     I-MISC     0.8947    0.8586    0.8763       297\n",
      "      I-ORG     0.9501    0.9221    0.9359      1219\n",
      "      I-PER     0.8824    0.9836    0.9302       244\n",
      "          O     0.0000    0.0000    0.0000       406\n",
      "      S-LOC     0.9745    0.9831    0.9788      6099\n",
      "     S-MISC     0.9535    0.9384    0.9459      2580\n",
      "      S-ORG     0.9733    0.9494    0.9612      3836\n",
      "      S-PER     0.9401    0.9624    0.9511      2316\n",
      "\n",
      "avg / total     0.9489    0.9515    0.9501     34449\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9057    0.9444    0.9247       234\n",
      "     B-MISC     0.7544    0.8366    0.7934       257\n",
      "      B-ORG     0.8966    0.8289    0.8614       450\n",
      "      B-PER     0.9753    0.9919    0.9835      1234\n",
      "      E-LOC     0.9012    0.9359    0.9182       234\n",
      "     E-MISC     0.7820    0.8794    0.8278       257\n",
      "      E-ORG     0.9091    0.8444    0.8756       450\n",
      "      E-PER     0.9737    0.9895    0.9815      1234\n",
      "      I-LOC     0.8500    0.7391    0.7907        23\n",
      "     I-MISC     0.6333    0.6404    0.6369        89\n",
      "      I-ORG     0.9158    0.8306    0.8711       301\n",
      "      I-PER     0.9286    0.7123    0.8062        73\n",
      "          O     0.0000    0.0000    0.0000       149\n",
      "      S-LOC     0.9613    0.9757    0.9684      1603\n",
      "     S-MISC     0.9340    0.8932    0.9131       665\n",
      "      S-ORG     0.9449    0.9237    0.9342       891\n",
      "      S-PER     0.8832    0.9326    0.9072       608\n",
      "\n",
      "avg / total     0.9136    0.9144    0.9134      8752\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7899    0.8750    0.8303       232\n",
      "     B-MISC     0.5760    0.7062    0.6345       177\n",
      "      B-ORG     0.8454    0.8497    0.8475       579\n",
      "      B-PER     0.9635    0.9954    0.9792      1086\n",
      "      E-LOC     0.7829    0.8707    0.8245       232\n",
      "     E-MISC     0.6019    0.7345    0.6616       177\n",
      "      E-ORG     0.8540    0.8584    0.8562       579\n",
      "      E-PER     0.9608    0.9926    0.9764      1086\n",
      "      I-LOC     0.5161    0.6400    0.5714        25\n",
      "     I-MISC     0.4237    0.6410    0.5102        39\n",
      "      I-ORG     0.7643    0.8359    0.7985       256\n",
      "      I-PER     0.9571    0.9571    0.9571        70\n",
      "          O     0.0000    0.0000    0.0000       369\n",
      "      S-LOC     0.9239    0.9380    0.9309      1436\n",
      "     S-MISC     0.8507    0.8248    0.8375       525\n",
      "      S-ORG     0.9144    0.8882    0.9011      1082\n",
      "      S-PER     0.9093    0.8682    0.8882       531\n",
      "\n",
      "avg / total     0.8471    0.8645    0.8551      8481\n",
      "\n",
      "\n",
      "Starting epoch 1\n",
      "Training completed in 436.54 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9527    0.9481    0.9504      1041\n",
      "     B-MISC     0.9464    0.9266    0.9364       858\n",
      "      B-ORG     0.9571    0.9614    0.9592      2485\n",
      "      B-PER     0.9893    0.9904    0.9899      4284\n",
      "      E-LOC     0.9537    0.9491    0.9514      1041\n",
      "     E-MISC     0.9474    0.9242    0.9357       858\n",
      "      E-ORG     0.9551    0.9594    0.9572      2485\n",
      "      E-PER     0.9914    0.9923    0.9918      4284\n",
      "      I-LOC     0.9247    0.7414    0.8230       116\n",
      "     I-MISC     0.8912    0.8552    0.8729       297\n",
      "      I-ORG     0.9466    0.9311    0.9388      1219\n",
      "      I-PER     0.9547    0.9508    0.9528       244\n",
      "          O     0.0000    0.0000    0.0000       284\n",
      "      S-LOC     0.9742    0.9857    0.9800      6099\n",
      "     S-MISC     0.9611    0.9391    0.9500      2580\n",
      "      S-ORG     0.9772    0.9518    0.9643      3836\n",
      "      S-PER     0.9455    0.9737    0.9594      2316\n",
      "\n",
      "avg / total     0.9603    0.9578    0.9590     34327\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9258    0.9060    0.9158       234\n",
      "     B-MISC     0.7899    0.7899    0.7899       257\n",
      "      B-ORG     0.8658    0.8600    0.8629       450\n",
      "      B-PER     0.9902    0.9870    0.9886      1234\n",
      "      E-LOC     0.9211    0.8974    0.9091       234\n",
      "     E-MISC     0.8077    0.8171    0.8124       257\n",
      "      E-ORG     0.8795    0.8756    0.8775       450\n",
      "      E-PER     0.9886    0.9846    0.9866      1234\n",
      "      I-LOC     0.8333    0.6522    0.7317        23\n",
      "     I-MISC     0.6944    0.5618    0.6211        89\n",
      "      I-ORG     0.9161    0.8339    0.8730       301\n",
      "      I-PER     0.9630    0.7123    0.8189        73\n",
      "          O     0.0000    0.0000    0.0000       103\n",
      "      S-LOC     0.9625    0.9763    0.9693      1603\n",
      "     S-MISC     0.9317    0.9023    0.9167       665\n",
      "      S-ORG     0.9463    0.9304    0.9383       891\n",
      "      S-PER     0.8942    0.9309    0.9122       608\n",
      "\n",
      "avg / total     0.9242    0.9163    0.9198      8706\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8008    0.8664    0.8323       232\n",
      "     B-MISC     0.6131    0.6893    0.6489       177\n",
      "      B-ORG     0.8436    0.8480    0.8458       579\n",
      "      B-PER     0.9800    0.9908    0.9853      1086\n",
      "      E-LOC     0.7976    0.8664    0.8306       232\n",
      "     E-MISC     0.6465    0.7232    0.6827       177\n",
      "      E-ORG     0.8537    0.8566    0.8552       579\n",
      "      E-PER     0.9781    0.9890    0.9835      1086\n",
      "      I-LOC     0.4286    0.4800    0.4528        25\n",
      "     I-MISC     0.4717    0.6410    0.5435        39\n",
      "      I-ORG     0.7687    0.8438    0.8045       256\n",
      "      I-PER     0.9710    0.9571    0.9640        70\n",
      "          O     0.0000    0.0000    0.0000       315\n",
      "      S-LOC     0.9226    0.9380    0.9302      1436\n",
      "     S-MISC     0.8718    0.8419    0.8566       525\n",
      "      S-ORG     0.9166    0.8937    0.9050      1082\n",
      "      S-PER     0.9082    0.8757    0.8917       531\n",
      "\n",
      "avg / total     0.8607    0.8698    0.8649      8427\n",
      "\n",
      "\n",
      "Starting epoch 2\n",
      "Training completed in 434.57 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9454    0.9645    0.9548      1041\n",
      "     B-MISC     0.9401    0.9149    0.9273       858\n",
      "      B-ORG     0.9651    0.9565    0.9608      2485\n",
      "      B-PER     0.9904    0.9907    0.9905      4284\n",
      "      E-LOC     0.9481    0.9645    0.9562      1041\n",
      "     E-MISC     0.9522    0.9277    0.9398       858\n",
      "      E-ORG     0.9659    0.9565    0.9612      2485\n",
      "      E-PER     0.9925    0.9925    0.9925      4284\n",
      "      I-LOC     0.9412    0.8276    0.8807       116\n",
      "     I-MISC     0.9395    0.7845    0.8550       297\n",
      "      I-ORG     0.9401    0.9532    0.9466      1219\n",
      "      I-PER     0.9476    0.9631    0.9553       244\n",
      "          O     0.0000    0.0000    0.0000       207\n",
      "      S-LOC     0.9676    0.9857    0.9766      6099\n",
      "     S-MISC     0.9709    0.9310    0.9505      2580\n",
      "      S-ORG     0.9846    0.9343    0.9588      3836\n",
      "      S-PER     0.9545    0.9689    0.9616      2316\n",
      "\n",
      "avg / total     0.9649    0.9579    0.9612     34250\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9028    0.9530    0.9272       234\n",
      "     B-MISC     0.7937    0.7782    0.7859       257\n",
      "      B-ORG     0.8715    0.8289    0.8497       450\n",
      "      B-PER     0.9870    0.9878    0.9874      1234\n",
      "      E-LOC     0.9024    0.9487    0.9250       234\n",
      "     E-MISC     0.8300    0.8171    0.8235       257\n",
      "      E-ORG     0.8832    0.8400    0.8610       450\n",
      "      E-PER     0.9854    0.9854    0.9854      1234\n",
      "      I-LOC     0.8095    0.7391    0.7727        23\n",
      "     I-MISC     0.7627    0.5056    0.6081        89\n",
      "      I-ORG     0.8826    0.8239    0.8522       301\n",
      "      I-PER     0.9630    0.7123    0.8189        73\n",
      "          O     0.0000    0.0000    0.0000       104\n",
      "      S-LOC     0.9538    0.9794    0.9665      1603\n",
      "     S-MISC     0.9336    0.8887    0.9106       665\n",
      "      S-ORG     0.9458    0.9001    0.9224       891\n",
      "      S-PER     0.8808    0.9359    0.9075       608\n",
      "\n",
      "avg / total     0.9204    0.9113    0.9151      8707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7600    0.9009    0.8245       232\n",
      "     B-MISC     0.6223    0.6610    0.6411       177\n",
      "      B-ORG     0.8536    0.8359    0.8447       579\n",
      "      B-PER     0.9809    0.9908    0.9858      1086\n",
      "      E-LOC     0.7564    0.8966    0.8205       232\n",
      "     E-MISC     0.6508    0.6949    0.6721       177\n",
      "      E-ORG     0.8622    0.8428    0.8524       579\n",
      "      E-PER     0.9799    0.9890    0.9844      1086\n",
      "      I-LOC     0.6000    0.7200    0.6545        25\n",
      "     I-MISC     0.6250    0.5128    0.5634        39\n",
      "      I-ORG     0.7634    0.8320    0.7963       256\n",
      "      I-PER     0.9437    0.9571    0.9504        70\n",
      "          O     0.0000    0.0000    0.0000       282\n",
      "      S-LOC     0.9161    0.9429    0.9293      1436\n",
      "     S-MISC     0.8631    0.8286    0.8455       525\n",
      "      S-ORG     0.9206    0.8678    0.8934      1082\n",
      "      S-PER     0.9173    0.8776    0.8970       531\n",
      "\n",
      "avg / total     0.8640    0.8686    0.8657      8394\n",
      "\n",
      "\n",
      "Starting epoch 3\n",
      "Training completed in 435.05 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9653    0.9616    0.9634      1041\n",
      "     B-MISC     0.9645    0.8869    0.9241       858\n",
      "      B-ORG     0.9437    0.9650    0.9542      2485\n",
      "      B-PER     0.9907    0.9921    0.9914      4284\n",
      "      E-LOC     0.9653    0.9625    0.9639      1041\n",
      "     E-MISC     0.9797    0.8986    0.9374       858\n",
      "      E-ORG     0.9429    0.9642    0.9534      2485\n",
      "      E-PER     0.9923    0.9937    0.9930      4284\n",
      "      I-LOC     0.8870    0.8793    0.8831       116\n",
      "     I-MISC     0.8838    0.8451    0.8640       297\n",
      "      I-ORG     0.8554    0.9754    0.9115      1219\n",
      "      I-PER     0.9781    0.9139    0.9449       244\n",
      "          O     0.0000    0.0000    0.0000       361\n",
      "      S-LOC     0.9798    0.9852    0.9825      6099\n",
      "     S-MISC     0.9456    0.9500    0.9478      2580\n",
      "      S-ORG     0.9820    0.9536    0.9676      3836\n",
      "      S-PER     0.9665    0.9706    0.9685      2316\n",
      "\n",
      "avg / total     0.9571    0.9582    0.9574     34404\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8920    0.9530    0.9215       234\n",
      "     B-MISC     0.8140    0.7665    0.7896       257\n",
      "      B-ORG     0.8484    0.8578    0.8530       450\n",
      "      B-PER     0.9902    0.9870    0.9886      1234\n",
      "      E-LOC     0.8952    0.9487    0.9212       234\n",
      "     E-MISC     0.8477    0.8016    0.8240       257\n",
      "      E-ORG     0.8615    0.8711    0.8663       450\n",
      "      E-PER     0.9878    0.9846    0.9862      1234\n",
      "      I-LOC     0.6786    0.8261    0.7451        23\n",
      "     I-MISC     0.7353    0.5618    0.6369        89\n",
      "      I-ORG     0.8006    0.9070    0.8505       301\n",
      "      I-PER     0.9811    0.7123    0.8254        73\n",
      "          O     0.0000    0.0000    0.0000       147\n",
      "      S-LOC     0.9661    0.9769    0.9715      1603\n",
      "     S-MISC     0.9217    0.9203    0.9210       665\n",
      "      S-ORG     0.9501    0.9192    0.9344       891\n",
      "      S-PER     0.8994    0.9260    0.9125       608\n",
      "\n",
      "avg / total     0.9148    0.9158    0.9147      8750\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8061    0.9138    0.8566       232\n",
      "     B-MISC     0.6374    0.6554    0.6462       177\n",
      "      B-ORG     0.8088    0.8618    0.8344       579\n",
      "      B-PER     0.9835    0.9853    0.9844      1086\n",
      "      E-LOC     0.8023    0.9095    0.8525       232\n",
      "     E-MISC     0.6758    0.6949    0.6852       177\n",
      "      E-ORG     0.8133    0.8653    0.8385       579\n",
      "      E-PER     0.9825    0.9843    0.9834      1086\n",
      "      I-LOC     0.4865    0.7200    0.5806        25\n",
      "     I-MISC     0.5000    0.6410    0.5618        39\n",
      "      I-ORG     0.6676    0.8867    0.7617       256\n",
      "      I-PER     0.9697    0.9143    0.9412        70\n",
      "          O     0.0000    0.0000    0.0000       372\n",
      "      S-LOC     0.9290    0.9380    0.9335      1436\n",
      "     S-MISC     0.8456    0.8552    0.8504       525\n",
      "      S-ORG     0.9195    0.8863    0.9026      1082\n",
      "      S-PER     0.9360    0.8814    0.9079       531\n",
      "\n",
      "avg / total     0.8510    0.8673    0.8582      8484\n",
      "\n",
      "\n",
      "Starting epoch 4\n",
      "Training completed in 432.15 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9587    0.9587    0.9587      1041\n",
      "     B-MISC     0.9524    0.9336    0.9429       858\n",
      "      B-ORG     0.9859    0.9557    0.9706      2485\n",
      "      B-PER     0.9834    0.9946    0.9890      4284\n",
      "      E-LOC     0.9587    0.9597    0.9592      1041\n",
      "     E-MISC     0.9631    0.9441    0.9535       858\n",
      "      E-ORG     0.9817    0.9513    0.9663      2485\n",
      "      E-PER     0.9852    0.9963    0.9907      4284\n",
      "      I-LOC     0.9115    0.8879    0.8996       116\n",
      "     I-MISC     0.8476    0.9360    0.8896       297\n",
      "      I-ORG     0.9706    0.9467    0.9585      1219\n",
      "      I-PER     0.9555    0.9672    0.9613       244\n",
      "          O     0.0000    0.0000    0.0000       239\n",
      "      S-LOC     0.9868    0.9802    0.9835      6099\n",
      "     S-MISC     0.9497    0.9581    0.9539      2580\n",
      "      S-ORG     0.9712    0.9669    0.9690      3836\n",
      "      S-PER     0.9599    0.9711    0.9654      2316\n",
      "\n",
      "avg / total     0.9671    0.9642    0.9656     34282\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9050    0.9359    0.9202       234\n",
      "     B-MISC     0.7717    0.8288    0.7992       257\n",
      "      B-ORG     0.9073    0.8044    0.8528       450\n",
      "      B-PER     0.9815    0.9911    0.9863      1234\n",
      "      E-LOC     0.9008    0.9316    0.9160       234\n",
      "     E-MISC     0.7878    0.8521    0.8187       257\n",
      "      E-ORG     0.9248    0.8200    0.8693       450\n",
      "      E-PER     0.9799    0.9895    0.9847      1234\n",
      "      I-LOC     0.8500    0.7391    0.7907        23\n",
      "     I-MISC     0.6022    0.6292    0.6154        89\n",
      "      I-ORG     0.9176    0.7774    0.8417       301\n",
      "      I-PER     0.9630    0.7123    0.8189        73\n",
      "          O     0.0000    0.0000    0.0000       126\n",
      "      S-LOC     0.9689    0.9707    0.9698      1603\n",
      "     S-MISC     0.9153    0.9098    0.9125       665\n",
      "      S-ORG     0.9181    0.9439    0.9308       891\n",
      "      S-PER     0.9019    0.9227    0.9122       608\n",
      "\n",
      "avg / total     0.9183    0.9126    0.9147      8729\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7753    0.8922    0.8297       232\n",
      "     B-MISC     0.5874    0.6836    0.6319       177\n",
      "      B-ORG     0.8741    0.8273    0.8500       579\n",
      "      B-PER     0.9738    0.9908    0.9822      1086\n",
      "      E-LOC     0.7658    0.8879    0.8224       232\n",
      "     E-MISC     0.6390    0.7401    0.6859       177\n",
      "      E-ORG     0.8850    0.8377    0.8607       579\n",
      "      E-PER     0.9719    0.9890    0.9804      1086\n",
      "      I-LOC     0.4722    0.6800    0.5574        25\n",
      "     I-MISC     0.4265    0.7436    0.5421        39\n",
      "      I-ORG     0.7984    0.8047    0.8016       256\n",
      "      I-PER     0.9571    0.9571    0.9571        70\n",
      "          O     0.0000    0.0000    0.0000       318\n",
      "      S-LOC     0.9383    0.9318    0.9350      1436\n",
      "     S-MISC     0.8439    0.8648    0.8542       525\n",
      "      S-ORG     0.8906    0.9030    0.8967      1082\n",
      "      S-PER     0.9194    0.8814    0.9000       531\n",
      "\n",
      "avg / total     0.8598    0.8701    0.8642      8430\n",
      "\n",
      "\n",
      "Starting epoch 5\n",
      "Training completed in 430.83 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9571    0.9654    0.9613      1041\n",
      "     B-MISC     0.9501    0.9324    0.9412       858\n",
      "      B-ORG     0.9608    0.9654    0.9631      2485\n",
      "      B-PER     0.9923    0.9928    0.9925      4284\n",
      "      E-LOC     0.9562    0.9654    0.9608      1041\n",
      "     E-MISC     0.9643    0.9441    0.9541       858\n",
      "      E-ORG     0.9592    0.9638    0.9615      2485\n",
      "      E-PER     0.9937    0.9942    0.9939      4284\n",
      "      I-LOC     0.9300    0.8017    0.8611       116\n",
      "     I-MISC     0.8874    0.9024    0.8948       297\n",
      "      I-ORG     0.8768    0.9811    0.9261      1219\n",
      "      I-PER     0.9713    0.9713    0.9713       244\n",
      "          O     0.0000    0.0000    0.0000       269\n",
      "      S-LOC     0.9836    0.9834    0.9835      6099\n",
      "     S-MISC     0.9663    0.9434    0.9547      2580\n",
      "      S-ORG     0.9857    0.9536    0.9694      3836\n",
      "      S-PER     0.9677    0.9698    0.9687      2316\n",
      "\n",
      "avg / total     0.9648    0.9634    0.9639     34312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8996    0.9573    0.9275       234\n",
      "     B-MISC     0.8273    0.8016    0.8142       257\n",
      "      B-ORG     0.8614    0.8422    0.8517       450\n",
      "      B-PER     0.9887    0.9887    0.9887      1234\n",
      "      E-LOC     0.8992    0.9530    0.9253       234\n",
      "     E-MISC     0.8440    0.8210    0.8323       257\n",
      "      E-ORG     0.8841    0.8644    0.8742       450\n",
      "      E-PER     0.9862    0.9862    0.9862      1234\n",
      "      I-LOC     0.7826    0.7826    0.7826        23\n",
      "     I-MISC     0.7681    0.5955    0.6709        89\n",
      "      I-ORG     0.8171    0.9203    0.8656       301\n",
      "      I-PER     0.9811    0.7123    0.8254        73\n",
      "          O     0.0000    0.0000    0.0000       137\n",
      "      S-LOC     0.9644    0.9807    0.9725      1603\n",
      "     S-MISC     0.9349    0.9068    0.9206       665\n",
      "      S-ORG     0.9502    0.9214    0.9356       891\n",
      "      S-PER     0.8979    0.9260    0.9117       608\n",
      "\n",
      "avg / total     0.9196    0.9185    0.9185      8740\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7684    0.9009    0.8294       232\n",
      "     B-MISC     0.5700    0.6441    0.6048       177\n",
      "      B-ORG     0.8202    0.8428    0.8313       579\n",
      "      B-PER     0.9808    0.9890    0.9849      1086\n",
      "      E-LOC     0.7619    0.8966    0.8238       232\n",
      "     E-MISC     0.6350    0.7175    0.6737       177\n",
      "      E-ORG     0.8294    0.8480    0.8386       579\n",
      "      E-PER     0.9781    0.9880    0.9831      1086\n",
      "      I-LOC     0.6071    0.6800    0.6415        25\n",
      "     I-MISC     0.3824    0.6667    0.4860        39\n",
      "      I-ORG     0.6867    0.8906    0.7755       256\n",
      "      I-PER     0.9552    0.9143    0.9343        70\n",
      "          O     0.0000    0.0000    0.0000       374\n",
      "      S-LOC     0.9333    0.9352    0.9343      1436\n",
      "     S-MISC     0.8848    0.8343    0.8588       525\n",
      "      S-ORG     0.9132    0.8845    0.8986      1082\n",
      "      S-PER     0.9196    0.8832    0.9011       531\n",
      "\n",
      "avg / total     0.8490    0.8633    0.8551      8486\n",
      "\n",
      "\n",
      "Starting epoch 6\n",
      "Training completed in 429.84 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9315    0.9798    0.9551      1041\n",
      "     B-MISC     0.9605    0.9347    0.9474       858\n",
      "      B-ORG     0.9685    0.9638    0.9661      2485\n",
      "      B-PER     0.9889    0.9946    0.9917      4284\n",
      "      E-LOC     0.9273    0.9798    0.9528      1041\n",
      "     E-MISC     0.9676    0.9406    0.9539       858\n",
      "      E-ORG     0.9692    0.9638    0.9665      2485\n",
      "      E-PER     0.9905    0.9963    0.9934      4284\n",
      "      I-LOC     0.8043    0.9569    0.8740       116\n",
      "     I-MISC     0.9485    0.8687    0.9069       297\n",
      "      I-ORG     0.9262    0.9680    0.9467      1219\n",
      "      I-PER     0.9597    0.9754    0.9675       244\n",
      "          O     0.0000    0.0000    0.0000       284\n",
      "      S-LOC     0.9812    0.9864    0.9838      6099\n",
      "     S-MISC     0.9814    0.9415    0.9610      2580\n",
      "      S-ORG     0.9760    0.9664    0.9712      3836\n",
      "      S-PER     0.9669    0.9711    0.9690      2316\n",
      "\n",
      "avg / total     0.9649    0.9659    0.9653     34327\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8511    0.9530    0.8992       234\n",
      "     B-MISC     0.8219    0.7899    0.8056       257\n",
      "      B-ORG     0.8735    0.8289    0.8506       450\n",
      "      B-PER     0.9839    0.9887    0.9863      1234\n",
      "      E-LOC     0.8533    0.9444    0.8966       234\n",
      "     E-MISC     0.8526    0.8327    0.8425       257\n",
      "      E-ORG     0.8993    0.8533    0.8757       450\n",
      "      E-PER     0.9823    0.9878    0.9851      1234\n",
      "      I-LOC     0.5588    0.8261    0.6667        23\n",
      "     I-MISC     0.7903    0.5506    0.6490        89\n",
      "      I-ORG     0.8380    0.8937    0.8650       301\n",
      "      I-PER     0.9630    0.7123    0.8189        73\n",
      "          O     0.0000    0.0000    0.0000       128\n",
      "      S-LOC     0.9661    0.9769    0.9715      1603\n",
      "     S-MISC     0.9384    0.8932    0.9153       665\n",
      "      S-ORG     0.9333    0.9270    0.9302       891\n",
      "      S-PER     0.8924    0.9408    0.9159       608\n",
      "\n",
      "avg / total     0.9169    0.9167    0.9160      8731\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7517    0.9267    0.8301       232\n",
      "     B-MISC     0.5931    0.6836    0.6352       177\n",
      "      B-ORG     0.8348    0.8377    0.8362       579\n",
      "      B-PER     0.9729    0.9899    0.9813      1086\n",
      "      E-LOC     0.7474    0.9181    0.8240       232\n",
      "     E-MISC     0.6368    0.7232    0.6772       177\n",
      "      E-ORG     0.8399    0.8428    0.8414       579\n",
      "      E-PER     0.9719    0.9890    0.9804      1086\n",
      "      I-LOC     0.4783    0.8800    0.6197        25\n",
      "     I-MISC     0.4717    0.6410    0.5435        39\n",
      "      I-ORG     0.7320    0.8750    0.7972       256\n",
      "      I-PER     0.9437    0.9571    0.9504        70\n",
      "          O     0.0000    0.0000    0.0000       390\n",
      "      S-LOC     0.9378    0.9345    0.9362      1436\n",
      "     S-MISC     0.8864    0.8324    0.8585       525\n",
      "      S-ORG     0.8981    0.9039    0.9010      1082\n",
      "      S-PER     0.9047    0.8757    0.8900       531\n",
      "\n",
      "avg / total     0.8463    0.8656    0.8548      8502\n",
      "\n",
      "\n",
      "Starting epoch 7\n",
      "Training completed in 427.62 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9623    0.9808    0.9715      1041\n",
      "     B-MISC     0.9407    0.9615    0.9510       858\n",
      "      B-ORG     0.9808    0.9662    0.9734      2485\n",
      "      B-PER     0.9925    0.9944    0.9935      4284\n",
      "      E-LOC     0.9595    0.9798    0.9696      1041\n",
      "     E-MISC     0.9418    0.9627    0.9522       858\n",
      "      E-ORG     0.9804    0.9662    0.9732      2485\n",
      "      E-PER     0.9942    0.9960    0.9951      4284\n",
      "      I-LOC     0.8640    0.9310    0.8963       116\n",
      "     I-MISC     0.9189    0.9158    0.9174       297\n",
      "      I-ORG     0.9688    0.9664    0.9676      1219\n",
      "      I-PER     0.9712    0.9672    0.9692       244\n",
      "          O     0.0000    0.0000    0.0000       213\n",
      "      S-LOC     0.9837    0.9867    0.9852      6099\n",
      "     S-MISC     0.9680    0.9605    0.9642      2580\n",
      "      S-ORG     0.9776    0.9677    0.9726      3836\n",
      "      S-PER     0.9828    0.9650    0.9739      2316\n",
      "\n",
      "avg / total     0.9725    0.9709    0.9717     34256\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9102    0.9530    0.9311       234\n",
      "     B-MISC     0.7754    0.8327    0.8030       257\n",
      "      B-ORG     0.9041    0.8378    0.8697       450\n",
      "      B-PER     0.9903    0.9911    0.9907      1234\n",
      "      E-LOC     0.9061    0.9487    0.9269       234\n",
      "     E-MISC     0.8014    0.8638    0.8315       257\n",
      "      E-ORG     0.9211    0.8556    0.8871       450\n",
      "      E-PER     0.9887    0.9887    0.9887      1234\n",
      "      I-LOC     0.7391    0.7391    0.7391        23\n",
      "     I-MISC     0.6842    0.5843    0.6303        89\n",
      "      I-ORG     0.9039    0.8439    0.8729       301\n",
      "      I-PER     0.9636    0.7260    0.8281        73\n",
      "          O     0.0000    0.0000    0.0000       105\n",
      "      S-LOC     0.9607    0.9763    0.9684      1603\n",
      "     S-MISC     0.9233    0.9053    0.9142       665\n",
      "      S-ORG     0.9382    0.9371    0.9377       891\n",
      "      S-PER     0.9209    0.9194    0.9202       608\n",
      "\n",
      "avg / total     0.9260    0.9213    0.9232      8708\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7871    0.8922    0.8364       232\n",
      "     B-MISC     0.6098    0.7062    0.6545       177\n",
      "      B-ORG     0.8581    0.8463    0.8522       579\n",
      "      B-PER     0.9782    0.9926    0.9854      1086\n",
      "      E-LOC     0.7833    0.8879    0.8323       232\n",
      "     E-MISC     0.6341    0.7345    0.6806       177\n",
      "      E-ORG     0.8702    0.8566    0.8634       579\n",
      "      E-PER     0.9764    0.9917    0.9840      1086\n",
      "      I-LOC     0.4706    0.6400    0.5424        25\n",
      "     I-MISC     0.5000    0.6410    0.5618        39\n",
      "      I-ORG     0.7814    0.8516    0.8150       256\n",
      "      I-PER     0.9571    0.9571    0.9571        70\n",
      "          O     0.0000    0.0000    0.0000       310\n",
      "      S-LOC     0.9267    0.9338    0.9303      1436\n",
      "     S-MISC     0.8451    0.8419    0.8435       525\n",
      "      S-ORG     0.8961    0.8928    0.8944      1082\n",
      "      S-PER     0.9558    0.8550    0.9026       531\n",
      "\n",
      "avg / total     0.8618    0.8713    0.8659      8422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting epoch 8\n",
      "Training completed in 425.67 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9824    0.9645    0.9733      1041\n",
      "     B-MISC     0.9168    0.9767    0.9458       858\n",
      "      B-ORG     0.9727    0.9738    0.9733      2485\n",
      "      B-PER     0.9941    0.9911    0.9926      4284\n",
      "      E-LOC     0.9805    0.9654    0.9729      1041\n",
      "     E-MISC     0.9223    0.9825    0.9515       858\n",
      "      E-ORG     0.9715    0.9734    0.9725      2485\n",
      "      E-PER     0.9948    0.9918    0.9933      4284\n",
      "      I-LOC     0.9901    0.8621    0.9217       116\n",
      "     I-MISC     0.8818    0.9798    0.9282       297\n",
      "      I-ORG     0.9772    0.9475    0.9621      1219\n",
      "      I-PER     0.9792    0.9631    0.9711       244\n",
      "          O     0.0000    0.0000    0.0000       266\n",
      "      S-LOC     0.9910    0.9802    0.9856      6099\n",
      "     S-MISC     0.9276    0.9740    0.9503      2580\n",
      "      S-ORG     0.9761    0.9698    0.9729      3836\n",
      "      S-PER     0.9807    0.9676    0.9741      2316\n",
      "\n",
      "avg / total     0.9687    0.9693    0.9688     34309\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9402    0.9402    0.9402       234\n",
      "     B-MISC     0.7441    0.8599    0.7978       257\n",
      "      B-ORG     0.8878    0.8267    0.8562       450\n",
      "      B-PER     0.9911    0.9903    0.9907      1234\n",
      "      E-LOC     0.9356    0.9316    0.9336       234\n",
      "     E-MISC     0.7633    0.8911    0.8223       257\n",
      "      E-ORG     0.9236    0.8600    0.8907       450\n",
      "      E-PER     0.9894    0.9878    0.9886      1234\n",
      "      I-LOC     0.8421    0.6957    0.7619        23\n",
      "     I-MISC     0.6064    0.6404    0.6230        89\n",
      "      I-ORG     0.9101    0.8073    0.8556       301\n",
      "      I-PER     0.9630    0.7123    0.8189        73\n",
      "          O     0.0000    0.0000    0.0000       132\n",
      "      S-LOC     0.9729    0.9638    0.9683      1603\n",
      "     S-MISC     0.8858    0.9218    0.9035       665\n",
      "      S-ORG     0.9247    0.9371    0.9309       891\n",
      "      S-PER     0.9175    0.9326    0.9250       608\n",
      "\n",
      "avg / total     0.9197    0.9177    0.9180      8735\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8361    0.8578    0.8468       232\n",
      "     B-MISC     0.5362    0.7119    0.6117       177\n",
      "      B-ORG     0.8297    0.8497    0.8396       579\n",
      "      B-PER     0.9826    0.9853    0.9839      1086\n",
      "      E-LOC     0.8326    0.8578    0.8450       232\n",
      "     E-MISC     0.5763    0.7684    0.6586       177\n",
      "      E-ORG     0.8412    0.8601    0.8506       579\n",
      "      E-PER     0.9807    0.9834    0.9821      1086\n",
      "      I-LOC     0.6087    0.5600    0.5833        25\n",
      "     I-MISC     0.3824    0.6667    0.4860        39\n",
      "      I-ORG     0.7704    0.8125    0.7909       256\n",
      "      I-PER     0.9559    0.9286    0.9420        70\n",
      "          O     0.0000    0.0000    0.0000       361\n",
      "      S-LOC     0.9508    0.9283    0.9394      1436\n",
      "     S-MISC     0.8088    0.8781    0.8420       525\n",
      "      S-ORG     0.8845    0.9057    0.8950      1082\n",
      "      S-PER     0.9421    0.8588    0.8985       531\n",
      "\n",
      "avg / total     0.8527    0.8652    0.8580      8473\n",
      "\n",
      "\n",
      "Starting epoch 9\n",
      "Training completed in 429.30 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9826    0.9750    0.9788      1041\n",
      "     B-MISC     0.9560    0.9615    0.9587       858\n",
      "      B-ORG     0.9708    0.9783    0.9745      2485\n",
      "      B-PER     0.9925    0.9942    0.9934      4284\n",
      "      E-LOC     0.9835    0.9760    0.9797      1041\n",
      "     E-MISC     0.9629    0.9674    0.9651       858\n",
      "      E-ORG     0.9709    0.9787    0.9747      2485\n",
      "      E-PER     0.9935    0.9951    0.9943      4284\n",
      "      I-LOC     0.9640    0.9224    0.9427       116\n",
      "     I-MISC     0.9492    0.9428    0.9459       297\n",
      "      I-ORG     0.9463    0.9836    0.9646      1219\n",
      "      I-PER     0.9754    0.9754    0.9754       244\n",
      "          O     0.0000    0.0000    0.0000       255\n",
      "      S-LOC     0.9899    0.9851    0.9875      6099\n",
      "     S-MISC     0.9632    0.9647    0.9640      2580\n",
      "      S-ORG     0.9758    0.9758    0.9758      3836\n",
      "      S-PER     0.9725    0.9763    0.9744      2316\n",
      "\n",
      "avg / total     0.9718    0.9737    0.9727     34298\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9241    0.9359    0.9299       234\n",
      "     B-MISC     0.7955    0.8327    0.8137       257\n",
      "      B-ORG     0.8764    0.8511    0.8636       450\n",
      "      B-PER     0.9871    0.9887    0.9879      1234\n",
      "      E-LOC     0.9237    0.9316    0.9277       234\n",
      "     E-MISC     0.8155    0.8599    0.8371       257\n",
      "      E-ORG     0.9064    0.8822    0.8941       450\n",
      "      E-PER     0.9854    0.9862    0.9858      1234\n",
      "      I-LOC     0.7619    0.6957    0.7273        23\n",
      "     I-MISC     0.6923    0.6067    0.6467        89\n",
      "      I-ORG     0.8571    0.8970    0.8766       301\n",
      "      I-PER     0.9630    0.7123    0.8189        73\n",
      "          O     0.0000    0.0000    0.0000       144\n",
      "      S-LOC     0.9726    0.9732    0.9729      1603\n",
      "     S-MISC     0.9129    0.9143    0.9136       665\n",
      "      S-ORG     0.9395    0.9405    0.9400       891\n",
      "      S-PER     0.9073    0.9342    0.9206       608\n",
      "\n",
      "avg / total     0.9197    0.9209    0.9200      8747\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8333    0.8836    0.8577       232\n",
      "     B-MISC     0.5825    0.6780    0.6266       177\n",
      "      B-ORG     0.8308    0.8653    0.8477       579\n",
      "      B-PER     0.9791    0.9917    0.9854      1086\n",
      "      E-LOC     0.8259    0.8793    0.8518       232\n",
      "     E-MISC     0.6341    0.7345    0.6806       177\n",
      "      E-ORG     0.8372    0.8705    0.8535       579\n",
      "      E-PER     0.9773    0.9890    0.9831      1086\n",
      "      I-LOC     0.5000    0.6800    0.5763        25\n",
      "     I-MISC     0.4032    0.6410    0.4950        39\n",
      "      I-ORG     0.7231    0.8672    0.7886       256\n",
      "      I-PER     0.9437    0.9571    0.9504        70\n",
      "          O     0.0000    0.0000    0.0000       378\n",
      "      S-LOC     0.9416    0.9325    0.9370      1436\n",
      "     S-MISC     0.8491    0.8571    0.8531       525\n",
      "      S-ORG     0.8965    0.9048    0.9006      1082\n",
      "      S-PER     0.9249    0.8814    0.9026       531\n",
      "\n",
      "avg / total     0.8515    0.8695    0.8598      8490\n",
      "\n",
      "\n",
      "Starting epoch 10\n",
      "Training completed in 427.51 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9449    0.9875    0.9657      1041\n",
      "     B-MISC     0.9753    0.9219    0.9479       858\n",
      "      B-ORG     0.9699    0.9714    0.9706      2485\n",
      "      B-PER     0.9930    0.9946    0.9938      4284\n",
      "      E-LOC     0.9430    0.9856    0.9638      1041\n",
      "     E-MISC     0.9790    0.9231    0.9502       858\n",
      "      E-ORG     0.9703    0.9718    0.9710      2485\n",
      "      E-PER     0.9939    0.9956    0.9948      4284\n",
      "      I-LOC     0.9322    0.9483    0.9402       116\n",
      "     I-MISC     0.9113    0.8990    0.9051       297\n",
      "      I-ORG     0.9497    0.9762    0.9628      1219\n",
      "      I-PER     0.9524    0.9836    0.9677       244\n",
      "          O     0.0000    0.0000    0.0000       241\n",
      "      S-LOC     0.9816    0.9898    0.9857      6099\n",
      "     S-MISC     0.9815    0.9481    0.9645      2580\n",
      "      S-ORG     0.9786    0.9758    0.9772      3836\n",
      "      S-PER     0.9692    0.9793    0.9742      2316\n",
      "\n",
      "avg / total     0.9702    0.9711    0.9705     34284\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8740    0.9487    0.9098       234\n",
      "     B-MISC     0.8133    0.7626    0.7871       257\n",
      "      B-ORG     0.8530    0.8511    0.8521       450\n",
      "      B-PER     0.9911    0.9878    0.9894      1234\n",
      "      E-LOC     0.8735    0.9444    0.9076       234\n",
      "     E-MISC     0.8436    0.7977    0.8200       257\n",
      "      E-ORG     0.8820    0.8800    0.8810       450\n",
      "      E-PER     0.9902    0.9862    0.9882      1234\n",
      "      I-LOC     0.7727    0.7391    0.7556        23\n",
      "     I-MISC     0.6265    0.5843    0.6047        89\n",
      "      I-ORG     0.8302    0.8937    0.8608       301\n",
      "      I-PER     0.9455    0.7123    0.8125        73\n",
      "          O     0.0000    0.0000    0.0000       145\n",
      "      S-LOC     0.9666    0.9757    0.9711      1603\n",
      "     S-MISC     0.9355    0.8947    0.9147       665\n",
      "      S-ORG     0.9270    0.9405    0.9337       891\n",
      "      S-PER     0.9005    0.9375    0.9186       608\n",
      "\n",
      "avg / total     0.9143    0.9163    0.9149      8748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7431    0.9224    0.8231       232\n",
      "     B-MISC     0.5737    0.6158    0.5940       177\n",
      "      B-ORG     0.8205    0.8446    0.8323       579\n",
      "      B-PER     0.9790    0.9871    0.9830      1086\n",
      "      E-LOC     0.7396    0.9181    0.8192       232\n",
      "     E-MISC     0.6474    0.6949    0.6703       177\n",
      "      E-ORG     0.8286    0.8515    0.8399       579\n",
      "      E-PER     0.9772    0.9853    0.9812      1086\n",
      "      I-LOC     0.5556    0.8000    0.6557        25\n",
      "     I-MISC     0.3521    0.6410    0.4545        39\n",
      "      I-ORG     0.7147    0.8711    0.7852       256\n",
      "      I-PER     0.9420    0.9286    0.9353        70\n",
      "          O     0.0000    0.0000    0.0000       382\n",
      "      S-LOC     0.9321    0.9373    0.9347      1436\n",
      "     S-MISC     0.8923    0.8362    0.8633       525\n",
      "      S-ORG     0.9043    0.8993    0.9018      1082\n",
      "      S-PER     0.9329    0.8908    0.9114       531\n",
      "\n",
      "avg / total     0.8473    0.8650    0.8549      8494\n",
      "\n",
      "\n",
      "Starting epoch 11\n",
      "Training completed in 426.61 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9816    0.9712    0.9763      1041\n",
      "     B-MISC     0.9652    0.9709    0.9680       858\n",
      "      B-ORG     0.9852    0.9666    0.9758      2485\n",
      "      B-PER     0.9914    0.9963    0.9938      4284\n",
      "      E-LOC     0.9806    0.9712    0.9759      1041\n",
      "     E-MISC     0.9687    0.9744    0.9715       858\n",
      "      E-ORG     0.9869    0.9670    0.9768      2485\n",
      "      E-PER     0.9926    0.9974    0.9950      4284\n",
      "      I-LOC     1.0000    0.8362    0.9108       116\n",
      "     I-MISC     0.9757    0.9461    0.9607       297\n",
      "      I-ORG     0.9513    0.9779    0.9644      1219\n",
      "      I-PER     0.9795    0.9795    0.9795       244\n",
      "          O     0.0000    0.0000    0.0000       242\n",
      "      S-LOC     0.9799    0.9910    0.9854      6099\n",
      "     S-MISC     0.9512    0.9736    0.9623      2580\n",
      "      S-ORG     0.9850    0.9739    0.9794      3836\n",
      "      S-PER     0.9733    0.9771    0.9752      2316\n",
      "\n",
      "avg / total     0.9733    0.9742    0.9737     34285\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8975    0.9359    0.9163       234\n",
      "     B-MISC     0.8140    0.8171    0.8155       257\n",
      "      B-ORG     0.9060    0.8356    0.8694       450\n",
      "      B-PER     0.9839    0.9911    0.9875      1234\n",
      "      E-LOC     0.8889    0.9231    0.9057       234\n",
      "     E-MISC     0.8385    0.8482    0.8433       257\n",
      "      E-ORG     0.9253    0.8533    0.8879       450\n",
      "      E-PER     0.9823    0.9887    0.9855      1234\n",
      "      I-LOC     0.7500    0.5217    0.6154        23\n",
      "     I-MISC     0.7879    0.5843    0.6710        89\n",
      "      I-ORG     0.8806    0.9070    0.8936       301\n",
      "      I-PER     0.9630    0.7123    0.8189        73\n",
      "          O     0.0000    0.0000    0.0000       115\n",
      "      S-LOC     0.9630    0.9750    0.9690      1603\n",
      "     S-MISC     0.9167    0.9098    0.9132       665\n",
      "      S-ORG     0.9315    0.9304    0.9309       891\n",
      "      S-PER     0.9036    0.9408    0.9218       608\n",
      "\n",
      "avg / total     0.9232    0.9204    0.9212      8718\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7854    0.8836    0.8316       232\n",
      "     B-MISC     0.6225    0.7175    0.6667       177\n",
      "      B-ORG     0.8718    0.8221    0.8462       579\n",
      "      B-PER     0.9737    0.9890    0.9813      1086\n",
      "      E-LOC     0.7816    0.8793    0.8276       232\n",
      "     E-MISC     0.6422    0.7401    0.6877       177\n",
      "      E-ORG     0.8842    0.8307    0.8566       579\n",
      "      E-PER     0.9719    0.9871    0.9794      1086\n",
      "      I-LOC     0.6800    0.6800    0.6800        25\n",
      "     I-MISC     0.5435    0.6410    0.5882        39\n",
      "      I-ORG     0.7458    0.8594    0.7985       256\n",
      "      I-PER     0.9420    0.9286    0.9353        70\n",
      "          O     0.0000    0.0000    0.0000       318\n",
      "      S-LOC     0.9192    0.9422    0.9305      1436\n",
      "     S-MISC     0.8431    0.8800    0.8611       525\n",
      "      S-ORG     0.9081    0.8946    0.9013      1082\n",
      "      S-PER     0.9214    0.8832    0.9019       531\n",
      "\n",
      "avg / total     0.8596    0.8718    0.8650      8430\n",
      "\n",
      "\n",
      "Starting epoch 12\n",
      "Training completed in 427.31 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9902    0.9741    0.9821      1041\n",
      "     B-MISC     0.9602    0.9569    0.9586       858\n",
      "      B-ORG     0.9649    0.9835    0.9741      2485\n",
      "      B-PER     0.9889    0.9972    0.9930      4284\n",
      "      E-LOC     0.9883    0.9731    0.9806      1041\n",
      "     E-MISC     0.9661    0.9627    0.9644       858\n",
      "      E-ORG     0.9648    0.9831    0.9739      2485\n",
      "      E-PER     0.9898    0.9981    0.9940      4284\n",
      "      I-LOC     0.9821    0.9483    0.9649       116\n",
      "     I-MISC     0.9248    0.9529    0.9386       297\n",
      "      I-ORG     0.9332    0.9861    0.9589      1219\n",
      "      I-PER     0.9758    0.9918    0.9837       244\n",
      "          O     0.0000    0.0000    0.0000       289\n",
      "      S-LOC     0.9940    0.9831    0.9885      6099\n",
      "     S-MISC     0.9787    0.9616    0.9701      2580\n",
      "      S-ORG     0.9738    0.9781    0.9759      3836\n",
      "      S-PER     0.9623    0.9801    0.9711      2316\n",
      "\n",
      "avg / total     0.9700    0.9742    0.9720     34332\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9247    0.9444    0.9345       234\n",
      "     B-MISC     0.8374    0.8016    0.8191       257\n",
      "      B-ORG     0.8527    0.8622    0.8575       450\n",
      "      B-PER     0.9776    0.9919    0.9847      1234\n",
      "      E-LOC     0.9244    0.9402    0.9322       234\n",
      "     E-MISC     0.8629    0.8327    0.8475       257\n",
      "      E-ORG     0.8794    0.8911    0.8852       450\n",
      "      E-PER     0.9760    0.9895    0.9827      1234\n",
      "      I-LOC     0.8000    0.6957    0.7442        23\n",
      "     I-MISC     0.7534    0.6180    0.6790        89\n",
      "      I-ORG     0.8527    0.9037    0.8774       301\n",
      "      I-PER     0.9636    0.7260    0.8281        73\n",
      "          O     0.0000    0.0000    0.0000       140\n",
      "      S-LOC     0.9780    0.9707    0.9743      1603\n",
      "     S-MISC     0.9421    0.9053    0.9233       665\n",
      "      S-ORG     0.9299    0.9383    0.9341       891\n",
      "      S-PER     0.8932    0.9490    0.9203       608\n",
      "\n",
      "avg / total     0.9194    0.9221    0.9204      8743\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8023    0.8922    0.8449       232\n",
      "     B-MISC     0.5529    0.6497    0.5974       177\n",
      "      B-ORG     0.8174    0.8584    0.8374       579\n",
      "      B-PER     0.9676    0.9890    0.9781      1086\n",
      "      E-LOC     0.7954    0.8879    0.8391       232\n",
      "     E-MISC     0.6232    0.7288    0.6719       177\n",
      "      E-ORG     0.8254    0.8653    0.8449       579\n",
      "      E-PER     0.9667    0.9890    0.9777      1086\n",
      "      I-LOC     0.6129    0.7600    0.6786        25\n",
      "     I-MISC     0.3291    0.6667    0.4407        39\n",
      "      I-ORG     0.7106    0.8633    0.7795       256\n",
      "      I-PER     0.9429    0.9429    0.9429        70\n",
      "          O     0.0000    0.0000    0.0000       383\n",
      "      S-LOC     0.9563    0.9304    0.9432      1436\n",
      "     S-MISC     0.8932    0.8286    0.8597       525\n",
      "      S-ORG     0.8997    0.9039    0.9018      1082\n",
      "      S-PER     0.9002    0.8832    0.8916       531\n",
      "\n",
      "avg / total     0.8476    0.8656    0.8556      8495\n",
      "\n",
      "\n",
      "Starting epoch 13\n",
      "Training completed in 426.91 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9828    0.9866    0.9847      1041\n",
      "     B-MISC     0.9514    0.9814    0.9662       858\n",
      "      B-ORG     0.9858    0.9755    0.9806      2485\n",
      "      B-PER     0.9928    0.9965    0.9946      4284\n",
      "      E-LOC     0.9808    0.9837    0.9823      1041\n",
      "     E-MISC     0.9537    0.9837    0.9684       858\n",
      "      E-ORG     0.9854    0.9746    0.9800      2485\n",
      "      E-PER     0.9940    0.9977    0.9958      4284\n",
      "      I-LOC     0.9910    0.9483    0.9692       116\n",
      "     I-MISC     0.9479    0.9798    0.9636       297\n",
      "      I-ORG     0.9699    0.9795    0.9747      1219\n",
      "      I-PER     0.9718    0.9877    0.9797       244\n",
      "          O     0.0000    0.0000    0.0000       204\n",
      "      S-LOC     0.9900    0.9890    0.9895      6099\n",
      "     S-MISC     0.9712    0.9686    0.9699      2580\n",
      "      S-ORG     0.9845    0.9784    0.9814      3836\n",
      "      S-PER     0.9755    0.9780    0.9767      2316\n",
      "\n",
      "avg / total     0.9777    0.9785    0.9781     34247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9061    0.9487    0.9269       234\n",
      "     B-MISC     0.7674    0.8599    0.8110       257\n",
      "      B-ORG     0.8988    0.8289    0.8624       450\n",
      "      B-PER     0.9847    0.9911    0.9879      1234\n",
      "      E-LOC     0.9057    0.9444    0.9247       234\n",
      "     E-MISC     0.7766    0.8794    0.8248       257\n",
      "      E-ORG     0.9159    0.8467    0.8799       450\n",
      "      E-PER     0.9839    0.9895    0.9867      1234\n",
      "      I-LOC     0.6957    0.6957    0.6957        23\n",
      "     I-MISC     0.5714    0.6292    0.5989        89\n",
      "      I-ORG     0.9032    0.8372    0.8690       301\n",
      "      I-PER     0.9464    0.7260    0.8217        73\n",
      "          O     0.0000    0.0000    0.0000       139\n",
      "      S-LOC     0.9690    0.9757    0.9723      1603\n",
      "     S-MISC     0.9416    0.8977    0.9192       665\n",
      "      S-ORG     0.9352    0.9394    0.9373       891\n",
      "      S-PER     0.9116    0.9326    0.9220       608\n",
      "\n",
      "avg / total     0.9199    0.9186    0.9186      8742\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7774    0.8879    0.8290       232\n",
      "     B-MISC     0.5434    0.6723    0.6010       177\n",
      "      B-ORG     0.8417    0.8359    0.8388       579\n",
      "      B-PER     0.9754    0.9871    0.9812      1086\n",
      "      E-LOC     0.7736    0.8836    0.8249       232\n",
      "     E-MISC     0.6009    0.7401    0.6633       177\n",
      "      E-ORG     0.8502    0.8428    0.8465       579\n",
      "      E-PER     0.9745    0.9862    0.9803      1086\n",
      "      I-LOC     0.5455    0.7200    0.6207        25\n",
      "     I-MISC     0.3421    0.6667    0.4522        39\n",
      "      I-ORG     0.7125    0.8711    0.7838       256\n",
      "      I-PER     0.9420    0.9286    0.9353        70\n",
      "          O     0.0000    0.0000    0.0000       370\n",
      "      S-LOC     0.9315    0.9380    0.9348      1436\n",
      "     S-MISC     0.8832    0.8495    0.8660       525\n",
      "      S-ORG     0.9104    0.9020    0.9062      1082\n",
      "      S-PER     0.9394    0.8757    0.9064       531\n",
      "\n",
      "avg / total     0.8512    0.8656    0.8573      8482\n",
      "\n",
      "\n",
      "Starting epoch 14\n",
      "Training completed in 425.74 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9763    0.9904    0.9833      1041\n",
      "     B-MISC     0.9522    0.9755    0.9637       858\n",
      "      B-ORG     0.9718    0.9847    0.9782      2485\n",
      "      B-PER     0.9891    0.9974    0.9933      4284\n",
      "      E-LOC     0.9726    0.9885    0.9805      1041\n",
      "     E-MISC     0.9568    0.9802    0.9683       858\n",
      "      E-ORG     0.9734    0.9859    0.9796      2485\n",
      "      E-PER     0.9900    0.9984    0.9942      4284\n",
      "      I-LOC     0.9194    0.9828    0.9500       116\n",
      "     I-MISC     0.9443    0.9697    0.9568       297\n",
      "      I-ORG     0.9683    0.9770    0.9726      1219\n",
      "      I-PER     0.9680    0.9918    0.9798       244\n",
      "          O     0.0000    0.0000    0.0000       405\n",
      "      S-LOC     0.9845    0.9916    0.9881      6099\n",
      "     S-MISC     0.9837    0.9578    0.9705      2580\n",
      "      S-ORG     0.9528    0.9849    0.9686      3836\n",
      "      S-PER     0.9808    0.9680    0.9744      2316\n",
      "\n",
      "avg / total     0.9653    0.9742    0.9697     34448\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8911    0.9444    0.9170       234\n",
      "     B-MISC     0.7947    0.8132    0.8038       257\n",
      "      B-ORG     0.8562    0.8600    0.8581       450\n",
      "      B-PER     0.9800    0.9927    0.9863      1234\n",
      "      E-LOC     0.8911    0.9444    0.9170       234\n",
      "     E-MISC     0.8175    0.8366    0.8269       257\n",
      "      E-ORG     0.8786    0.8844    0.8815       450\n",
      "      E-PER     0.9792    0.9903    0.9847      1234\n",
      "      I-LOC     0.6800    0.7391    0.7083        23\n",
      "     I-MISC     0.5914    0.6180    0.6044        89\n",
      "      I-ORG     0.8874    0.8904    0.8889       301\n",
      "      I-PER     0.9464    0.7260    0.8217        73\n",
      "          O     0.0000    0.0000    0.0000       177\n",
      "      S-LOC     0.9666    0.9744    0.9705      1603\n",
      "     S-MISC     0.9435    0.9038    0.9232       665\n",
      "      S-ORG     0.9259    0.9394    0.9326       891\n",
      "      S-PER     0.9145    0.9326    0.9235       608\n",
      "\n",
      "avg / total     0.9102    0.9178    0.9138      8780\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7599    0.9138    0.8297       232\n",
      "     B-MISC     0.5392    0.6610    0.5939       177\n",
      "      B-ORG     0.8186    0.8497    0.8339       579\n",
      "      B-PER     0.9702    0.9890    0.9795      1086\n",
      "      E-LOC     0.7536    0.9095    0.8242       232\n",
      "     E-MISC     0.6047    0.7345    0.6633       177\n",
      "      E-ORG     0.8220    0.8532    0.8373       579\n",
      "      E-PER     0.9693    0.9880    0.9786      1086\n",
      "      I-LOC     0.5366    0.8800    0.6667        25\n",
      "     I-MISC     0.3289    0.6410    0.4348        39\n",
      "      I-ORG     0.7205    0.8359    0.7740       256\n",
      "      I-PER     0.9559    0.9286    0.9420        70\n",
      "          O     0.0000    0.0000    0.0000       430\n",
      "      S-LOC     0.9315    0.9380    0.9348      1436\n",
      "     S-MISC     0.8891    0.8248    0.8557       525\n",
      "      S-ORG     0.8888    0.9011    0.8949      1082\n",
      "      S-PER     0.9281    0.8757    0.9012       531\n",
      "\n",
      "avg / total     0.8366    0.8603    0.8472      8542\n",
      "\n",
      "\n",
      "Starting epoch 15\n",
      "Training completed in 427.50 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9645    0.9923    0.9782      1041\n",
      "     B-MISC     0.9708    0.9674    0.9691       858\n",
      "      B-ORG     0.9874    0.9755    0.9814      2485\n",
      "      B-PER     0.9935    0.9972    0.9953      4284\n",
      "      E-LOC     0.9618    0.9923    0.9768      1041\n",
      "     E-MISC     0.9778    0.9744    0.9761       858\n",
      "      E-ORG     0.9870    0.9751    0.9810      2485\n",
      "      E-PER     0.9946    0.9981    0.9964      4284\n",
      "      I-LOC     0.9344    0.9828    0.9580       116\n",
      "     I-MISC     0.9729    0.9663    0.9696       297\n",
      "      I-ORG     0.9834    0.9746    0.9790      1219\n",
      "      I-PER     0.9835    0.9795    0.9815       244\n",
      "          O     0.0000    0.0000    0.0000       133\n",
      "      S-LOC     0.9890    0.9911    0.9901      6099\n",
      "     S-MISC     0.9744    0.9725    0.9734      2580\n",
      "      S-ORG     0.9952    0.9685    0.9816      3836\n",
      "      S-PER     0.9781    0.9823    0.9802      2316\n",
      "\n",
      "avg / total     0.9821    0.9802    0.9811     34176\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8755    0.9615    0.9165       234\n",
      "     B-MISC     0.8106    0.8327    0.8215       257\n",
      "      B-ORG     0.9007    0.8267    0.8621       450\n",
      "      B-PER     0.9839    0.9919    0.9879      1234\n",
      "      E-LOC     0.8750    0.9573    0.9143       234\n",
      "     E-MISC     0.8415    0.8677    0.8544       257\n",
      "      E-ORG     0.9275    0.8533    0.8889       450\n",
      "      E-PER     0.9815    0.9895    0.9855      1234\n",
      "      I-LOC     0.6786    0.8261    0.7451        23\n",
      "     I-MISC     0.7534    0.6180    0.6790        89\n",
      "      I-ORG     0.9123    0.8638    0.8874       301\n",
      "      I-PER     0.9815    0.7260    0.8346        73\n",
      "          O     0.0000    0.0000    0.0000        94\n",
      "      S-LOC     0.9672    0.9738    0.9705      1603\n",
      "     S-MISC     0.9235    0.9083    0.9158       665\n",
      "      S-ORG     0.9504    0.9248    0.9374       891\n",
      "      S-PER     0.9175    0.9326    0.9250       608\n",
      "\n",
      "avg / total     0.9291    0.9233    0.9256      8697\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7483    0.9612    0.8415       232\n",
      "     B-MISC     0.6294    0.7006    0.6631       177\n",
      "      B-ORG     0.8592    0.8325    0.8456       579\n",
      "      B-PER     0.9729    0.9899    0.9813      1086\n",
      "      E-LOC     0.7416    0.9526    0.8340       232\n",
      "     E-MISC     0.6566    0.7345    0.6933       177\n",
      "      E-ORG     0.8681    0.8411    0.8544       579\n",
      "      E-PER     0.9711    0.9890    0.9799      1086\n",
      "      I-LOC     0.4583    0.8800    0.6027        25\n",
      "     I-MISC     0.5102    0.6410    0.5682        39\n",
      "      I-ORG     0.7482    0.8242    0.7844       256\n",
      "      I-PER     0.9565    0.9429    0.9496        70\n",
      "          O     0.0000    0.0000    0.0000       338\n",
      "      S-LOC     0.9414    0.9394    0.9404      1436\n",
      "     S-MISC     0.8561    0.8724    0.8642       525\n",
      "      S-ORG     0.9208    0.8817    0.9008      1082\n",
      "      S-PER     0.9339    0.8776    0.9049       531\n",
      "\n",
      "avg / total     0.8601    0.8718    0.8647      8450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting epoch 16\n",
      "Training completed in 426.44 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9913    0.9798    0.9855      1041\n",
      "     B-MISC     0.9600    0.9802    0.9700       858\n",
      "      B-ORG     0.9886    0.9771    0.9828      2485\n",
      "      B-PER     0.9907    0.9979    0.9943      4284\n",
      "      E-LOC     0.9903    0.9779    0.9841      1041\n",
      "     E-MISC     0.9613    0.9837    0.9724       858\n",
      "      E-ORG     0.9898    0.9783    0.9840      2485\n",
      "      E-PER     0.9914    0.9986    0.9950      4284\n",
      "      I-LOC     0.9910    0.9483    0.9692       116\n",
      "     I-MISC     0.9630    0.9630    0.9630       297\n",
      "      I-ORG     0.9788    0.9828    0.9808      1219\n",
      "      I-PER     0.9796    0.9836    0.9816       244\n",
      "          O     0.0000    0.0000    0.0000       151\n",
      "      S-LOC     0.9957    0.9811    0.9884      6099\n",
      "     S-MISC     0.9807    0.9651    0.9728      2580\n",
      "      S-ORG     0.9737    0.9833    0.9785      3836\n",
      "      S-PER     0.9637    0.9853    0.9744      2316\n",
      "\n",
      "avg / total     0.9803    0.9796    0.9799     34194\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9139    0.9530    0.9331       234\n",
      "     B-MISC     0.7921    0.8599    0.8246       257\n",
      "      B-ORG     0.9084    0.8156    0.8595       450\n",
      "      B-PER     0.9769    0.9919    0.9843      1234\n",
      "      E-LOC     0.9098    0.9487    0.9289       234\n",
      "     E-MISC     0.8149    0.8911    0.8513       257\n",
      "      E-ORG     0.9358    0.8422    0.8865       450\n",
      "      E-PER     0.9760    0.9895    0.9827      1234\n",
      "      I-LOC     0.8000    0.6957    0.7442        23\n",
      "     I-MISC     0.6875    0.6180    0.6509        89\n",
      "      I-ORG     0.9239    0.8472    0.8839       301\n",
      "      I-PER     0.9455    0.7123    0.8125        73\n",
      "          O     0.0000    0.0000    0.0000       109\n",
      "      S-LOC     0.9792    0.9694    0.9743      1603\n",
      "     S-MISC     0.9393    0.9083    0.9235       665\n",
      "      S-ORG     0.9267    0.9360    0.9313       891\n",
      "      S-PER     0.8940    0.9572    0.9245       608\n",
      "\n",
      "avg / total     0.9263    0.9226    0.9237      8712\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7992    0.9095    0.8508       232\n",
      "     B-MISC     0.5714    0.7006    0.6294       177\n",
      "      B-ORG     0.8605    0.8204    0.8400       579\n",
      "      B-PER     0.9618    0.9963    0.9787      1086\n",
      "      E-LOC     0.7895    0.9052    0.8434       232\n",
      "     E-MISC     0.6256    0.7740    0.6919       177\n",
      "      E-ORG     0.8675    0.8256    0.8460       579\n",
      "      E-PER     0.9591    0.9936    0.9760      1086\n",
      "      I-LOC     0.5405    0.8000    0.6452        25\n",
      "     I-MISC     0.4107    0.5897    0.4842        39\n",
      "      I-ORG     0.7794    0.8281    0.8030       256\n",
      "      I-PER     0.9452    0.9857    0.9650        70\n",
      "          O     0.0000    0.0000    0.0000       336\n",
      "      S-LOC     0.9516    0.9311    0.9412      1436\n",
      "     S-MISC     0.8834    0.8229    0.8521       525\n",
      "      S-ORG     0.8913    0.9020    0.8966      1082\n",
      "      S-PER     0.8977    0.8927    0.8952       531\n",
      "\n",
      "avg / total     0.8563    0.8687    0.8616      8448\n",
      "\n",
      "\n",
      "Starting epoch 17\n",
      "Training completed in 429.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9866    0.9875    0.9870      1041\n",
      "     B-MISC     0.9789    0.9732    0.9760       858\n",
      "      B-ORG     0.9819    0.9843    0.9831      2485\n",
      "      B-PER     0.9949    0.9951    0.9950      4284\n",
      "      E-LOC     0.9866    0.9875    0.9870      1041\n",
      "     E-MISC     0.9836    0.9779    0.9807       858\n",
      "      E-ORG     0.9819    0.9839    0.9829      2485\n",
      "      E-PER     0.9956    0.9958    0.9957      4284\n",
      "      I-LOC     0.9913    0.9828    0.9870       116\n",
      "     I-MISC     0.9732    0.9798    0.9765       297\n",
      "      I-ORG     0.9594    0.9885    0.9737      1219\n",
      "      I-PER     0.9916    0.9713    0.9814       244\n",
      "          O     0.0000    0.0000    0.0000       112\n",
      "      S-LOC     0.9945    0.9874    0.9909      6099\n",
      "     S-MISC     0.9869    0.9671    0.9769      2580\n",
      "      S-ORG     0.9923    0.9758    0.9840      3836\n",
      "      S-PER     0.9723    0.9853    0.9788      2316\n",
      "\n",
      "avg / total     0.9847    0.9820    0.9833     34155\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9280    0.9359    0.9319       234\n",
      "     B-MISC     0.8529    0.7899    0.8202       257\n",
      "      B-ORG     0.8433    0.8733    0.8581       450\n",
      "      B-PER     0.9871    0.9887    0.9879      1234\n",
      "      E-LOC     0.9274    0.9274    0.9274       234\n",
      "     E-MISC     0.8792    0.8210    0.8491       257\n",
      "      E-ORG     0.8691    0.9000    0.8843       450\n",
      "      E-PER     0.9854    0.9862    0.9858      1234\n",
      "      I-LOC     0.8421    0.6957    0.7619        23\n",
      "     I-MISC     0.8030    0.5955    0.6839        89\n",
      "      I-ORG     0.8527    0.9037    0.8774       301\n",
      "      I-PER     0.9636    0.7260    0.8281        73\n",
      "          O     0.0000    0.0000    0.0000       103\n",
      "      S-LOC     0.9786    0.9694    0.9740      1603\n",
      "     S-MISC     0.9437    0.9068    0.9248       665\n",
      "      S-ORG     0.9443    0.9327    0.9385       891\n",
      "      S-PER     0.9100    0.9474    0.9283       608\n",
      "\n",
      "avg / total     0.9295    0.9238    0.9262      8706\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8150    0.8922    0.8519       232\n",
      "     B-MISC     0.6085    0.6497    0.6284       177\n",
      "      B-ORG     0.8260    0.8774    0.8509       579\n",
      "      B-PER     0.9808    0.9890    0.9849      1086\n",
      "      E-LOC     0.8110    0.8879    0.8477       232\n",
      "     E-MISC     0.6772    0.7232    0.6995       177\n",
      "      E-ORG     0.8322    0.8826    0.8567       579\n",
      "      E-PER     0.9790    0.9871    0.9830      1086\n",
      "      I-LOC     0.5333    0.6400    0.5818        25\n",
      "     I-MISC     0.4444    0.6154    0.5161        39\n",
      "      I-ORG     0.7267    0.8828    0.7972       256\n",
      "      I-PER     0.9701    0.9286    0.9489        70\n",
      "          O     0.0000    0.0000    0.0000       322\n",
      "      S-LOC     0.9484    0.9352    0.9418      1436\n",
      "     S-MISC     0.8815    0.8362    0.8583       525\n",
      "      S-ORG     0.9171    0.8900    0.9034      1082\n",
      "      S-PER     0.9270    0.8851    0.9056       531\n",
      "\n",
      "avg / total     0.8640    0.8735    0.8681      8434\n",
      "\n",
      "\n",
      "Starting epoch 18\n",
      "Training completed in 427.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9913    0.9894    0.9904      1041\n",
      "     B-MISC     0.9780    0.9825    0.9802       858\n",
      "      B-ORG     0.9844    0.9875    0.9859      2485\n",
      "      B-PER     0.9970    0.9972    0.9971      4284\n",
      "      E-LOC     0.9904    0.9885    0.9894      1041\n",
      "     E-MISC     0.9814    0.9860    0.9837       858\n",
      "      E-ORG     0.9844    0.9875    0.9859      2485\n",
      "      E-PER     0.9970    0.9972    0.9971      4284\n",
      "      I-LOC     0.9829    0.9914    0.9871       116\n",
      "     I-MISC     0.9671    0.9899    0.9784       297\n",
      "      I-ORG     0.9812    0.9836    0.9824      1219\n",
      "      I-PER     0.9759    0.9959    0.9858       244\n",
      "          O     0.0000    0.0000    0.0000       124\n",
      "      S-LOC     0.9878    0.9933    0.9905      6099\n",
      "     S-MISC     0.9835    0.9721    0.9778      2580\n",
      "      S-ORG     0.9925    0.9716    0.9820      3836\n",
      "      S-PER     0.9781    0.9827    0.9804      2316\n",
      "\n",
      "avg / total     0.9848    0.9840    0.9844     34167\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9247    0.9444    0.9345       234\n",
      "     B-MISC     0.8288    0.8288    0.8288       257\n",
      "      B-ORG     0.8782    0.8489    0.8633       450\n",
      "      B-PER     0.9807    0.9878    0.9843      1234\n",
      "      E-LOC     0.9208    0.9444    0.9325       234\n",
      "     E-MISC     0.8571    0.8638    0.8605       257\n",
      "      E-ORG     0.9014    0.8733    0.8871       450\n",
      "      E-PER     0.9807    0.9870    0.9838      1234\n",
      "      I-LOC     0.7391    0.7391    0.7391        23\n",
      "     I-MISC     0.7714    0.6067    0.6792        89\n",
      "      I-ORG     0.9048    0.8837    0.8941       301\n",
      "      I-PER     0.9455    0.7123    0.8125        73\n",
      "          O     0.0000    0.0000    0.0000        91\n",
      "      S-LOC     0.9661    0.9788    0.9724      1603\n",
      "     S-MISC     0.9392    0.9053    0.9219       665\n",
      "      S-ORG     0.9569    0.9226    0.9394       891\n",
      "      S-PER     0.9038    0.9424    0.9227       608\n",
      "\n",
      "avg / total     0.9304    0.9252    0.9274      8694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7932    0.9095    0.8474       232\n",
      "     B-MISC     0.5859    0.6554    0.6187       177\n",
      "      B-ORG     0.8417    0.8446    0.8431       579\n",
      "      B-PER     0.9791    0.9899    0.9844      1086\n",
      "      E-LOC     0.7865    0.9052    0.8417       232\n",
      "     E-MISC     0.6548    0.7288    0.6898       177\n",
      "      E-ORG     0.8552    0.8566    0.8559       579\n",
      "      E-PER     0.9782    0.9899    0.9840      1086\n",
      "      I-LOC     0.5405    0.8000    0.6452        25\n",
      "     I-MISC     0.4032    0.6410    0.4950        39\n",
      "      I-ORG     0.7441    0.8633    0.7993       256\n",
      "      I-PER     0.9565    0.9429    0.9496        70\n",
      "          O     0.0000    0.0000    0.0000       327\n",
      "      S-LOC     0.9273    0.9422    0.9347      1436\n",
      "     S-MISC     0.8797    0.8495    0.8643       525\n",
      "      S-ORG     0.9218    0.8826    0.9018      1082\n",
      "      S-PER     0.9209    0.8776    0.8987       531\n",
      "\n",
      "avg / total     0.8604    0.8713    0.8651      8439\n",
      "\n",
      "\n",
      "Starting epoch 19\n",
      "Training completed in 426.41 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9904    0.9885    0.9894      1041\n",
      "     B-MISC     0.9834    0.9650    0.9741       858\n",
      "      B-ORG     0.9754    0.9911    0.9832      2485\n",
      "      B-PER     0.9958    0.9974    0.9966      4284\n",
      "      E-LOC     0.9904    0.9885    0.9894      1041\n",
      "     E-MISC     0.9893    0.9720    0.9806       858\n",
      "      E-ORG     0.9750    0.9903    0.9826      2485\n",
      "      E-PER     0.9960    0.9977    0.9969      4284\n",
      "      I-LOC     0.9826    0.9741    0.9784       116\n",
      "     I-MISC     0.9762    0.9663    0.9712       297\n",
      "      I-ORG     0.9558    0.9926    0.9738      1219\n",
      "      I-PER     0.9878    0.9918    0.9898       244\n",
      "          O     0.0000    0.0000    0.0000       146\n",
      "      S-LOC     0.9934    0.9913    0.9924      6099\n",
      "     S-MISC     0.9882    0.9717    0.9799      2580\n",
      "      S-ORG     0.9851    0.9833    0.9842      3836\n",
      "      S-PER     0.9848    0.9788    0.9818      2316\n",
      "\n",
      "avg / total     0.9831    0.9838    0.9834     34189\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9561    0.9316    0.9437       234\n",
      "     B-MISC     0.8133    0.7626    0.7871       257\n",
      "      B-ORG     0.8238    0.8933    0.8571       450\n",
      "      B-PER     0.9879    0.9919    0.9899      1234\n",
      "      E-LOC     0.9515    0.9231    0.9371       234\n",
      "     E-MISC     0.8402    0.7977    0.8184       257\n",
      "      E-ORG     0.8525    0.9244    0.8870       450\n",
      "      E-PER     0.9863    0.9895    0.9879      1234\n",
      "      I-LOC     0.8421    0.6957    0.7619        23\n",
      "     I-MISC     0.6533    0.5506    0.5976        89\n",
      "      I-ORG     0.8358    0.9302    0.8805       301\n",
      "      I-PER     0.9636    0.7260    0.8281        73\n",
      "          O     0.0000    0.0000    0.0000       142\n",
      "      S-LOC     0.9738    0.9726    0.9732      1603\n",
      "     S-MISC     0.9401    0.8962    0.9176       665\n",
      "      S-ORG     0.9342    0.9405    0.9374       891\n",
      "      S-PER     0.9184    0.9260    0.9222       608\n",
      "\n",
      "avg / total     0.9192    0.9208    0.9194      8745\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8395    0.8793    0.8589       232\n",
      "     B-MISC     0.5700    0.6441    0.6048       177\n",
      "      B-ORG     0.7963    0.8843    0.8380       579\n",
      "      B-PER     0.9799    0.9899    0.9849      1086\n",
      "      E-LOC     0.8320    0.8750    0.8529       232\n",
      "     E-MISC     0.6400    0.7232    0.6790       177\n",
      "      E-ORG     0.8025    0.8912    0.8445       579\n",
      "      E-PER     0.9781    0.9880    0.9831      1086\n",
      "      I-LOC     0.6538    0.6800    0.6667        25\n",
      "     I-MISC     0.3378    0.6410    0.4425        39\n",
      "      I-ORG     0.6686    0.8906    0.7638       256\n",
      "      I-PER     0.9706    0.9429    0.9565        70\n",
      "          O     0.0000    0.0000    0.0000       408\n",
      "      S-LOC     0.9498    0.9345    0.9421      1436\n",
      "     S-MISC     0.8925    0.8381    0.8644       525\n",
      "      S-ORG     0.8949    0.9048    0.8998      1082\n",
      "      S-PER     0.9504    0.8663    0.9064       531\n",
      "\n",
      "avg / total     0.8484    0.8664    0.8561      8520\n",
      "\n",
      "\n",
      "Starting epoch 20\n",
      "Training completed in 427.18 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9923    0.9914    0.9918      1041\n",
      "     B-MISC     0.9847    0.9767    0.9807       858\n",
      "      B-ORG     0.9891    0.9871    0.9881      2485\n",
      "      B-PER     0.9970    0.9972    0.9971      4284\n",
      "      E-LOC     0.9914    0.9914    0.9914      1041\n",
      "     E-MISC     0.9906    0.9825    0.9865       858\n",
      "      E-ORG     0.9911    0.9887    0.9899      2485\n",
      "      E-PER     0.9974    0.9974    0.9974      4284\n",
      "      I-LOC     0.9913    0.9828    0.9870       116\n",
      "     I-MISC     0.9864    0.9764    0.9814       297\n",
      "      I-ORG     0.9909    0.9852    0.9881      1219\n",
      "      I-PER     0.9878    0.9918    0.9898       244\n",
      "          O     0.0000    0.0000    0.0000        77\n",
      "      S-LOC     0.9925    0.9936    0.9930      6099\n",
      "     S-MISC     0.9886    0.9717    0.9801      2580\n",
      "      S-ORG     0.9905    0.9831    0.9868      3836\n",
      "      S-PER     0.9777    0.9862    0.9819      2316\n",
      "\n",
      "avg / total     0.9891    0.9868    0.9879     34120\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9319    0.9359    0.9339       234\n",
      "     B-MISC     0.8266    0.7977    0.8119       257\n",
      "      B-ORG     0.8668    0.8533    0.8600       450\n",
      "      B-PER     0.9871    0.9903    0.9887      1234\n",
      "      E-LOC     0.9274    0.9274    0.9274       234\n",
      "     E-MISC     0.8675    0.8405    0.8538       257\n",
      "      E-ORG     0.8962    0.8822    0.8891       450\n",
      "      E-PER     0.9854    0.9878    0.9866      1234\n",
      "      I-LOC     0.8333    0.6522    0.7317        23\n",
      "     I-MISC     0.7500    0.5730    0.6497        89\n",
      "      I-ORG     0.8953    0.8804    0.8878       301\n",
      "      I-PER     0.9630    0.7123    0.8189        73\n",
      "          O     0.0000    0.0000    0.0000        94\n",
      "      S-LOC     0.9720    0.9750    0.9735      1603\n",
      "     S-MISC     0.9447    0.8992    0.9214       665\n",
      "      S-ORG     0.9322    0.9416    0.9369       891\n",
      "      S-PER     0.9089    0.9523    0.9301       608\n",
      "\n",
      "avg / total     0.9306    0.9246    0.9272      8697\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7799    0.9009    0.8360       232\n",
      "     B-MISC     0.6296    0.6723    0.6503       177\n",
      "      B-ORG     0.8488    0.8532    0.8510       579\n",
      "      B-PER     0.9826    0.9899    0.9862      1086\n",
      "      E-LOC     0.7761    0.8966    0.8320       232\n",
      "     E-MISC     0.6720    0.7175    0.6940       177\n",
      "      E-ORG     0.8571    0.8601    0.8586       579\n",
      "      E-PER     0.9826    0.9899    0.9862      1086\n",
      "      I-LOC     0.5758    0.7600    0.6552        25\n",
      "     I-MISC     0.6389    0.5897    0.6133        39\n",
      "      I-ORG     0.7622    0.8516    0.8044       256\n",
      "      I-PER     0.9701    0.9286    0.9489        70\n",
      "          O     0.0000    0.0000    0.0000       294\n",
      "      S-LOC     0.9360    0.9373    0.9367      1436\n",
      "     S-MISC     0.8753    0.8286    0.8513       525\n",
      "      S-ORG     0.9057    0.9057    0.9057      1082\n",
      "      S-PER     0.9289    0.8851    0.9065       531\n",
      "\n",
      "avg / total     0.8675    0.8757    0.8711      8406\n",
      "\n",
      "\n",
      "Starting epoch 21\n",
      "Training completed in 426.83 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9932    0.9875    0.9904      1041\n",
      "     B-MISC     0.9803    0.9848    0.9826       858\n",
      "      B-ORG     0.9852    0.9911    0.9882      2485\n",
      "      B-PER     0.9965    0.9981    0.9973      4284\n",
      "      E-LOC     0.9923    0.9875    0.9899      1041\n",
      "     E-MISC     0.9872    0.9918    0.9895       858\n",
      "      E-ORG     0.9864    0.9920    0.9892      2485\n",
      "      E-PER     0.9967    0.9984    0.9976      4284\n",
      "      I-LOC     0.9912    0.9741    0.9826       116\n",
      "     I-MISC     0.9399    1.0000    0.9690       297\n",
      "      I-ORG     0.9774    0.9918    0.9845      1219\n",
      "      I-PER     0.9799    1.0000    0.9899       244\n",
      "          O     0.0000    0.0000    0.0000       126\n",
      "      S-LOC     0.9952    0.9923    0.9938      6099\n",
      "     S-MISC     0.9878    0.9748    0.9813      2580\n",
      "      S-ORG     0.9893    0.9849    0.9871      3836\n",
      "      S-PER     0.9827    0.9832    0.9829      2316\n",
      "\n",
      "avg / total     0.9865    0.9868    0.9866     34169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9250    0.9487    0.9367       234\n",
      "     B-MISC     0.8175    0.8016    0.8094       257\n",
      "      B-ORG     0.8773    0.8578    0.8674       450\n",
      "      B-PER     0.9808    0.9911    0.9859      1234\n",
      "      E-LOC     0.9212    0.9487    0.9347       234\n",
      "     E-MISC     0.8588    0.8521    0.8555       257\n",
      "      E-ORG     0.9048    0.8867    0.8956       450\n",
      "      E-PER     0.9807    0.9887    0.9847      1234\n",
      "      I-LOC     0.7368    0.6087    0.6667        23\n",
      "     I-MISC     0.7105    0.6067    0.6545        89\n",
      "      I-ORG     0.9046    0.9136    0.9091       301\n",
      "      I-PER     0.9464    0.7260    0.8217        73\n",
      "          O     0.0000    0.0000    0.0000        99\n",
      "      S-LOC     0.9756    0.9713    0.9734      1603\n",
      "     S-MISC     0.9390    0.9023    0.9202       665\n",
      "      S-ORG     0.9386    0.9439    0.9412       891\n",
      "      S-PER     0.9223    0.9375    0.9299       608\n",
      "\n",
      "avg / total     0.9299    0.9263    0.9279      8702\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8008    0.9009    0.8479       232\n",
      "     B-MISC     0.5707    0.6384    0.6027       177\n",
      "      B-ORG     0.8528    0.8705    0.8615       579\n",
      "      B-PER     0.9791    0.9917    0.9854      1086\n",
      "      E-LOC     0.7969    0.8966    0.8438       232\n",
      "     E-MISC     0.6465    0.7232    0.6827       177\n",
      "      E-ORG     0.8576    0.8739    0.8657       579\n",
      "      E-PER     0.9773    0.9908    0.9840      1086\n",
      "      I-LOC     0.6333    0.7600    0.6909        25\n",
      "     I-MISC     0.3582    0.6154    0.4528        39\n",
      "      I-ORG     0.7517    0.8633    0.8036       256\n",
      "      I-PER     0.9710    0.9571    0.9640        70\n",
      "          O     0.0000    0.0000    0.0000       320\n",
      "      S-LOC     0.9479    0.9366    0.9422      1436\n",
      "     S-MISC     0.8735    0.8419    0.8574       525\n",
      "      S-ORG     0.9061    0.9094    0.9077      1082\n",
      "      S-PER     0.9472    0.8776    0.9110       531\n",
      "\n",
      "avg / total     0.8651    0.8763    0.8700      8432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_counter = 0  # number of epochs with no improvement on the validation test in terms of F1-score\n",
    "previous_best_valid_f1_score = 0\n",
    "epoch_number = -1\n",
    "\n",
    "while True:\n",
    "\n",
    "    step = 0\n",
    "    epoch_number += 1\n",
    "    print('\\nStarting epoch {0}'.format(epoch_number))\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    if epoch_number != 0:\n",
    "        # Train model: loop over all sequences of training set with shuffling\n",
    "        sequence_numbers = list(range(len(dataset.token_indices['train'])))\n",
    "        random.shuffle(sequence_numbers)\n",
    "        for sequence_number in sequence_numbers:\n",
    "            transition_params_trained = train.train_step(sess, dataset, sequence_number, model, parameters['dropout_rate'])\n",
    "            step += 1\n",
    "            if step % 10 == 0:\n",
    "                print('Training {0:.2f}% done'.format(step / len(sequence_numbers) * 100), end='\\r', flush=True)\n",
    "\n",
    "    epoch_elapsed_training_time = time.time() - epoch_start_time\n",
    "    print('Training completed in {0:.2f} seconds'.format(epoch_elapsed_training_time), flush=True)\n",
    "\n",
    "    y_pred, y_true, output_filepaths = train.predict_labels(sess=sess,model= model,transition_params_trained= transition_params_trained,\n",
    "                                                                         dataset=dataset,epoch_number= epoch_number,\n",
    "                                                                        stats_graph_folder= stats_graph_folder,dataset_filepaths= dataset_filepaths,\n",
    "                                                                        tagging_format= parameters['tagging_format'])\n",
    "\n",
    "       \n",
    "#     if epoch_number % 3 ==0:\n",
    "    model.saver.save(sess, os.path.join(model_folder, 'model_{0:05d}.ckpt'.format(epoch_number%3)))\n",
    "        \n",
    "    if epoch_number > 20 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_count=0\n",
    "def predict(text):\n",
    "    #         if prediction_count == 1:\n",
    "    parameters['dataset_text_folder'] = os.path.join('..', 'data', 'temp')\n",
    "    stats_graph_folder, _ = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "    # Update the deploy folder, file, and dataset\n",
    "    dataset_type = 'deploy'\n",
    "    ### Delete all deployment data\n",
    "    for filepath in glob.glob(os.path.join(parameters['dataset_text_folder'], '{0}*'.format(dataset_type))):\n",
    "        if os.path.isdir(filepath):\n",
    "            shutil.rmtree(filepath)\n",
    "        else:\n",
    "            os.remove(filepath)\n",
    "    ### Create brat folder and file\n",
    "    dataset_brat_deploy_folder = os.path.join(parameters['dataset_text_folder'], dataset_type)\n",
    "    utils.create_folder_if_not_exists(dataset_brat_deploy_folder)\n",
    "    dataset_brat_deploy_filepath = os.path.join(dataset_brat_deploy_folder, 'temp_{0}.txt'.format(\n",
    "        str(prediction_count).zfill(5)))  # self._get_dataset_brat_deploy_filepath(dataset_brat_deploy_folder)\n",
    "    with codecs.open(dataset_brat_deploy_filepath, 'w', 'UTF-8') as f:\n",
    "        f.write(text)\n",
    "    ### Update deploy filepaths\n",
    "    dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters,\n",
    "                                                                           dataset_types=[dataset_type])\n",
    "    dataset_filepaths.update(dataset_filepaths)\n",
    "    dataset_brat_folders.update(dataset_brat_folders)\n",
    "    ### Update the dataset for the new deploy set\n",
    "    dataset.update_dataset(dataset_filepaths, [dataset_type])\n",
    "\n",
    "    # Predict labels and output brat\n",
    "    output_filepaths = {}\n",
    "    prediction_output = train.prediction_step(sess, dataset, dataset_type, model,\n",
    "                                              transition_params_trained, stats_graph_folder,\n",
    "                                              prediction_count, dataset_filepaths, parameters['tagging_format'])\n",
    "    predictions , _, output_filepaths[dataset_type] = prediction_output\n",
    "    \n",
    "    print([dataset.index_to_label[prediction] for prediction in predictions])\n",
    "    conll2brat.output_brat(output_filepaths, dataset_brat_folders, stats_graph_folder, overwrite=True)\n",
    "\n",
    "    # Print and output result\n",
    "    text_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy',\n",
    "                                 os.path.basename(dataset_brat_deploy_filepath))\n",
    "    annotation_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy', '{0}.ann'.format(\n",
    "        utils.get_basename_without_extension(dataset_brat_deploy_filepath)))\n",
    "    text2, entities = brat2conll.get_entities_from_brat(text_filepath, annotation_filepath, verbose=True)\n",
    "    assert (text == text2)\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting deploy set from BRAT to CONLL... Done.\n",
      "Converting CONLL from BIO to BIOES format... Done.\n",
      "Predict labels for the deploy set\n",
      "['O', 'O', 'O', 'O', 'B-PER', 'E-PER']\n",
      "Formatting 000_deploy set from CONLL to BRAT... Done.\n",
      "\n",
      "text:\n",
      "my name is Phạm  Ngoc Linh\n",
      "\n",
      "entity: {'id': 'T1', 'type': 'PER', 'start': 17, 'end': 26, 'text': 'Ngoc Linh'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 26, 'id': 'T1', 'start': 17, 'text': 'Ngoc Linh', 'type': 'PER'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('my name is Phạm  Ngoc Linh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting deploy set from BRAT to CONLL... Done.\n",
      "Converting CONLL from BIO to BIOES format... Done.\n",
      "Predict labels for the deploy set\n",
      "['B-ORG', 'I-ORG', 'E-ORG', 'O', 'B-ORG', 'I-ORG', 'E-ORG', 'O', 'S-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'E-MISC', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'E-PER', 'O', 'O', 'B-PER', 'E-PER', 'O', 'O', 'O', 'B-MISC', 'E-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'E-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'E-ORG', 'O', 'B-LOC', 'E-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'E-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'E-ORG', 'O', 'S-ORG', 'O', 'O', 'O', 'B-MISC', 'E-MISC', 'O', 'S-ORG', 'O', 'S-MISC', 'O', 'O', 'O', 'B-MISC', 'E-MISC', 'O', 'B-ORG', 'I-ORG', 'E-ORG', 'O', 'O', 'B-ORG', 'E-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-MISC', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'E-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'E-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'E-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'E-LOC', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'E-LOC', 'O', 'O', 'O', 'O', 'S-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Formatting 000_deploy set from CONLL to BRAT... Done.\n",
      "\n",
      "text:\n",
      "Hồ Chí Minh (/ˈhoʊ ˈtʃiː ˈmɪn/;[2] Vietnamese: [hò tɕǐ mīɲ] (About this sound listen), Saigon: [hò tɕǐ mɨ̄n] (About this sound listen); Chữ nôm: 胡志明; 19 May 1890 – 2 September 1969), born Nguyễn Sinh Cung,[3][4][5] also known as Nguyễn Tất Thành and Nguyễn Ái Quốc, was a Vietnamese Communist revolutionary leader who was Chairman and First Secretary of the Workers' Party of Vietnam. Hồ was also Prime Minister (1945–55) and President (1945–69) of the Democratic Republic of Vietnam (North Vietnam). He was a key figure in the foundation of the Democratic Republic of Vietnam in 1945, as well as the People's Army of Vietnam (PAVN) and the Việt Cộng (NLF or VC) during the Vietnam War.Hồ Chí Minh led the Việt Minh independence movement from 1941 onward, establishing the Communist-ruled Democratic Republic of Vietnam in 1945 and defeating the French Union in 1954 at the battle of Điện Biên Phủ. He officially stepped down from power in 1965 due to health problems. After the war, Saigon, the former capital of the Republic of Vietnam, was renamed Hồ Chí Minh City.Any description of Ho's life before he came to power in Vietnam is necessarily fraught with ambiguity. He is known to have used at least 50 and perhaps as many as 200 pseudonyms.[6] (Duiker says at least 75.)[7]:582 His place of birth and date of birth are products of academic consensus since neither is known with certainty. \"Official biographies and there are at least four, vary on names, dates, places and other hard facts. Unofficial biographies vary even more widely.\n",
      "\n",
      "entity: {'id': 'T1', 'type': 'ORG', 'start': 0, 'end': 11, 'text': 'Hồ Chí Minh'}\n",
      "entity: {'id': 'T2', 'type': 'ORG', 'start': 13, 'end': 33, 'text': '/ˈhoʊ ˈtʃiː ˈmɪn/;[2'}\n",
      "entity: {'id': 'T3', 'type': 'MISC', 'start': 35, 'end': 45, 'text': 'Vietnamese'}\n",
      "entity: {'id': 'T4', 'type': 'MISC', 'start': 188, 'end': 213, 'text': 'Nguyễn Sinh Cung,[3][4][5'}\n",
      "entity: {'id': 'T5', 'type': 'PER', 'start': 236, 'end': 245, 'text': 'Tất Thành'}\n",
      "entity: {'id': 'T6', 'type': 'PER', 'start': 257, 'end': 264, 'text': 'Ái Quốc'}\n",
      "entity: {'id': 'T7', 'type': 'MISC', 'start': 272, 'end': 292, 'text': 'Vietnamese Communist'}\n",
      "entity: {'id': 'T8', 'type': 'ORG', 'start': 335, 'end': 383, 'text': \"First Secretary of the Workers' Party of Vietnam\"}\n",
      "entity: {'id': 'T9', 'type': 'ORG', 'start': 453, 'end': 483, 'text': 'Democratic Republic of Vietnam'}\n",
      "entity: {'id': 'T10', 'type': 'LOC', 'start': 485, 'end': 498, 'text': 'North Vietnam'}\n",
      "entity: {'id': 'T11', 'type': 'ORG', 'start': 546, 'end': 576, 'text': 'Democratic Republic of Vietnam'}\n",
      "entity: {'id': 'T12', 'type': 'ORG', 'start': 601, 'end': 625, 'text': \"People's Army of Vietnam\"}\n",
      "entity: {'id': 'T13', 'type': 'ORG', 'start': 627, 'end': 631, 'text': 'PAVN'}\n",
      "entity: {'id': 'T14', 'type': 'MISC', 'start': 641, 'end': 650, 'text': 'Việt Cộng'}\n",
      "entity: {'id': 'T15', 'type': 'ORG', 'start': 652, 'end': 655, 'text': 'NLF'}\n",
      "entity: {'id': 'T16', 'type': 'MISC', 'start': 659, 'end': 661, 'text': 'VC'}\n",
      "entity: {'id': 'T17', 'type': 'MISC', 'start': 674, 'end': 685, 'text': 'Vietnam War'}\n",
      "entity: {'id': 'T18', 'type': 'ORG', 'start': 686, 'end': 697, 'text': 'Hồ Chí Minh'}\n",
      "entity: {'id': 'T19', 'type': 'ORG', 'start': 706, 'end': 715, 'text': 'Việt Minh'}\n",
      "entity: {'id': 'T20', 'type': 'MISC', 'start': 773, 'end': 782, 'text': 'Communist'}\n",
      "entity: {'id': 'T21', 'type': 'ORG', 'start': 789, 'end': 819, 'text': 'Democratic Republic of Vietnam'}\n",
      "entity: {'id': 'T22', 'type': 'ORG', 'start': 846, 'end': 858, 'text': 'French Union'}\n",
      "entity: {'id': 'T23', 'type': 'ORG', 'start': 884, 'end': 897, 'text': 'Điện Biên Phủ'}\n",
      "entity: {'id': 'T24', 'type': 'PER', 'start': 984, 'end': 990, 'text': 'Saigon'}\n",
      "entity: {'id': 'T25', 'type': 'LOC', 'start': 1018, 'end': 1037, 'text': 'Republic of Vietnam'}\n",
      "entity: {'id': 'T26', 'type': 'LOC', 'start': 1051, 'end': 1067, 'text': 'Hồ Chí Minh City'}\n",
      "entity: {'id': 'T27', 'type': 'ORG', 'start': 1087, 'end': 1089, 'text': 'Ho'}\n",
      "entity: {'id': 'T28', 'type': 'LOC', 'start': 1124, 'end': 1131, 'text': 'Vietnam'}\n",
      "entity: {'id': 'T29', 'type': 'PER', 'start': 1251, 'end': 1257, 'text': 'Duiker'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 11, 'id': 'T1', 'start': 0, 'text': 'Hồ Chí Minh', 'type': 'ORG'},\n",
       " {'end': 33,\n",
       "  'id': 'T2',\n",
       "  'start': 13,\n",
       "  'text': '/ˈhoʊ ˈtʃiː ˈmɪn/;[2',\n",
       "  'type': 'ORG'},\n",
       " {'end': 45, 'id': 'T3', 'start': 35, 'text': 'Vietnamese', 'type': 'MISC'},\n",
       " {'end': 213,\n",
       "  'id': 'T4',\n",
       "  'start': 188,\n",
       "  'text': 'Nguyễn Sinh Cung,[3][4][5',\n",
       "  'type': 'MISC'},\n",
       " {'end': 245, 'id': 'T5', 'start': 236, 'text': 'Tất Thành', 'type': 'PER'},\n",
       " {'end': 264, 'id': 'T6', 'start': 257, 'text': 'Ái Quốc', 'type': 'PER'},\n",
       " {'end': 292,\n",
       "  'id': 'T7',\n",
       "  'start': 272,\n",
       "  'text': 'Vietnamese Communist',\n",
       "  'type': 'MISC'},\n",
       " {'end': 383,\n",
       "  'id': 'T8',\n",
       "  'start': 335,\n",
       "  'text': \"First Secretary of the Workers' Party of Vietnam\",\n",
       "  'type': 'ORG'},\n",
       " {'end': 483,\n",
       "  'id': 'T9',\n",
       "  'start': 453,\n",
       "  'text': 'Democratic Republic of Vietnam',\n",
       "  'type': 'ORG'},\n",
       " {'end': 498,\n",
       "  'id': 'T10',\n",
       "  'start': 485,\n",
       "  'text': 'North Vietnam',\n",
       "  'type': 'LOC'},\n",
       " {'end': 576,\n",
       "  'id': 'T11',\n",
       "  'start': 546,\n",
       "  'text': 'Democratic Republic of Vietnam',\n",
       "  'type': 'ORG'},\n",
       " {'end': 625,\n",
       "  'id': 'T12',\n",
       "  'start': 601,\n",
       "  'text': \"People's Army of Vietnam\",\n",
       "  'type': 'ORG'},\n",
       " {'end': 631, 'id': 'T13', 'start': 627, 'text': 'PAVN', 'type': 'ORG'},\n",
       " {'end': 650, 'id': 'T14', 'start': 641, 'text': 'Việt Cộng', 'type': 'MISC'},\n",
       " {'end': 655, 'id': 'T15', 'start': 652, 'text': 'NLF', 'type': 'ORG'},\n",
       " {'end': 661, 'id': 'T16', 'start': 659, 'text': 'VC', 'type': 'MISC'},\n",
       " {'end': 685,\n",
       "  'id': 'T17',\n",
       "  'start': 674,\n",
       "  'text': 'Vietnam War',\n",
       "  'type': 'MISC'},\n",
       " {'end': 697, 'id': 'T18', 'start': 686, 'text': 'Hồ Chí Minh', 'type': 'ORG'},\n",
       " {'end': 715, 'id': 'T19', 'start': 706, 'text': 'Việt Minh', 'type': 'ORG'},\n",
       " {'end': 782, 'id': 'T20', 'start': 773, 'text': 'Communist', 'type': 'MISC'},\n",
       " {'end': 819,\n",
       "  'id': 'T21',\n",
       "  'start': 789,\n",
       "  'text': 'Democratic Republic of Vietnam',\n",
       "  'type': 'ORG'},\n",
       " {'end': 858,\n",
       "  'id': 'T22',\n",
       "  'start': 846,\n",
       "  'text': 'French Union',\n",
       "  'type': 'ORG'},\n",
       " {'end': 897,\n",
       "  'id': 'T23',\n",
       "  'start': 884,\n",
       "  'text': 'Điện Biên Phủ',\n",
       "  'type': 'ORG'},\n",
       " {'end': 990, 'id': 'T24', 'start': 984, 'text': 'Saigon', 'type': 'PER'},\n",
       " {'end': 1037,\n",
       "  'id': 'T25',\n",
       "  'start': 1018,\n",
       "  'text': 'Republic of Vietnam',\n",
       "  'type': 'LOC'},\n",
       " {'end': 1067,\n",
       "  'id': 'T26',\n",
       "  'start': 1051,\n",
       "  'text': 'Hồ Chí Minh City',\n",
       "  'type': 'LOC'},\n",
       " {'end': 1089, 'id': 'T27', 'start': 1087, 'text': 'Ho', 'type': 'ORG'},\n",
       " {'end': 1131, 'id': 'T28', 'start': 1124, 'text': 'Vietnam', 'type': 'LOC'},\n",
       " {'end': 1257, 'id': 'T29', 'start': 1251, 'text': 'Duiker', 'type': 'PER'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Hồ Chí Minh (/ˈhoʊ ˈtʃiː ˈmɪn/;[2] Vietnamese: [hò tɕǐ mīɲ] (About this sound listen), Saigon: [hò tɕǐ mɨ̄n] (About this sound listen); Chữ nôm: 胡志明; 19 May 1890 – 2 September 1969), born Nguyễn Sinh Cung,[3][4][5] also known as Nguyễn Tất Thành and Nguyễn Ái Quốc, was a Vietnamese Communist revolutionary leader who was Chairman and First Secretary of the Workers' Party of Vietnam. Hồ was also Prime Minister (1945–55) and President (1945–69) of the Democratic Republic of Vietnam (North Vietnam). He was a key figure in the foundation of the Democratic Republic of Vietnam in 1945, as well as the People's Army of Vietnam (PAVN) and the Việt Cộng (NLF or VC) during the Vietnam War.Hồ Chí Minh led the Việt Minh independence movement from 1941 onward, establishing the Communist-ruled Democratic Republic of Vietnam in 1945 and defeating the French Union in 1954 at the battle of Điện Biên Phủ. He officially stepped down from power in 1965 due to health problems. After the war, Saigon, the former capital of the Republic of Vietnam, was renamed Hồ Chí Minh City.Any description of Ho's life before he came to power in Vietnam is necessarily fraught with ambiguity. He is known to have used at least 50 and perhaps as many as 200 pseudonyms.[6] (Duiker says at least 75.)[7]:582 His place of birth and date of birth are products of academic consensus since neither is known with certainty. \\\"Official biographies and there are at least four, vary on names, dates, places and other hard facts. Unofficial biographies vary even more widely.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
