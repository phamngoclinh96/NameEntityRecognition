{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import train_P as train\n",
    "import dataset as ds\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "import utils\n",
    "import os\n",
    "import conll2brat\n",
    "import glob\n",
    "import codecs\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import evaluate\n",
    "import random\n",
    "import pickle\n",
    "import brat2conll\n",
    "import numpy as np\n",
    "import utils_nlp\n",
    "import distutils.util as distutils_util\n",
    "import configparser\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'pretrained_model_folder':'../model',\n",
    "                      'dataset_text_folder':'../../../ML_EntityData/data/en',\n",
    "                      'character_embedding_dimension':25,\n",
    "                      'character_lstm_hidden_state_dimension':25,\n",
    "                      'check_for_digits_replaced_with_zeros':True,\n",
    "                      'check_for_lowercase':True,\n",
    "                      'debug':False,\n",
    "                      'dropout_rate':0.5,\n",
    "                      'experiment_name':'test',\n",
    "                      'freeze_token_embeddings':False,\n",
    "                      'gradient_clipping_value':5.0,\n",
    "                      'learning_rate':0.005,\n",
    "                      'load_only_pretrained_token_embeddings':False,\n",
    "                      'load_all_pretrained_token_embeddings':False,\n",
    "#                       'main_evaluation_mode':'conll',\n",
    "                      'maximum_number_of_epochs':500,\n",
    "                      'number_of_cpu_threads':8,\n",
    "                      'number_of_gpus':0,\n",
    "                      'optimizer':'sgd',\n",
    "                      'output_folder':'../../../ML_EntityData/output',\n",
    "                      'patience':10,\n",
    "#                       'plot_format':'pdf',\n",
    "                      'reload_character_embeddings':True,\n",
    "                      'reload_character_lstm':True,\n",
    "                      'reload_crf':True,\n",
    "                      'reload_feedforward':True,\n",
    "                      'reload_token_embeddings':True,\n",
    "                      'reload_token_lstm':True,\n",
    "                      'remap_unknown_tokens_to_unk':True,\n",
    "#                       'spacylanguage':'en',\n",
    "                      'tagging_format':'bioes',\n",
    "                      'token_embedding_dimension':100,\n",
    "                      'token_lstm_hidden_state_dimension':100,\n",
    "                      'token_pretrained_embedding_filepath':'../../../ML_EntityData/embedding/en/glove.6B.100d.txt',\n",
    "#                       'tokenizer':'spacy',\n",
    "                      'train_model':True,\n",
    "                      'use_character_lstm':True,\n",
    "#                       'use_crf':True,\n",
    "                      'use_pretrained_model':False,\n",
    "                      'verbose':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the validity of BRAT-formatted train set... Done.\n",
      "Checking compatibility between CONLL and BRAT for train_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted valid set... Done.\n",
      "Checking compatibility between CONLL and BRAT for valid_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted test set... Done.\n",
      "Checking compatibility between CONLL and BRAT for test_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Load dataset... done (57.36 seconds)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import utils_data as ds\n",
    "# Load dataset\n",
    "dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters)\n",
    "dataset = ds.DatasetP(verbose=False, debug=False)\n",
    "token_to_vector = dataset.load_dataset(dataset_filepaths, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_characters: Tensor(\"character_embedding/embedded_characters:0\", shape=(?, ?, 25), dtype=float32)\n",
      "embedded_tokens: Tensor(\"token_embedding/embedding_lookup:0\", shape=(?, 100), dtype=float32)\n",
      "token_lstm_input: Tensor(\"concatenate_token_and_character_vectors/token_lstm_input:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop: Tensor(\"dropout/token_lstm_input_drop/mul:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop_expanded: Tensor(\"dropout/token_lstm_input_drop_expanded:0\", shape=(1, ?, 163), dtype=float32)\n",
      "unary_scores_expanded: Tensor(\"crf/unary_scores_expanded:0\", shape=(1, ?, 19), dtype=float32)\n",
      "input_label_indices_flat_batch: Tensor(\"crf/input_label_indices_flat_batch:0\", shape=(1, ?), dtype=int32)\n",
      "sequence_lengths: Tensor(\"crf/sequence_lengths:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from BLSTM_CRF_P import BLSTM_CRF\n",
    "# Create model lstm+crf\n",
    "session_conf = tf.ConfigProto(\n",
    "            intra_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            inter_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            device_count={'CPU': 2, 'GPU': parameters['number_of_gpus']},\n",
    "            allow_soft_placement=True,\n",
    "            # automatically choose an existing and supported device to run the operations in case the specified one doesn't exist\n",
    "            log_device_placement=False\n",
    "        )\n",
    "sess = tf.Session(config=session_conf)\n",
    "\n",
    "with sess.as_default():\n",
    "    # Create model and initialize or load pretrained model\n",
    "    ### Instantiate the model\n",
    "    model = BLSTM_CRF(dataset, token_embedding_dimension=parameters['token_embedding_dimension'],\n",
    "                       character_lstm_hidden_state_dimension=parameters['character_lstm_hidden_state_dimension'],\n",
    "                       token_lstm_hidden_state_dimension=parameters['token_lstm_hidden_state_dimension'],\n",
    "                       character_embedding_dimension=parameters['character_embedding_dimension'],\n",
    "                       gradient_clipping_value=parameters['gradient_clipping_value'],\n",
    "                       learning_rate=parameters['learning_rate'],\n",
    "                       freeze_token_embeddings=parameters['freeze_token_embeddings'],\n",
    "                       optimizer=parameters['optimizer'],\n",
    "                       maximum_number_of_epochs=parameters['maximum_number_of_epochs'])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (0.22 seconds)\n",
      "number_of_token_original_case_found: 14618\n",
      "number_of_token_lowercase_found: 11723\n",
      "number_of_token_digits_replaced_with_zeros_found: 119\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 16\n",
      "number_of_loaded_word_vectors: 26476\n",
      "dataset.vocabulary_size: 28984\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.load_pretrained_token_embeddings(sess, dataset,embedding_filepath=parameters['token_pretrained_embedding_filepath'],\n",
    "                                                       check_lowercase= parameters['check_for_lowercase'],check_digits=parameters['check_for_digits_replaced_with_zeros'],\n",
    "                                                       token_to_vector=token_to_vector)\n",
    "# Initial params_train\n",
    "transition_params_trained = np.random.rand(len(dataset.unique_labels) + 2,len(dataset.unique_labels) + 2)\n",
    "\n",
    "del token_to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/en/model_00000.ckpt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "transition_params_trained = model.restore_from_pretrained_model(dataset, sess , model_pathfile=('../model/en/model_00000.ckpt'),\n",
    "                                                                                     dataset_pathfile=('../model/en/dataset.pickle'),\n",
    "                                                                                     embedding_filepath= parameters['token_pretrained_embedding_filepath'],\n",
    "                                                                                     character_dimension = parameters['character_embedding_dimension'],\n",
    "                                                                                     token_dimension=parameters['token_embedding_dimension'],token_to_vector=token_to_vector)\n",
    "del token_to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "stats_graph_folder, experiment_timestamp = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "        # Initialize and save execution details\n",
    "start_time = time.time()\n",
    "# results = {}\n",
    "# results['epoch'] = {}\n",
    "# results['execution_details'] = {}\n",
    "# results['execution_details']['train_start'] = start_time\n",
    "# results['execution_details']['time_stamp'] = experiment_timestamp\n",
    "# results['execution_details']['early_stop'] = False\n",
    "# results['execution_details']['keyboard_interrupt'] = False\n",
    "# results['execution_details']['num_epochs'] = 0\n",
    "# results['model_options'] = copy.copy(parameters)\n",
    "\n",
    "model_folder = os.path.join(stats_graph_folder, 'model')\n",
    "utils.create_folder_if_not_exists(model_folder)\n",
    "\n",
    "pickle.dump(dataset, open(os.path.join(model_folder, 'dataset.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 0\n",
      "Training completed in 0.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9839    0.9971    0.9905      1041\n",
      "     B-MISC     0.9584    0.9942    0.9760       858\n",
      "      B-ORG     0.9963    0.9859    0.9911      2485\n",
      "      B-PER     0.9967    0.9979    0.9973      4284\n",
      "      E-LOC     0.9829    0.9962    0.9895      1041\n",
      "     E-MISC     0.9618    0.9977    0.9794       858\n",
      "      E-ORG     0.9972    0.9867    0.9919      2485\n",
      "      E-PER     0.9977    0.9988    0.9983      4284\n",
      "      I-LOC     0.9915    1.0000    0.9957       116\n",
      "     I-MISC     0.9643    1.0000    0.9818       297\n",
      "      I-ORG     0.9870    0.9951    0.9910      1219\n",
      "      I-PER     0.9760    1.0000    0.9879       244\n",
      "          O     0.0000    0.0000    0.0000       130\n",
      "      S-LOC     0.9909    0.9970    0.9940      6099\n",
      "     S-MISC     0.9801    0.9907    0.9854      2580\n",
      "      S-ORG     0.9979    0.9804    0.9891      3836\n",
      "      S-PER     0.9887    0.9866    0.9877      2316\n",
      "\n",
      "avg / total     0.9869    0.9889    0.9878     34173\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9032    0.9573    0.9295       234\n",
      "     B-MISC     0.7698    0.8716    0.8175       257\n",
      "      B-ORG     0.9049    0.8244    0.8628       450\n",
      "      B-PER     0.9903    0.9887    0.9895      1234\n",
      "      E-LOC     0.8988    0.9487    0.9231       234\n",
      "     E-MISC     0.7766    0.8794    0.8248       257\n",
      "      E-ORG     0.9319    0.8511    0.8897       450\n",
      "      E-PER     0.9894    0.9870    0.9882      1234\n",
      "      I-LOC     0.6500    0.5652    0.6047        23\n",
      "     I-MISC     0.6429    0.6067    0.6243        89\n",
      "      I-ORG     0.8915    0.8738    0.8826       301\n",
      "      I-PER     0.9643    0.7397    0.8372        73\n",
      "          O     0.0000    0.0000    0.0000       125\n",
      "      S-LOC     0.9620    0.9794    0.9706      1603\n",
      "     S-MISC     0.9155    0.9128    0.9142       665\n",
      "      S-ORG     0.9517    0.9282    0.9398       891\n",
      "      S-PER     0.9192    0.9359    0.9275       608\n",
      "\n",
      "avg / total     0.9231    0.9217    0.9219      8728\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7690    0.9181    0.8369       232\n",
      "     B-MISC     0.5522    0.7175    0.6241       177\n",
      "      B-ORG     0.8732    0.8446    0.8586       579\n",
      "      B-PER     0.9827    0.9917    0.9872      1086\n",
      "      E-LOC     0.7653    0.9138    0.8330       232\n",
      "     E-MISC     0.5887    0.7684    0.6667       177\n",
      "      E-ORG     0.8801    0.8497    0.8647       579\n",
      "      E-PER     0.9808    0.9899    0.9853      1086\n",
      "      I-LOC     0.5429    0.7600    0.6333        25\n",
      "     I-MISC     0.4815    0.6667    0.5591        39\n",
      "      I-ORG     0.7450    0.8672    0.8014       256\n",
      "      I-PER     0.9710    0.9571    0.9640        70\n",
      "          O     0.0000    0.0000    0.0000       361\n",
      "      S-LOC     0.9193    0.9436    0.9313      1436\n",
      "     S-MISC     0.8467    0.8629    0.8547       525\n",
      "      S-ORG     0.9284    0.8872    0.9074      1082\n",
      "      S-PER     0.9430    0.8719    0.9061       531\n",
      "\n",
      "avg / total     0.8576    0.8717    0.8633      8473\n",
      "\n",
      "\n",
      "Starting epoch 1\n",
      "Training completed in 293.77 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9962    0.9962    0.9962      1041\n",
      "     B-MISC     0.9884    0.9895    0.9889       858\n",
      "      B-ORG     0.9948    0.9960    0.9954      2485\n",
      "      B-PER     0.9974    0.9986    0.9980      4284\n",
      "      E-LOC     0.9952    0.9952    0.9952      1041\n",
      "     E-MISC     0.9930    0.9942    0.9936       858\n",
      "      E-ORG     0.9952    0.9964    0.9958      2485\n",
      "      E-PER     0.9974    0.9986    0.9980      4284\n",
      "      I-LOC     0.9914    0.9914    0.9914       116\n",
      "     I-MISC     0.9834    1.0000    0.9917       297\n",
      "      I-ORG     0.9902    0.9959    0.9930      1219\n",
      "      I-PER     0.9839    1.0000    0.9919       244\n",
      "          O     0.0000    0.0000    0.0000       100\n",
      "      S-LOC     0.9883    0.9966    0.9924      6099\n",
      "     S-MISC     0.9937    0.9837    0.9887      2580\n",
      "      S-ORG     0.9953    0.9901    0.9927      3836\n",
      "      S-PER     0.9870    0.9870    0.9870      2316\n",
      "\n",
      "avg / total     0.9904    0.9915    0.9909     34143\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9250    0.9487    0.9367       234\n",
      "     B-MISC     0.8275    0.8210    0.8242       257\n",
      "      B-ORG     0.8797    0.8778    0.8788       450\n",
      "      B-PER     0.9887    0.9903    0.9895      1234\n",
      "      E-LOC     0.9212    0.9487    0.9347       234\n",
      "     E-MISC     0.8583    0.8482    0.8532       257\n",
      "      E-ORG     0.9067    0.9067    0.9067       450\n",
      "      E-PER     0.9879    0.9887    0.9883      1234\n",
      "      I-LOC     0.7083    0.7391    0.7234        23\n",
      "     I-MISC     0.8065    0.5618    0.6623        89\n",
      "      I-ORG     0.8935    0.9203    0.9067       301\n",
      "      I-PER     0.9464    0.7260    0.8217        73\n",
      "          O     0.0000    0.0000    0.0000       103\n",
      "      S-LOC     0.9655    0.9788    0.9721      1603\n",
      "     S-MISC     0.9359    0.9008    0.9180       665\n",
      "      S-ORG     0.9467    0.9360    0.9413       891\n",
      "      S-PER     0.9267    0.9359    0.9313       608\n",
      "\n",
      "avg / total     0.9317    0.9288    0.9298      8706\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7704    0.8966    0.8287       232\n",
      "     B-MISC     0.6250    0.6780    0.6504       177\n",
      "      B-ORG     0.8317    0.8618    0.8465       579\n",
      "      B-PER     0.9817    0.9890    0.9853      1086\n",
      "      E-LOC     0.7638    0.8922    0.8231       232\n",
      "     E-MISC     0.6806    0.7345    0.7065       177\n",
      "      E-ORG     0.8367    0.8670    0.8516       579\n",
      "      E-PER     0.9808    0.9890    0.9849      1086\n",
      "      I-LOC     0.6452    0.8000    0.7143        25\n",
      "     I-MISC     0.5714    0.6154    0.5926        39\n",
      "      I-ORG     0.7042    0.8555    0.7725       256\n",
      "      I-PER     0.9571    0.9571    0.9571        70\n",
      "          O     0.0000    0.0000    0.0000       342\n",
      "      S-LOC     0.9193    0.9436    0.9313      1436\n",
      "     S-MISC     0.8762    0.8495    0.8627       525\n",
      "      S-ORG     0.9194    0.8956    0.9073      1082\n",
      "      S-PER     0.9450    0.8738    0.9080       531\n",
      "\n",
      "avg / total     0.8572    0.8727    0.8642      8454\n",
      "\n",
      "\n",
      "Starting epoch 2\n",
      "Training completed in 299.75 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9952    1.0000    0.9976      1041\n",
      "     B-MISC     0.9895    0.9907    0.9901       858\n",
      "      B-ORG     0.9968    0.9952    0.9960      2485\n",
      "      B-PER     0.9974    0.9993    0.9984      4284\n",
      "      E-LOC     0.9943    0.9990    0.9966      1041\n",
      "     E-MISC     0.9942    0.9953    0.9948       858\n",
      "      E-ORG     0.9964    0.9948    0.9956      2485\n",
      "      E-PER     0.9972    0.9991    0.9981      4284\n",
      "      I-LOC     0.9915    1.0000    0.9957       116\n",
      "     I-MISC     0.9834    1.0000    0.9917       297\n",
      "      I-ORG     0.9894    0.9959    0.9926      1219\n",
      "      I-PER     0.9879    1.0000    0.9939       244\n",
      "          O     0.0000    0.0000    0.0000        79\n",
      "      S-LOC     0.9918    0.9969    0.9944      6099\n",
      "     S-MISC     0.9953    0.9833    0.9893      2580\n",
      "      S-ORG     0.9955    0.9898    0.9927      3836\n",
      "      S-PER     0.9884    0.9892    0.9888      2316\n",
      "\n",
      "avg / total     0.9920    0.9925    0.9923     34122\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9102    0.9530    0.9311       234\n",
      "     B-MISC     0.8477    0.8016    0.8240       257\n",
      "      B-ORG     0.8770    0.8711    0.8740       450\n",
      "      B-PER     0.9831    0.9887    0.9859      1234\n",
      "      E-LOC     0.9065    0.9530    0.9292       234\n",
      "     E-MISC     0.8848    0.8366    0.8600       257\n",
      "      E-ORG     0.9038    0.8978    0.9008       450\n",
      "      E-PER     0.9847    0.9878    0.9862      1234\n",
      "      I-LOC     0.6296    0.7391    0.6800        23\n",
      "     I-MISC     0.8621    0.5618    0.6803        89\n",
      "      I-ORG     0.8842    0.9136    0.8987       301\n",
      "      I-PER     0.9655    0.7671    0.8550        73\n",
      "          O     0.0000    0.0000    0.0000        93\n",
      "      S-LOC     0.9702    0.9763    0.9733      1603\n",
      "     S-MISC     0.9480    0.9053    0.9262       665\n",
      "      S-ORG     0.9351    0.9371    0.9361       891\n",
      "      S-PER     0.9246    0.9474    0.9358       608\n",
      "\n",
      "avg / total     0.9325    0.9289    0.9301      8696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7414    0.9267    0.8238       232\n",
      "     B-MISC     0.6166    0.6723    0.6432       177\n",
      "      B-ORG     0.8515    0.8515    0.8515       579\n",
      "      B-PER     0.9791    0.9917    0.9854      1086\n",
      "      E-LOC     0.7405    0.9224    0.8215       232\n",
      "     E-MISC     0.6684    0.7288    0.6973       177\n",
      "      E-ORG     0.8547    0.8532    0.8539       579\n",
      "      E-PER     0.9764    0.9899    0.9831      1086\n",
      "      I-LOC     0.4878    0.8000    0.6061        25\n",
      "     I-MISC     0.5476    0.5897    0.5679        39\n",
      "      I-ORG     0.7270    0.8633    0.7893       256\n",
      "      I-PER     0.9706    0.9429    0.9565        70\n",
      "          O     0.0000    0.0000    0.0000       344\n",
      "      S-LOC     0.9302    0.9366    0.9334      1436\n",
      "     S-MISC     0.8887    0.8362    0.8616       525\n",
      "      S-ORG     0.9102    0.8993    0.9047      1082\n",
      "      S-PER     0.9281    0.8757    0.9012       531\n",
      "\n",
      "avg / total     0.8574    0.8713    0.8634      8456\n",
      "\n",
      "\n",
      "Starting epoch 3\n",
      "Training completed in 293.23 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9981    0.9933    0.9957      1041\n",
      "     B-MISC     0.9930    0.9883    0.9907       858\n",
      "      B-ORG     0.9964    0.9924    0.9944      2485\n",
      "      B-PER     0.9974    0.9993    0.9984      4284\n",
      "      E-LOC     0.9981    0.9942    0.9962      1041\n",
      "     E-MISC     0.9965    0.9918    0.9942       858\n",
      "      E-ORG     0.9964    0.9924    0.9944      2485\n",
      "      E-PER     0.9972    0.9991    0.9981      4284\n",
      "      I-LOC     1.0000    0.9914    0.9957       116\n",
      "     I-MISC     0.9867    1.0000    0.9933       297\n",
      "      I-ORG     0.9918    0.9943    0.9930      1219\n",
      "      I-PER     0.9959    1.0000    0.9980       244\n",
      "          O     0.0000    0.0000    0.0000        80\n",
      "      S-LOC     0.9957    0.9954    0.9956      6099\n",
      "     S-MISC     0.9918    0.9899    0.9909      2580\n",
      "      S-ORG     0.9932    0.9927    0.9930      3836\n",
      "      S-PER     0.9749    0.9905    0.9827      2316\n",
      "\n",
      "avg / total     0.9918    0.9922    0.9920     34123\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9247    0.9444    0.9345       234\n",
      "     B-MISC     0.8360    0.8132    0.8245       257\n",
      "      B-ORG     0.8881    0.8467    0.8669       450\n",
      "      B-PER     0.9815    0.9911    0.9863      1234\n",
      "      E-LOC     0.9205    0.9402    0.9302       234\n",
      "     E-MISC     0.8651    0.8482    0.8566       257\n",
      "      E-ORG     0.9065    0.8622    0.8838       450\n",
      "      E-PER     0.9807    0.9887    0.9847      1234\n",
      "      I-LOC     0.7059    0.5217    0.6000        23\n",
      "     I-MISC     0.7361    0.5955    0.6584        89\n",
      "      I-ORG     0.9200    0.8405    0.8785       301\n",
      "      I-PER     0.9286    0.7123    0.8062        73\n",
      "          O     0.0000    0.0000    0.0000        96\n",
      "      S-LOC     0.9673    0.9782    0.9727      1603\n",
      "     S-MISC     0.9271    0.9173    0.9221       665\n",
      "      S-ORG     0.9402    0.9349    0.9375       891\n",
      "      S-PER     0.8961    0.9507    0.9226       608\n",
      "\n",
      "avg / total     0.9282    0.9241    0.9257      8699\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8015    0.9052    0.8502       232\n",
      "     B-MISC     0.6310    0.6667    0.6484       177\n",
      "      B-ORG     0.8566    0.8463    0.8514       579\n",
      "      B-PER     0.9720    0.9917    0.9818      1086\n",
      "      E-LOC     0.7947    0.9009    0.8444       232\n",
      "     E-MISC     0.6845    0.7232    0.7033       177\n",
      "      E-ORG     0.8669    0.8549    0.8609       579\n",
      "      E-PER     0.9702    0.9908    0.9804      1086\n",
      "      I-LOC     0.5882    0.8000    0.6780        25\n",
      "     I-MISC     0.5581    0.6154    0.5854        39\n",
      "      I-ORG     0.7634    0.8320    0.7963       256\n",
      "      I-PER     0.9706    0.9429    0.9565        70\n",
      "          O     0.0000    0.0000    0.0000       318\n",
      "      S-LOC     0.9279    0.9408    0.9343      1436\n",
      "     S-MISC     0.8569    0.8552    0.8561       525\n",
      "      S-ORG     0.9099    0.9057    0.9078      1082\n",
      "      S-PER     0.9121    0.8795    0.8955       531\n",
      "\n",
      "avg / total     0.8614    0.8746    0.8676      8430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_counter = 0  # number of epochs with no improvement on the validation test in terms of F1-score\n",
    "previous_best_valid_f1_score = 0\n",
    "epoch_number = -1\n",
    "\n",
    "while True:\n",
    "\n",
    "    step = 0\n",
    "    epoch_number += 1\n",
    "    print('\\nStarting epoch {0}'.format(epoch_number))\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    if epoch_number != 0:\n",
    "        # Train model: loop over all sequences of training set with shuffling\n",
    "        sequence_numbers = list(range(len(dataset.token_indices['train'])))\n",
    "        random.shuffle(sequence_numbers)\n",
    "        for sequence_number in sequence_numbers:\n",
    "            transition_params_trained = train.train_step(sess, dataset, sequence_number, model, parameters['dropout_rate'])\n",
    "            step += 1\n",
    "            if step % 10 == 0:\n",
    "                print('Training {0:.2f}% done'.format(step / len(sequence_numbers) * 100), end='\\r', flush=True)\n",
    "\n",
    "    epoch_elapsed_training_time = time.time() - epoch_start_time\n",
    "    print('Training completed in {0:.2f} seconds'.format(epoch_elapsed_training_time), flush=True)\n",
    "\n",
    "    y_pred, y_true, output_filepaths = train.predict_labels(sess=sess,model= model,transition_params_trained= transition_params_trained,\n",
    "                                                                         dataset=dataset,epoch_number= epoch_number,\n",
    "                                                                        stats_graph_folder= stats_graph_folder,dataset_filepaths= dataset_filepaths,\n",
    "                                                                        tagging_format= parameters['tagging_format'])\n",
    "\n",
    "       \n",
    "#     if epoch_number % 3 ==0:\n",
    "    model.saver.save(sess, os.path.join(model_folder, 'model.ckpt'))\n",
    "        \n",
    "    if epoch_number > 2 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_count=0\n",
    "def predict(text):\n",
    "    #         if prediction_count == 1:\n",
    "    parameters['dataset_text_folder'] = os.path.join('..', 'data', 'temp')\n",
    "    stats_graph_folder, _ = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "    # Update the deploy folder, file, and dataset\n",
    "    dataset_type = 'deploy'\n",
    "    ### Delete all deployment data\n",
    "    for filepath in glob.glob(os.path.join(parameters['dataset_text_folder'], '{0}*'.format(dataset_type))):\n",
    "        if os.path.isdir(filepath):\n",
    "            shutil.rmtree(filepath)\n",
    "        else:\n",
    "            os.remove(filepath)\n",
    "    ### Create brat folder and file\n",
    "    dataset_brat_deploy_folder = os.path.join(parameters['dataset_text_folder'], dataset_type)\n",
    "    utils.create_folder_if_not_exists(dataset_brat_deploy_folder)\n",
    "    dataset_brat_deploy_filepath = os.path.join(dataset_brat_deploy_folder, 'temp_{0}.txt'.format(\n",
    "        str(prediction_count).zfill(5)))  # self._get_dataset_brat_deploy_filepath(dataset_brat_deploy_folder)\n",
    "    with codecs.open(dataset_brat_deploy_filepath, 'w', 'UTF-8') as f:\n",
    "        f.write(text)\n",
    "    ### Update deploy filepaths\n",
    "    dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters,\n",
    "                                                                           dataset_types=[dataset_type])\n",
    "    dataset_filepaths.update(dataset_filepaths)\n",
    "    dataset_brat_folders.update(dataset_brat_folders)\n",
    "    ### Update the dataset for the new deploy set\n",
    "    dataset.update_dataset(dataset_filepaths, [dataset_type])\n",
    "\n",
    "    # Predict labels and output brat\n",
    "    output_filepaths = {}\n",
    "    prediction_output = train.prediction_step(sess, dataset, dataset_type, model,\n",
    "                                              transition_params_trained, stats_graph_folder,\n",
    "                                              prediction_count, dataset_filepaths, parameters['tagging_format'])\n",
    "    predictions , _, output_filepaths[dataset_type] = prediction_output\n",
    "    \n",
    "#     print([dataset.index_to_label[prediction] for prediction in predictions])\n",
    "    conll2brat.output_brat(output_filepaths, dataset_brat_folders, stats_graph_folder, overwrite=True)\n",
    "\n",
    "    # Print and output result\n",
    "    text_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy',\n",
    "                                 os.path.basename(dataset_brat_deploy_filepath))\n",
    "    annotation_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy', '{0}.ann'.format(\n",
    "        utils.get_basename_without_extension(dataset_brat_deploy_filepath)))\n",
    "    text2, entities = brat2conll.get_entities_from_brat(text_filepath, annotation_filepath, verbose=True)\n",
    "    assert (text == text2)\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting deploy set from BRAT to CONLL... Done.\n",
      "Converting CONLL from BIO to BIOES format... Done.\n",
      "Predict labels for the deploy set\n",
      "Formatting 000_deploy set from CONLL to BRAT... Done.\n",
      "\n",
      "text:\n",
      "my name is Phạm  Ngoc Linh\n",
      "\n",
      "entity: {'id': 'T1', 'type': 'PER', 'start': 17, 'end': 26, 'text': 'Ngoc Linh'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 26, 'id': 'T1', 'start': 17, 'text': 'Ngoc Linh', 'type': 'PER'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('my name is Phạm  Ngoc Linh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 12506, 28, 8, 2468, 67, 4958, 11492, 9, 1],\n",
       " [0, 28, 8, 2468, 67, 4958, 11492, 9, 218],\n",
       " [0,\n",
       "  0,\n",
       "  28,\n",
       "  218,\n",
       "  361,\n",
       "  341,\n",
       "  28015,\n",
       "  0,\n",
       "  21,\n",
       "  186,\n",
       "  6658,\n",
       "  9,\n",
       "  1,\n",
       "  1638,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  86,\n",
       "  708,\n",
       "  31,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  10,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  19,\n",
       "  7,\n",
       "  12506,\n",
       "  6508,\n",
       "  16611,\n",
       "  335,\n",
       "  43,\n",
       "  19,\n",
       "  5526,\n",
       "  10,\n",
       "  755,\n",
       "  1522,\n",
       "  4,\n",
       "  3,\n",
       "  2572,\n",
       "  108,\n",
       "  482,\n",
       "  4,\n",
       "  9303,\n",
       "  2],\n",
       " [0,\n",
       "  19,\n",
       "  86,\n",
       "  427,\n",
       "  163,\n",
       "  8,\n",
       "  0,\n",
       "  9,\n",
       "  10,\n",
       "  156,\n",
       "  8,\n",
       "  0,\n",
       "  9,\n",
       "  4,\n",
       "  3,\n",
       "  540,\n",
       "  365,\n",
       "  4,\n",
       "  9303,\n",
       "  8,\n",
       "  839,\n",
       "  9303,\n",
       "  9,\n",
       "  2],\n",
       " [85,\n",
       "  19,\n",
       "  7,\n",
       "  1222,\n",
       "  1980,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  4,\n",
       "  3,\n",
       "  540,\n",
       "  365,\n",
       "  4,\n",
       "  9303,\n",
       "  5,\n",
       "  15100,\n",
       "  1,\n",
       "  31,\n",
       "  316,\n",
       "  31,\n",
       "  3,\n",
       "  1810,\n",
       "  14,\n",
       "  2861,\n",
       "  4,\n",
       "  9303,\n",
       "  8,\n",
       "  0,\n",
       "  9,\n",
       "  10,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  8,\n",
       "  0,\n",
       "  93,\n",
       "  0,\n",
       "  9,\n",
       "  230,\n",
       "  3,\n",
       "  9303,\n",
       "  1284,\n",
       "  2],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  629,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  923,\n",
       "  1138,\n",
       "  26,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  11851,\n",
       "  3,\n",
       "  6508,\n",
       "  16,\n",
       "  1611,\n",
       "  540,\n",
       "  365,\n",
       "  4,\n",
       "  9303,\n",
       "  5,\n",
       "  15100,\n",
       "  10,\n",
       "  7191,\n",
       "  3,\n",
       "  315,\n",
       "  558,\n",
       "  5,\n",
       "  0,\n",
       "  20,\n",
       "  3,\n",
       "  1565,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2],\n",
       " [85, 3506, 2200, 148, 26, 636, 5, 15092, 295, 6, 1141, 1102, 2],\n",
       " [883,\n",
       "  3,\n",
       "  328,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  181,\n",
       "  297,\n",
       "  4,\n",
       "  3,\n",
       "  365,\n",
       "  4,\n",
       "  9303,\n",
       "  1,\n",
       "  19,\n",
       "  16697,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  560,\n",
       "  2],\n",
       " [10268,\n",
       "  19151,\n",
       "  4,\n",
       "  0,\n",
       "  14,\n",
       "  946,\n",
       "  119,\n",
       "  32,\n",
       "  465,\n",
       "  6,\n",
       "  636,\n",
       "  5,\n",
       "  9303,\n",
       "  29,\n",
       "  5863,\n",
       "  0,\n",
       "  24,\n",
       "  0,\n",
       "  2],\n",
       " [85, 29, 708, 6, 41, 738, 20, 706, 350, 10, 5839, 31, 458, 31, 999, 0, 2],\n",
       " [8, 0, 338, 20, 706, 332, 2, 9],\n",
       " [1064,\n",
       "  377,\n",
       "  4,\n",
       "  7273,\n",
       "  10,\n",
       "  748,\n",
       "  4,\n",
       "  7273,\n",
       "  53,\n",
       "  979,\n",
       "  4,\n",
       "  9220,\n",
       "  4512,\n",
       "  133,\n",
       "  4418,\n",
       "  29,\n",
       "  708,\n",
       "  24,\n",
       "  19654,\n",
       "  2,\n",
       "  11],\n",
       " [22263,\n",
       "  0,\n",
       "  10,\n",
       "  138,\n",
       "  53,\n",
       "  20,\n",
       "  706,\n",
       "  150,\n",
       "  1,\n",
       "  0,\n",
       "  12,\n",
       "  2728,\n",
       "  1,\n",
       "  5170,\n",
       "  1,\n",
       "  2925,\n",
       "  10,\n",
       "  131,\n",
       "  1871,\n",
       "  18728,\n",
       "  2],\n",
       " [0, 0, 0, 814, 92, 4914, 2]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.token_indices['deploy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNK',\n",
       " 'UNK',\n",
       " ':',\n",
       " ';',\n",
       " '19',\n",
       " 'May',\n",
       " '1890',\n",
       " 'UNK',\n",
       " '2',\n",
       " 'September',\n",
       " '1969',\n",
       " ')',\n",
       " ',',\n",
       " 'born',\n",
       " 'UNK',\n",
       " 'UNK',\n",
       " 'UNK',\n",
       " ',',\n",
       " 'also',\n",
       " 'known',\n",
       " 'as',\n",
       " 'UNK',\n",
       " 'UNK',\n",
       " 'UNK',\n",
       " 'and',\n",
       " 'UNK',\n",
       " 'UNK',\n",
       " 'UNK',\n",
       " ',',\n",
       " 'was',\n",
       " 'a',\n",
       " 'Vietnamese',\n",
       " 'Communist',\n",
       " 'revolutionary',\n",
       " 'leader',\n",
       " 'who',\n",
       " 'was',\n",
       " 'Chairman',\n",
       " 'and',\n",
       " 'First',\n",
       " 'Secretary',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Workers',\n",
       " \"'\",\n",
       " 'Party',\n",
       " 'of',\n",
       " 'Vietnam',\n",
       " '.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dataset.index_to_token[i] for i in dataset.token_indices['deploy'][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting deploy set from BRAT to CONLL... Done.\n",
      "Converting CONLL from BIO to BIOES format... Done.\n",
      "Predict labels for the deploy set\n",
      "Formatting 000_deploy set from CONLL to BRAT... Done.\n",
      "\n",
      "text:\n",
      "Hồ Chí Minh Vietnamese:  (About this sound listen), Saigon:  (About this sound listen); Chữ nôm: ; 19 May 1890 – 2 September 1969), born Nguyễn Sinh Cung, also known as Nguyễn Tất Thành and Nguyễn Ái Quốc, was a Vietnamese Communist revolutionary leader who was Chairman and First Secretary of the Workers' Party of Vietnam. Hồ was also Prime Minister (1945–55) and President (1945–69) of the Democratic Republic of Vietnam (North Vietnam). He was a key figure in the foundation of the Democratic Republic of Vietnam in 1945, as well as the People's Army of Vietnam (PAVN) and the Việt Cộng (NLF or VC) during the Vietnam War.Hồ Chí Minh led the Việt Minh independence movement from 1941 onward, establishing the Communist-ruled Democratic Republic of Vietnam in 1945 and defeating the French Union in 1954 at the battle of Điện Biên Phủ. He officially stepped down from power in 1965 due to health problems. After the war, Saigon, the former capital of the Republic of Vietnam, was renamed Hồ Chí Minh City.Any description of Ho's life before he came to power in Vietnam is necessarily fraught with ambiguity. He is known to have used at least 50 and perhaps as many as 200 pseudonyms. (Duiker says at least 75.) His place of birth and date of birth are products of academic consensus since neither is known with certainty. \"Official biographies and there are at least four, vary on names, dates, places and other hard facts. Unofficial biographies vary even more widely.\n",
      "\n",
      "entity: {'id': 'T1', 'type': 'MISC', 'start': 0, 'end': 22, 'text': 'Hồ Chí Minh Vietnamese'}\n",
      "entity: {'id': 'T2', 'type': 'PER', 'start': 137, 'end': 153, 'text': 'Nguyễn Sinh Cung'}\n",
      "entity: {'id': 'T3', 'type': 'PER', 'start': 176, 'end': 185, 'text': 'Tất Thành'}\n",
      "entity: {'id': 'T4', 'type': 'PER', 'start': 190, 'end': 204, 'text': 'Nguyễn Ái Quốc'}\n",
      "entity: {'id': 'T5', 'type': 'MISC', 'start': 212, 'end': 232, 'text': 'Vietnamese Communist'}\n",
      "entity: {'id': 'T6', 'type': 'ORG', 'start': 298, 'end': 323, 'text': \"Workers' Party of Vietnam\"}\n",
      "entity: {'id': 'T7', 'type': 'ORG', 'start': 393, 'end': 423, 'text': 'Democratic Republic of Vietnam'}\n",
      "entity: {'id': 'T8', 'type': 'LOC', 'start': 425, 'end': 438, 'text': 'North Vietnam'}\n",
      "entity: {'id': 'T9', 'type': 'ORG', 'start': 486, 'end': 516, 'text': 'Democratic Republic of Vietnam'}\n",
      "entity: {'id': 'T10', 'type': 'MISC', 'start': 541, 'end': 547, 'text': 'People'}\n",
      "entity: {'id': 'T11', 'type': 'ORG', 'start': 550, 'end': 565, 'text': 'Army of Vietnam'}\n",
      "entity: {'id': 'T12', 'type': 'ORG', 'start': 567, 'end': 571, 'text': 'PAVN'}\n",
      "entity: {'id': 'T13', 'type': 'MISC', 'start': 581, 'end': 590, 'text': 'Việt Cộng'}\n",
      "entity: {'id': 'T14', 'type': 'ORG', 'start': 592, 'end': 595, 'text': 'NLF'}\n",
      "entity: {'id': 'T15', 'type': 'MISC', 'start': 599, 'end': 601, 'text': 'VC'}\n",
      "entity: {'id': 'T16', 'type': 'MISC', 'start': 614, 'end': 625, 'text': 'Vietnam War'}\n",
      "entity: {'id': 'T17', 'type': 'PER', 'start': 629, 'end': 637, 'text': 'Chí Minh'}\n",
      "entity: {'id': 'T18', 'type': 'ORG', 'start': 646, 'end': 655, 'text': 'Việt Minh'}\n",
      "entity: {'id': 'T19', 'type': 'MISC', 'start': 713, 'end': 722, 'text': 'Communist'}\n",
      "entity: {'id': 'T20', 'type': 'ORG', 'start': 729, 'end': 759, 'text': 'Democratic Republic of Vietnam'}\n",
      "entity: {'id': 'T21', 'type': 'ORG', 'start': 786, 'end': 798, 'text': 'French Union'}\n",
      "entity: {'id': 'T22', 'type': 'LOC', 'start': 829, 'end': 837, 'text': 'Biên Phủ'}\n",
      "entity: {'id': 'T23', 'type': 'PER', 'start': 924, 'end': 930, 'text': 'Saigon'}\n",
      "entity: {'id': 'T24', 'type': 'LOC', 'start': 958, 'end': 977, 'text': 'Republic of Vietnam'}\n",
      "entity: {'id': 'T25', 'type': 'LOC', 'start': 991, 'end': 1007, 'text': 'Hồ Chí Minh City'}\n",
      "entity: {'id': 'T26', 'type': 'PER', 'start': 1027, 'end': 1029, 'text': 'Ho'}\n",
      "entity: {'id': 'T27', 'type': 'LOC', 'start': 1064, 'end': 1071, 'text': 'Vietnam'}\n",
      "entity: {'id': 'T28', 'type': 'PER', 'start': 1188, 'end': 1194, 'text': 'Duiker'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 22,\n",
       "  'id': 'T1',\n",
       "  'start': 0,\n",
       "  'text': 'Hồ Chí Minh Vietnamese',\n",
       "  'type': 'MISC'},\n",
       " {'end': 153,\n",
       "  'id': 'T2',\n",
       "  'start': 137,\n",
       "  'text': 'Nguyễn Sinh Cung',\n",
       "  'type': 'PER'},\n",
       " {'end': 185, 'id': 'T3', 'start': 176, 'text': 'Tất Thành', 'type': 'PER'},\n",
       " {'end': 204,\n",
       "  'id': 'T4',\n",
       "  'start': 190,\n",
       "  'text': 'Nguyễn Ái Quốc',\n",
       "  'type': 'PER'},\n",
       " {'end': 232,\n",
       "  'id': 'T5',\n",
       "  'start': 212,\n",
       "  'text': 'Vietnamese Communist',\n",
       "  'type': 'MISC'},\n",
       " {'end': 323,\n",
       "  'id': 'T6',\n",
       "  'start': 298,\n",
       "  'text': \"Workers' Party of Vietnam\",\n",
       "  'type': 'ORG'},\n",
       " {'end': 423,\n",
       "  'id': 'T7',\n",
       "  'start': 393,\n",
       "  'text': 'Democratic Republic of Vietnam',\n",
       "  'type': 'ORG'},\n",
       " {'end': 438,\n",
       "  'id': 'T8',\n",
       "  'start': 425,\n",
       "  'text': 'North Vietnam',\n",
       "  'type': 'LOC'},\n",
       " {'end': 516,\n",
       "  'id': 'T9',\n",
       "  'start': 486,\n",
       "  'text': 'Democratic Republic of Vietnam',\n",
       "  'type': 'ORG'},\n",
       " {'end': 547, 'id': 'T10', 'start': 541, 'text': 'People', 'type': 'MISC'},\n",
       " {'end': 565,\n",
       "  'id': 'T11',\n",
       "  'start': 550,\n",
       "  'text': 'Army of Vietnam',\n",
       "  'type': 'ORG'},\n",
       " {'end': 571, 'id': 'T12', 'start': 567, 'text': 'PAVN', 'type': 'ORG'},\n",
       " {'end': 590, 'id': 'T13', 'start': 581, 'text': 'Việt Cộng', 'type': 'MISC'},\n",
       " {'end': 595, 'id': 'T14', 'start': 592, 'text': 'NLF', 'type': 'ORG'},\n",
       " {'end': 601, 'id': 'T15', 'start': 599, 'text': 'VC', 'type': 'MISC'},\n",
       " {'end': 625,\n",
       "  'id': 'T16',\n",
       "  'start': 614,\n",
       "  'text': 'Vietnam War',\n",
       "  'type': 'MISC'},\n",
       " {'end': 637, 'id': 'T17', 'start': 629, 'text': 'Chí Minh', 'type': 'PER'},\n",
       " {'end': 655, 'id': 'T18', 'start': 646, 'text': 'Việt Minh', 'type': 'ORG'},\n",
       " {'end': 722, 'id': 'T19', 'start': 713, 'text': 'Communist', 'type': 'MISC'},\n",
       " {'end': 759,\n",
       "  'id': 'T20',\n",
       "  'start': 729,\n",
       "  'text': 'Democratic Republic of Vietnam',\n",
       "  'type': 'ORG'},\n",
       " {'end': 798,\n",
       "  'id': 'T21',\n",
       "  'start': 786,\n",
       "  'text': 'French Union',\n",
       "  'type': 'ORG'},\n",
       " {'end': 837, 'id': 'T22', 'start': 829, 'text': 'Biên Phủ', 'type': 'LOC'},\n",
       " {'end': 930, 'id': 'T23', 'start': 924, 'text': 'Saigon', 'type': 'PER'},\n",
       " {'end': 977,\n",
       "  'id': 'T24',\n",
       "  'start': 958,\n",
       "  'text': 'Republic of Vietnam',\n",
       "  'type': 'LOC'},\n",
       " {'end': 1007,\n",
       "  'id': 'T25',\n",
       "  'start': 991,\n",
       "  'text': 'Hồ Chí Minh City',\n",
       "  'type': 'LOC'},\n",
       " {'end': 1029, 'id': 'T26', 'start': 1027, 'text': 'Ho', 'type': 'PER'},\n",
       " {'end': 1071, 'id': 'T27', 'start': 1064, 'text': 'Vietnam', 'type': 'LOC'},\n",
       " {'end': 1194, 'id': 'T28', 'start': 1188, 'text': 'Duiker', 'type': 'PER'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Hồ Chí Minh Vietnamese:  (About this sound listen), Saigon:  (About this sound listen); Chữ nôm: ; 19 May 1890 – 2 September 1969), born Nguyễn Sinh Cung, also known as Nguyễn Tất Thành and Nguyễn Ái Quốc, was a Vietnamese Communist revolutionary leader who was Chairman and First Secretary of the Workers' Party of Vietnam. Hồ was also Prime Minister (1945–55) and President (1945–69) of the Democratic Republic of Vietnam (North Vietnam). He was a key figure in the foundation of the Democratic Republic of Vietnam in 1945, as well as the People's Army of Vietnam (PAVN) and the Việt Cộng (NLF or VC) during the Vietnam War.Hồ Chí Minh led the Việt Minh independence movement from 1941 onward, establishing the Communist-ruled Democratic Republic of Vietnam in 1945 and defeating the French Union in 1954 at the battle of Điện Biên Phủ. He officially stepped down from power in 1965 due to health problems. After the war, Saigon, the former capital of the Republic of Vietnam, was renamed Hồ Chí Minh City.Any description of Ho's life before he came to power in Vietnam is necessarily fraught with ambiguity. He is known to have used at least 50 and perhaps as many as 200 pseudonyms. (Duiker says at least 75.) His place of birth and date of birth are products of academic consensus since neither is known with certainty. \\\"Official biographies and there are at least four, vary on names, dates, places and other hard facts. Unofficial biographies vary even more widely.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
