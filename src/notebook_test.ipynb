{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import train\n",
    "import dataset as ds\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "import utils\n",
    "import os\n",
    "import conll2brat\n",
    "import glob\n",
    "import codecs\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import evaluate\n",
    "import random\n",
    "import pickle\n",
    "import brat2conll\n",
    "import numpy as np\n",
    "import utils_nlp\n",
    "import distutils.util as distutils_util\n",
    "import configparser\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'pretrained_model_folder':'../model',\n",
    "                      'dataset_text_folder':'../../../ML_EntityData/data/en',\n",
    "                      'character_embedding_dimension':25,\n",
    "                      'character_lstm_hidden_state_dimension':25,\n",
    "                      'check_for_digits_replaced_with_zeros':True,\n",
    "                      'check_for_lowercase':True,\n",
    "                      'debug':False,\n",
    "                      'dropout_rate':0.5,\n",
    "                      'experiment_name':'test',\n",
    "                      'freeze_token_embeddings':False,\n",
    "                      'gradient_clipping_value':5.0,\n",
    "                      'learning_rate':0.005,\n",
    "                      'load_only_pretrained_token_embeddings':False,\n",
    "                      'load_all_pretrained_token_embeddings':False,\n",
    "                      'main_evaluation_mode':'conll',\n",
    "                      'maximum_number_of_epochs':500,\n",
    "                      'number_of_cpu_threads':8,\n",
    "                      'number_of_gpus':0,\n",
    "                      'optimizer':'sgd',\n",
    "                      'output_folder':'../../../ML_EntityData/output',\n",
    "                      'patience':10,\n",
    "                      'plot_format':'pdf',\n",
    "                      'reload_character_embeddings':True,\n",
    "                      'reload_character_lstm':True,\n",
    "                      'reload_crf':True,\n",
    "                      'reload_feedforward':True,\n",
    "                      'reload_token_embeddings':True,\n",
    "                      'reload_token_lstm':True,\n",
    "                      'remap_unknown_tokens_to_unk':True,\n",
    "                      'spacylanguage':'en',\n",
    "                      'tagging_format':'bioes',\n",
    "                      'token_embedding_dimension':100,\n",
    "                      'token_lstm_hidden_state_dimension':100,\n",
    "                      'token_pretrained_embedding_filepath':'../../../ML_EntityData/embedding/en/glove.6B.100d.txt',\n",
    "                      'tokenizer':'spacy',\n",
    "                      'train_model':True,\n",
    "                      'use_character_lstm':True,\n",
    "                      'use_crf':True,\n",
    "                      'use_pretrained_model':False,\n",
    "                      'verbose':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the validity of BRAT-formatted train set... Done.\n",
      "Checking compatibility between CONLL and BRAT for train_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted valid set... Done.\n",
      "Checking compatibility between CONLL and BRAT for valid_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted test set... Done.\n",
      "Checking compatibility between CONLL and BRAT for test_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Load dataset... done (47.02 seconds)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import dataset as ds\n",
    "# Load dataset\n",
    "dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters)\n",
    "dataset = ds.Dataset(verbose=False, debug=False)\n",
    "token_to_vector = dataset.load_dataset(dataset_filepaths, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_characters: Tensor(\"character_embedding/embedded_characters:0\", shape=(?, ?, 25), dtype=float32)\n",
      "embedded_tokens: Tensor(\"token_embedding/embedding_lookup:0\", shape=(?, 100), dtype=float32)\n",
      "token_lstm_input: Tensor(\"concatenate_token_and_character_vectors/token_lstm_input:0\", shape=(?, 150), dtype=float32)\n",
      "token_lstm_input_drop: Tensor(\"dropout/token_lstm_input_drop/mul:0\", shape=(?, 150), dtype=float32)\n",
      "token_lstm_input_drop_expanded: Tensor(\"dropout/token_lstm_input_drop_expanded:0\", shape=(1, ?, 150), dtype=float32)\n",
      "unary_scores_expanded: Tensor(\"crf/unary_scores_expanded:0\", shape=(1, ?, 19), dtype=float32)\n",
      "input_label_indices_flat_batch: Tensor(\"crf/input_label_indices_flat_batch:0\", shape=(1, ?), dtype=int32)\n",
      "sequence_lengths: Tensor(\"crf/sequence_lengths:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from BLSTM_CRF import Char_BLSTM_CRF\n",
    "# Create model lstm+crf\n",
    "session_conf = tf.ConfigProto(\n",
    "            intra_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            inter_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            device_count={'CPU': 2, 'GPU': parameters['number_of_gpus']},\n",
    "            allow_soft_placement=True,\n",
    "            # automatically choose an existing and supported device to run the operations in case the specified one doesn't exist\n",
    "            log_device_placement=False\n",
    "        )\n",
    "sess = tf.Session(config=session_conf)\n",
    "\n",
    "with sess.as_default():\n",
    "    # Create model and initialize or load pretrained model\n",
    "    ### Instantiate the model\n",
    "    model = Char_BLSTM_CRF(dataset=dataset, token_embedding_dimension=parameters['token_embedding_dimension'],\n",
    "                       character_lstm_hidden_state_dimension=parameters['character_lstm_hidden_state_dimension'],\n",
    "                       token_lstm_hidden_state_dimension=parameters['token_lstm_hidden_state_dimension'],\n",
    "                       character_embedding_dimension=parameters['character_embedding_dimension'],\n",
    "                       gradient_clipping_value=parameters['gradient_clipping_value'],\n",
    "                       learning_rate=parameters['learning_rate'],\n",
    "                       freeze_token_embeddings=parameters['freeze_token_embeddings'],\n",
    "                       optimizer=parameters['optimizer'],\n",
    "                       maximum_number_of_epochs=parameters['maximum_number_of_epochs'])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (0.37 seconds)\n",
      "number_of_token_original_case_found: 14618\n",
      "number_of_token_lowercase_found: 11723\n",
      "number_of_token_digits_replaced_with_zeros_found: 119\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 16\n",
      "number_of_loaded_word_vectors: 26476\n",
      "dataset.vocabulary_size: 28984\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.load_pretrained_token_embeddings(sess, dataset,embedding_filepath=parameters['token_pretrained_embedding_filepath'],\n",
    "                                                       check_lowercase= parameters['check_for_lowercase'],check_digits=parameters['check_for_digits_replaced_with_zeros'],\n",
    "                                                       token_to_vector=token_to_vector)\n",
    "# Initial params_train\n",
    "transition_params_trained = np.random.rand(len(dataset.unique_labels) + 2,len(dataset.unique_labels) + 2)\n",
    "\n",
    "del token_to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "stats_graph_folder, experiment_timestamp = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "        # Initialize and save execution details\n",
    "start_time = time.time()\n",
    "# results = {}\n",
    "# results['epoch'] = {}\n",
    "# results['execution_details'] = {}\n",
    "# results['execution_details']['train_start'] = start_time\n",
    "# results['execution_details']['time_stamp'] = experiment_timestamp\n",
    "# results['execution_details']['early_stop'] = False\n",
    "# results['execution_details']['keyboard_interrupt'] = False\n",
    "# results['execution_details']['num_epochs'] = 0\n",
    "# results['model_options'] = copy.copy(parameters)\n",
    "\n",
    "model_folder = os.path.join(stats_graph_folder, 'model')\n",
    "utils.create_folder_if_not_exists(model_folder)\n",
    "\n",
    "pickle.dump(dataset, open(os.path.join(model_folder, 'dataset.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 0\n",
      "Training completed in 0.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0013    0.0096    0.0022      1041\n",
      "     B-MISC     0.0039    0.1597    0.0076       858\n",
      "      B-ORG     0.0094    0.0249    0.0137      2485\n",
      "      B-PER     0.0756    0.0929    0.0834      4284\n",
      "      E-LOC     0.0000    0.0000    0.0000      1041\n",
      "     E-MISC     0.0000    0.0000    0.0000       858\n",
      "      E-ORG     0.0101    0.0266    0.0146      2485\n",
      "      E-PER     0.0119    0.2054    0.0225      4284\n",
      "      I-LOC     0.0016    0.0431    0.0030       116\n",
      "     I-MISC     0.0032    0.0640    0.0061       297\n",
      "      I-ORG     0.0020    0.0049    0.0028      1219\n",
      "      I-PER     0.0009    0.0369    0.0018       244\n",
      "          O     0.0000    0.0000    0.0000    167594\n",
      "      S-LOC     0.0377    0.0087    0.0141      6099\n",
      "     S-MISC     0.0100    0.1446    0.0187      2580\n",
      "      S-ORG     0.0831    0.1025    0.0918      3836\n",
      "      S-PER     0.0000    0.0000    0.0000      2316\n",
      "\n",
      "avg / total     0.0050    0.0120    0.0051    201637\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0026    0.0214    0.0047       234\n",
      "     B-MISC     0.0047    0.1595    0.0092       257\n",
      "      B-ORG     0.0116    0.0422    0.0182       450\n",
      "      B-PER     0.0874    0.0810    0.0841      1234\n",
      "      E-LOC     0.0000    0.0000    0.0000       234\n",
      "     E-MISC     0.0000    0.0000    0.0000       257\n",
      "      E-ORG     0.0117    0.0444    0.0185       450\n",
      "      E-PER     0.0150    0.2334    0.0282      1234\n",
      "      I-LOC     0.0000    0.0000    0.0000        23\n",
      "     I-MISC     0.0048    0.0787    0.0090        89\n",
      "      I-ORG     0.0000    0.0000    0.0000       301\n",
      "      I-PER     0.0013    0.0411    0.0026        73\n",
      "          O     0.0000    0.0000    0.0000     42251\n",
      "      S-LOC     0.0665    0.0131    0.0219      1603\n",
      "     S-MISC     0.0118    0.1729    0.0221       665\n",
      "      S-ORG     0.0950    0.1257    0.1082       891\n",
      "      S-PER     0.0000    0.0000    0.0000       608\n",
      "\n",
      "avg / total     0.0067    0.0144    0.0060     50854\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0016    0.0129    0.0029       232\n",
      "     B-MISC     0.0020    0.0904    0.0040       177\n",
      "      B-ORG     0.0043    0.0104    0.0061       579\n",
      "      B-PER     0.0753    0.1050    0.0877      1086\n",
      "      E-LOC     0.0000    0.0000    0.0000       232\n",
      "     E-MISC     0.0000    0.0000    0.0000       177\n",
      "      E-ORG     0.0176    0.0432    0.0250       579\n",
      "      E-PER     0.0145    0.2173    0.0272      1086\n",
      "      I-LOC     0.0000    0.0000    0.0000        25\n",
      "     I-MISC     0.0015    0.0513    0.0029        39\n",
      "      I-ORG     0.0000    0.0000    0.0000       256\n",
      "      I-PER     0.0005    0.0143    0.0009        70\n",
      "          O     0.0000    0.0000    0.0000     37793\n",
      "      S-LOC     0.0711    0.0216    0.0331      1436\n",
      "     S-MISC     0.0100    0.1524    0.0187       525\n",
      "      S-ORG     0.0530    0.0712    0.0608      1082\n",
      "      S-PER     0.0000    0.0000    0.0000       531\n",
      "\n",
      "avg / total     0.0060    0.0129    0.0058     45905\n",
      "\n",
      "\n",
      "Starting epoch 1\n",
      "Training completed in 303.10 seconds\n",
      "Evaluate model on the train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7743    0.7118    0.7417      1041\n",
      "     B-MISC     0.7000    0.5303    0.6034       858\n",
      "      B-ORG     0.8161    0.6197    0.7045      2485\n",
      "      B-PER     0.9228    0.9573    0.9397      4284\n",
      "      E-LOC     0.7588    0.7012    0.7289      1041\n",
      "     E-MISC     0.6822    0.5303    0.5967       858\n",
      "      E-ORG     0.8319    0.6394    0.7231      2485\n",
      "      E-PER     0.9268    0.9601    0.9431      4284\n",
      "      I-LOC     0.0000    0.0000    0.0000       116\n",
      "     I-MISC     1.0000    0.0202    0.0396       297\n",
      "      I-ORG     0.6807    0.5176    0.5881      1219\n",
      "      I-PER     0.8559    0.3893    0.5352       244\n",
      "          O     0.0000    0.0000    0.0000       797\n",
      "      S-LOC     0.8764    0.9311    0.9029      6099\n",
      "     S-MISC     0.9135    0.6225    0.7404      2580\n",
      "      S-ORG     0.8970    0.7560    0.8205      3836\n",
      "      S-PER     0.9159    0.7526    0.8263      2316\n",
      "\n",
      "avg / total     0.8439    0.7573    0.7897     34840\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7536    0.6667    0.7075       234\n",
      "     B-MISC     0.6537    0.5214    0.5801       257\n",
      "      B-ORG     0.7672    0.5200    0.6199       450\n",
      "      B-PER     0.9426    0.9716    0.9569      1234\n",
      "      E-LOC     0.7536    0.6795    0.7146       234\n",
      "     E-MISC     0.6509    0.5370    0.5885       257\n",
      "      E-ORG     0.8071    0.5578    0.6597       450\n",
      "      E-PER     0.9477    0.9692    0.9583      1234\n",
      "      I-LOC     0.0000    0.0000    0.0000        23\n",
      "     I-MISC     0.3333    0.0112    0.0217        89\n",
      "      I-ORG     0.7718    0.5282    0.6272       301\n",
      "      I-PER     0.9722    0.4795    0.6422        73\n",
      "          O     0.0000    0.0000    0.0000       192\n",
      "      S-LOC     0.8930    0.9526    0.9218      1603\n",
      "     S-MISC     0.9268    0.6857    0.7882       665\n",
      "      S-ORG     0.9056    0.7969    0.8478       891\n",
      "      S-PER     0.8958    0.7780    0.8327       608\n",
      "\n",
      "avg / total     0.8484    0.7764    0.8043      8795\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.6880    0.7414    0.7137       232\n",
      "     B-MISC     0.5714    0.5650    0.5682       177\n",
      "      B-ORG     0.7763    0.6114    0.6841       579\n",
      "      B-PER     0.9184    0.9540    0.9359      1086\n",
      "      E-LOC     0.6707    0.7198    0.6944       232\n",
      "     E-MISC     0.5304    0.5424    0.5363       177\n",
      "      E-ORG     0.7780    0.6114    0.6847       579\n",
      "      E-PER     0.9269    0.9576    0.9420      1086\n",
      "      I-LOC     0.0000    0.0000    0.0000        25\n",
      "     I-MISC     0.6667    0.1026    0.1778        39\n",
      "      I-ORG     0.7053    0.5234    0.6009       256\n",
      "      I-PER     0.8696    0.2857    0.4301        70\n",
      "          O     0.0000    0.0000    0.0000       308\n",
      "      S-LOC     0.8323    0.9262    0.8767      1436\n",
      "     S-MISC     0.8956    0.6210    0.7334       525\n",
      "      S-ORG     0.8728    0.6978    0.7756      1082\n",
      "      S-PER     0.9136    0.6573    0.7645       531\n",
      "\n",
      "avg / total     0.8048    0.7407    0.7641      8420\n",
      "\n",
      "\n",
      "Starting epoch 2\n",
      "Training 76.56% done\r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bad_counter = 0  # number of epochs with no improvement on the validation test in terms of F1-score\n",
    "previous_best_valid_f1_score = 0\n",
    "epoch_number = -1\n",
    "\n",
    "while True:\n",
    "\n",
    "    step = 0\n",
    "    epoch_number += 1\n",
    "    print('\\nStarting epoch {0}'.format(epoch_number))\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    if epoch_number != 0:\n",
    "        # Train model: loop over all sequences of training set with shuffling\n",
    "        sequence_numbers = list(range(len(dataset.token_indices['train'])))\n",
    "        random.shuffle(sequence_numbers)\n",
    "        for sequence_number in sequence_numbers:\n",
    "            transition_params_trained = train.train_step(sess, dataset, sequence_number, model, parameters['dropout_rate'])\n",
    "            step += 1\n",
    "            if step % 10 == 0:\n",
    "                print('Training {0:.2f}% done'.format(step / len(sequence_numbers) * 100), end='\\r', flush=True)\n",
    "\n",
    "    epoch_elapsed_training_time = time.time() - epoch_start_time\n",
    "    print('Training completed in {0:.2f} seconds'.format(epoch_elapsed_training_time), flush=True)\n",
    "\n",
    "    y_pred, y_true, output_filepaths = train.predict_labels_lite(sess=sess,model= model,transition_params_trained= transition_params_trained,\n",
    "                                                                         dataset=dataset,epoch_number= epoch_number,\n",
    "                                                                        stats_graph_folder= stats_graph_folder,dataset_filepaths= dataset_filepaths,\n",
    "                                                                        tagging_format= parameters['tagging_format'], main_evaluation_mode=parameters['main_evaluation_mode'],use_crf=parameters['use_crf'])\n",
    "\n",
    "       \n",
    "    if epoch_number % 3 ==0:\n",
    "        model.saver.save(sess, os.path.join(model_folder, 'model_{0:05d}.ckpt'.format(epoch_number)))\n",
    "        \n",
    "    if epoch_number > 5 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prediction_count=0\n",
    "\n",
    "\n",
    "def predict(text):\n",
    "    #         if prediction_count == 1:\n",
    "    parameters['dataset_text_folder'] = os.path.join('..', 'data', 'temp')\n",
    "    stats_graph_folder, _ = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "    # Update the deploy folder, file, and dataset\n",
    "    dataset_type = 'deploy'\n",
    "    ### Delete all deployment data\n",
    "    for filepath in glob.glob(os.path.join(parameters['dataset_text_folder'], '{0}*'.format(dataset_type))):\n",
    "        if os.path.isdir(filepath):\n",
    "            shutil.rmtree(filepath)\n",
    "        else:\n",
    "            os.remove(filepath)\n",
    "    ### Create brat folder and file\n",
    "    dataset_brat_deploy_folder = os.path.join(parameters['dataset_text_folder'], dataset_type)\n",
    "    utils.create_folder_if_not_exists(dataset_brat_deploy_folder)\n",
    "    dataset_brat_deploy_filepath = os.path.join(dataset_brat_deploy_folder, 'temp_{0}.txt'.format(\n",
    "        str(prediction_count).zfill(5)))  # self._get_dataset_brat_deploy_filepath(dataset_brat_deploy_folder)\n",
    "    with codecs.open(dataset_brat_deploy_filepath, 'w', 'UTF-8') as f:\n",
    "        f.write(text)\n",
    "    ### Update deploy filepaths\n",
    "    dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters,\n",
    "                                                                           dataset_types=[dataset_type])\n",
    "    dataset_filepaths.update(dataset_filepaths)\n",
    "    dataset_brat_folders.update(dataset_brat_folders)\n",
    "    ### Update the dataset for the new deploy set\n",
    "    dataset.update_dataset(dataset_filepaths, [dataset_type])\n",
    "\n",
    "    # Predict labels and output brat\n",
    "    output_filepaths = {}\n",
    "    prediction_output = train.prediction_step_lite(sess, dataset, dataset_type, model,\n",
    "                                              transition_params_trained, stats_graph_folder,\n",
    "                                              prediction_count, dataset_filepaths, parameters['tagging_format'],\n",
    "                                              parameters['main_evaluation_mode'])\n",
    "    _, _, output_filepaths[dataset_type] = prediction_output\n",
    "    conll2brat.output_brat(output_filepaths, dataset_brat_folders, stats_graph_folder, overwrite=True)\n",
    "\n",
    "    # Print and output result\n",
    "    text_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy',\n",
    "                                 os.path.basename(dataset_brat_deploy_filepath))\n",
    "    annotation_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy', '{0}.ann'.format(\n",
    "        utils.get_basename_without_extension(dataset_brat_deploy_filepath)))\n",
    "    text2, entities = brat2conll.get_entities_from_brat(text_filepath, annotation_filepath, verbose=True)\n",
    "    assert (text == text2)\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting deploy set from BRAT to CONLL... Done.\n",
      "Converting CONLL from BIO to BIOES format... Done.\n",
      "Predict labels for the deploy set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1428: UserWarning: labels size, 4, does not match size of target_names, 17\n",
      "  .format(len(labels), len(target_names))\n",
      "d:\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0000    0.0000    0.0000         0\n",
      "     B-MISC     0.0000    0.0000    0.0000         0\n",
      "      B-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-PER     0.0000    0.0000    0.0000         3\n",
      "\n",
      "avg / total     0.0000    0.0000    0.0000         3\n",
      "\n",
      "Formatting 000_deploy set from CONLL to BRAT... Done.\n",
      "\n",
      "text:\n",
      "her name are Pham Ngoc Linh\n",
      "\n",
      "entity: {'id': 'T1', 'type': 'ORG', 'start': 13, 'end': 27, 'text': 'Pham Ngoc Linh'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 27, 'id': 'T1', 'start': 13, 'text': 'Pham Ngoc Linh', 'type': 'ORG'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('her name i Pham Ngoc Linh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
