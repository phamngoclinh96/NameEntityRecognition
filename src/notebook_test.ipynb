{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import train\n",
    "import dataset as ds\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "import utils\n",
    "import os\n",
    "import conll2brat\n",
    "import glob\n",
    "import codecs\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import evaluate\n",
    "import random\n",
    "import pickle\n",
    "import brat2conll\n",
    "import numpy as np\n",
    "import utils_nlp\n",
    "import distutils.util as distutils_util\n",
    "import configparser\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'pretrained_model_folder':'../model',\n",
    "                      'dataset_text_folder':'../../../ML_EntityData/data/en',\n",
    "                      'character_embedding_dimension':25,\n",
    "                      'character_lstm_hidden_state_dimension':25,\n",
    "                      'check_for_digits_replaced_with_zeros':True,\n",
    "                      'check_for_lowercase':True,\n",
    "                      'debug':False,\n",
    "                      'dropout_rate':0.5,\n",
    "                      'experiment_name':'test',\n",
    "                      'freeze_token_embeddings':False,\n",
    "                      'gradient_clipping_value':5.0,\n",
    "                      'learning_rate':0.005,\n",
    "                      'load_only_pretrained_token_embeddings':False,\n",
    "                      'load_all_pretrained_token_embeddings':False,\n",
    "                      'main_evaluation_mode':'conll',\n",
    "                      'maximum_number_of_epochs':500,\n",
    "                      'number_of_cpu_threads':8,\n",
    "                      'number_of_gpus':0,\n",
    "                      'optimizer':'sgd',\n",
    "                      'output_folder':'../../../ML_EntityData/output',\n",
    "                      'patience':10,\n",
    "                      'plot_format':'pdf',\n",
    "                      'reload_character_embeddings':True,\n",
    "                      'reload_character_lstm':True,\n",
    "                      'reload_crf':True,\n",
    "                      'reload_feedforward':True,\n",
    "                      'reload_token_embeddings':True,\n",
    "                      'reload_token_lstm':True,\n",
    "                      'remap_unknown_tokens_to_unk':True,\n",
    "                      'spacylanguage':'en',\n",
    "                      'tagging_format':'bioes',\n",
    "                      'token_embedding_dimension':100,\n",
    "                      'token_lstm_hidden_state_dimension':100,\n",
    "                      'token_pretrained_embedding_filepath':'../../../ML_EntityData/embedding/en/glove.6B.100d.txt',\n",
    "                      'tokenizer':'spacy',\n",
    "                      'train_model':True,\n",
    "                      'use_character_lstm':True,\n",
    "                      'use_crf':True,\n",
    "                      'use_pretrained_model':False,\n",
    "                      'verbose':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the validity of BRAT-formatted train set... Done.\n",
      "Checking compatibility between CONLL and BRAT for train_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted valid set... Done.\n",
      "Checking compatibility between CONLL and BRAT for valid_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted test set... Done.\n",
      "Checking compatibility between CONLL and BRAT for test_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Load dataset... done (47.02 seconds)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import dataset as ds\n",
    "# Load dataset\n",
    "dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters)\n",
    "dataset = ds.Dataset(verbose=False, debug=False)\n",
    "token_to_vector = dataset.load_dataset(dataset_filepaths, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_characters: Tensor(\"character_embedding/embedded_characters:0\", shape=(?, ?, 25), dtype=float32)\n",
      "embedded_tokens: Tensor(\"token_embedding/embedding_lookup:0\", shape=(?, 100), dtype=float32)\n",
      "token_lstm_input: Tensor(\"concatenate_token_and_character_vectors/token_lstm_input:0\", shape=(?, 150), dtype=float32)\n",
      "token_lstm_input_drop: Tensor(\"dropout/token_lstm_input_drop/mul:0\", shape=(?, 150), dtype=float32)\n",
      "token_lstm_input_drop_expanded: Tensor(\"dropout/token_lstm_input_drop_expanded:0\", shape=(1, ?, 150), dtype=float32)\n",
      "unary_scores_expanded: Tensor(\"crf/unary_scores_expanded:0\", shape=(1, ?, 19), dtype=float32)\n",
      "input_label_indices_flat_batch: Tensor(\"crf/input_label_indices_flat_batch:0\", shape=(1, ?), dtype=int32)\n",
      "sequence_lengths: Tensor(\"crf/sequence_lengths:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from BLSTM_CRF import Char_BLSTM_CRF\n",
    "# Create model lstm+crf\n",
    "session_conf = tf.ConfigProto(\n",
    "            intra_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            inter_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            device_count={'CPU': 2, 'GPU': parameters['number_of_gpus']},\n",
    "            allow_soft_placement=True,\n",
    "            # automatically choose an existing and supported device to run the operations in case the specified one doesn't exist\n",
    "            log_device_placement=False\n",
    "        )\n",
    "sess = tf.Session(config=session_conf)\n",
    "\n",
    "with sess.as_default():\n",
    "    # Create model and initialize or load pretrained model\n",
    "    ### Instantiate the model\n",
    "    model = Char_BLSTM_CRF(dataset=dataset, token_embedding_dimension=parameters['token_embedding_dimension'],\n",
    "                       character_lstm_hidden_state_dimension=parameters['character_lstm_hidden_state_dimension'],\n",
    "                       token_lstm_hidden_state_dimension=parameters['token_lstm_hidden_state_dimension'],\n",
    "                       character_embedding_dimension=parameters['character_embedding_dimension'],\n",
    "                       gradient_clipping_value=parameters['gradient_clipping_value'],\n",
    "                       learning_rate=parameters['learning_rate'],\n",
    "                       freeze_token_embeddings=parameters['freeze_token_embeddings'],\n",
    "                       optimizer=parameters['optimizer'],\n",
    "                       maximum_number_of_epochs=parameters['maximum_number_of_epochs'])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (0.37 seconds)\n",
      "number_of_token_original_case_found: 14618\n",
      "number_of_token_lowercase_found: 11723\n",
      "number_of_token_digits_replaced_with_zeros_found: 119\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 16\n",
      "number_of_loaded_word_vectors: 26476\n",
      "dataset.vocabulary_size: 28984\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.load_pretrained_token_embeddings(sess, dataset,embedding_filepath=parameters['token_pretrained_embedding_filepath'],\n",
    "                                                       check_lowercase= parameters['check_for_lowercase'],check_digits=parameters['check_for_digits_replaced_with_zeros'],\n",
    "                                                       token_to_vector=token_to_vector)\n",
    "# Initial params_train\n",
    "transition_params_trained = np.random.rand(len(dataset.unique_labels) + 2,len(dataset.unique_labels) + 2)\n",
    "\n",
    "del token_to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "stats_graph_folder, experiment_timestamp = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "        # Initialize and save execution details\n",
    "start_time = time.time()\n",
    "# results = {}\n",
    "# results['epoch'] = {}\n",
    "# results['execution_details'] = {}\n",
    "# results['execution_details']['train_start'] = start_time\n",
    "# results['execution_details']['time_stamp'] = experiment_timestamp\n",
    "# results['execution_details']['early_stop'] = False\n",
    "# results['execution_details']['keyboard_interrupt'] = False\n",
    "# results['execution_details']['num_epochs'] = 0\n",
    "# results['model_options'] = copy.copy(parameters)\n",
    "\n",
    "model_folder = os.path.join(stats_graph_folder, 'model')\n",
    "utils.create_folder_if_not_exists(model_folder)\n",
    "\n",
    "pickle.dump(dataset, open(os.path.join(model_folder, 'dataset.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 0\n",
      "Training completed in 0.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0013    0.0096    0.0022      1041\n",
      "     B-MISC     0.0039    0.1597    0.0076       858\n",
      "      B-ORG     0.0094    0.0249    0.0137      2485\n",
      "      B-PER     0.0756    0.0929    0.0834      4284\n",
      "      E-LOC     0.0000    0.0000    0.0000      1041\n",
      "     E-MISC     0.0000    0.0000    0.0000       858\n",
      "      E-ORG     0.0101    0.0266    0.0146      2485\n",
      "      E-PER     0.0119    0.2054    0.0225      4284\n",
      "      I-LOC     0.0016    0.0431    0.0030       116\n",
      "     I-MISC     0.0032    0.0640    0.0061       297\n",
      "      I-ORG     0.0020    0.0049    0.0028      1219\n",
      "      I-PER     0.0009    0.0369    0.0018       244\n",
      "          O     0.0000    0.0000    0.0000    167594\n",
      "      S-LOC     0.0377    0.0087    0.0141      6099\n",
      "     S-MISC     0.0100    0.1446    0.0187      2580\n",
      "      S-ORG     0.0831    0.1025    0.0918      3836\n",
      "      S-PER     0.0000    0.0000    0.0000      2316\n",
      "\n",
      "avg / total     0.0050    0.0120    0.0051    201637\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0026    0.0214    0.0047       234\n",
      "     B-MISC     0.0047    0.1595    0.0092       257\n",
      "      B-ORG     0.0116    0.0422    0.0182       450\n",
      "      B-PER     0.0874    0.0810    0.0841      1234\n",
      "      E-LOC     0.0000    0.0000    0.0000       234\n",
      "     E-MISC     0.0000    0.0000    0.0000       257\n",
      "      E-ORG     0.0117    0.0444    0.0185       450\n",
      "      E-PER     0.0150    0.2334    0.0282      1234\n",
      "      I-LOC     0.0000    0.0000    0.0000        23\n",
      "     I-MISC     0.0048    0.0787    0.0090        89\n",
      "      I-ORG     0.0000    0.0000    0.0000       301\n",
      "      I-PER     0.0013    0.0411    0.0026        73\n",
      "          O     0.0000    0.0000    0.0000     42251\n",
      "      S-LOC     0.0665    0.0131    0.0219      1603\n",
      "     S-MISC     0.0118    0.1729    0.0221       665\n",
      "      S-ORG     0.0950    0.1257    0.1082       891\n",
      "      S-PER     0.0000    0.0000    0.0000       608\n",
      "\n",
      "avg / total     0.0067    0.0144    0.0060     50854\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0016    0.0129    0.0029       232\n",
      "     B-MISC     0.0020    0.0904    0.0040       177\n",
      "      B-ORG     0.0043    0.0104    0.0061       579\n",
      "      B-PER     0.0753    0.1050    0.0877      1086\n",
      "      E-LOC     0.0000    0.0000    0.0000       232\n",
      "     E-MISC     0.0000    0.0000    0.0000       177\n",
      "      E-ORG     0.0176    0.0432    0.0250       579\n",
      "      E-PER     0.0145    0.2173    0.0272      1086\n",
      "      I-LOC     0.0000    0.0000    0.0000        25\n",
      "     I-MISC     0.0015    0.0513    0.0029        39\n",
      "      I-ORG     0.0000    0.0000    0.0000       256\n",
      "      I-PER     0.0005    0.0143    0.0009        70\n",
      "          O     0.0000    0.0000    0.0000     37793\n",
      "      S-LOC     0.0711    0.0216    0.0331      1436\n",
      "     S-MISC     0.0100    0.1524    0.0187       525\n",
      "      S-ORG     0.0530    0.0712    0.0608      1082\n",
      "      S-PER     0.0000    0.0000    0.0000       531\n",
      "\n",
      "avg / total     0.0060    0.0129    0.0058     45905\n",
      "\n",
      "\n",
      "Starting epoch 1\n",
      "Training completed in 303.10 seconds\n",
      "Evaluate model on the train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7743    0.7118    0.7417      1041\n",
      "     B-MISC     0.7000    0.5303    0.6034       858\n",
      "      B-ORG     0.8161    0.6197    0.7045      2485\n",
      "      B-PER     0.9228    0.9573    0.9397      4284\n",
      "      E-LOC     0.7588    0.7012    0.7289      1041\n",
      "     E-MISC     0.6822    0.5303    0.5967       858\n",
      "      E-ORG     0.8319    0.6394    0.7231      2485\n",
      "      E-PER     0.9268    0.9601    0.9431      4284\n",
      "      I-LOC     0.0000    0.0000    0.0000       116\n",
      "     I-MISC     1.0000    0.0202    0.0396       297\n",
      "      I-ORG     0.6807    0.5176    0.5881      1219\n",
      "      I-PER     0.8559    0.3893    0.5352       244\n",
      "          O     0.0000    0.0000    0.0000       797\n",
      "      S-LOC     0.8764    0.9311    0.9029      6099\n",
      "     S-MISC     0.9135    0.6225    0.7404      2580\n",
      "      S-ORG     0.8970    0.7560    0.8205      3836\n",
      "      S-PER     0.9159    0.7526    0.8263      2316\n",
      "\n",
      "avg / total     0.8439    0.7573    0.7897     34840\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7536    0.6667    0.7075       234\n",
      "     B-MISC     0.6537    0.5214    0.5801       257\n",
      "      B-ORG     0.7672    0.5200    0.6199       450\n",
      "      B-PER     0.9426    0.9716    0.9569      1234\n",
      "      E-LOC     0.7536    0.6795    0.7146       234\n",
      "     E-MISC     0.6509    0.5370    0.5885       257\n",
      "      E-ORG     0.8071    0.5578    0.6597       450\n",
      "      E-PER     0.9477    0.9692    0.9583      1234\n",
      "      I-LOC     0.0000    0.0000    0.0000        23\n",
      "     I-MISC     0.3333    0.0112    0.0217        89\n",
      "      I-ORG     0.7718    0.5282    0.6272       301\n",
      "      I-PER     0.9722    0.4795    0.6422        73\n",
      "          O     0.0000    0.0000    0.0000       192\n",
      "      S-LOC     0.8930    0.9526    0.9218      1603\n",
      "     S-MISC     0.9268    0.6857    0.7882       665\n",
      "      S-ORG     0.9056    0.7969    0.8478       891\n",
      "      S-PER     0.8958    0.7780    0.8327       608\n",
      "\n",
      "avg / total     0.8484    0.7764    0.8043      8795\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.6880    0.7414    0.7137       232\n",
      "     B-MISC     0.5714    0.5650    0.5682       177\n",
      "      B-ORG     0.7763    0.6114    0.6841       579\n",
      "      B-PER     0.9184    0.9540    0.9359      1086\n",
      "      E-LOC     0.6707    0.7198    0.6944       232\n",
      "     E-MISC     0.5304    0.5424    0.5363       177\n",
      "      E-ORG     0.7780    0.6114    0.6847       579\n",
      "      E-PER     0.9269    0.9576    0.9420      1086\n",
      "      I-LOC     0.0000    0.0000    0.0000        25\n",
      "     I-MISC     0.6667    0.1026    0.1778        39\n",
      "      I-ORG     0.7053    0.5234    0.6009       256\n",
      "      I-PER     0.8696    0.2857    0.4301        70\n",
      "          O     0.0000    0.0000    0.0000       308\n",
      "      S-LOC     0.8323    0.9262    0.8767      1436\n",
      "     S-MISC     0.8956    0.6210    0.7334       525\n",
      "      S-ORG     0.8728    0.6978    0.7756      1082\n",
      "      S-PER     0.9136    0.6573    0.7645       531\n",
      "\n",
      "avg / total     0.8048    0.7407    0.7641      8420\n",
      "\n",
      "\n",
      "Starting epoch 2\n",
      "Training completed in 305.53 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8958    0.8175    0.8548      1041\n",
      "     B-MISC     0.7919    0.7098    0.7486       858\n",
      "      B-ORG     0.8648    0.8338    0.8490      2485\n",
      "      B-PER     0.9430    0.9813    0.9618      4284\n",
      "      E-LOC     0.8975    0.8242    0.8593      1041\n",
      "     E-MISC     0.7974    0.7203    0.7569       858\n",
      "      E-ORG     0.8663    0.8370    0.8514      2485\n",
      "      E-PER     0.9495    0.9869    0.9678      4284\n",
      "      I-LOC     0.0000    0.0000    0.0000       116\n",
      "     I-MISC     0.7951    0.3266    0.4630       297\n",
      "      I-ORG     0.7736    0.8212    0.7967      1219\n",
      "      I-PER     0.8427    0.8566    0.8496       244\n",
      "          O     0.0000    0.0000    0.0000       522\n",
      "      S-LOC     0.9622    0.9256    0.9435      6099\n",
      "     S-MISC     0.9227    0.8287    0.8732      2580\n",
      "      S-ORG     0.8997    0.8650    0.8820      3836\n",
      "      S-PER     0.8881    0.9046    0.8963      2316\n",
      "\n",
      "avg / total     0.8905    0.8686    0.8781     34565\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8960    0.7735    0.8303       234\n",
      "     B-MISC     0.7389    0.6498    0.6915       257\n",
      "      B-ORG     0.8063    0.7956    0.8009       450\n",
      "      B-PER     0.9666    0.9846    0.9755      1234\n",
      "      E-LOC     0.8883    0.7821    0.8318       234\n",
      "     E-MISC     0.7500    0.6887    0.7181       257\n",
      "      E-ORG     0.8143    0.8089    0.8116       450\n",
      "      E-PER     0.9705    0.9854    0.9779      1234\n",
      "      I-LOC     1.0000    0.0435    0.0833        23\n",
      "     I-MISC     0.7353    0.2809    0.4065        89\n",
      "      I-ORG     0.8080    0.7409    0.7730       301\n",
      "      I-PER     0.8500    0.6986    0.7669        73\n",
      "          O     0.0000    0.0000    0.0000       123\n",
      "      S-LOC     0.9555    0.9507    0.9531      1603\n",
      "     S-MISC     0.9278    0.8496    0.8870       665\n",
      "      S-ORG     0.8977    0.8664    0.8818       891\n",
      "      S-PER     0.8607    0.9145    0.8868       608\n",
      "\n",
      "avg / total     0.8922    0.8684    0.8774      8726\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7832    0.7629    0.7729       232\n",
      "     B-MISC     0.5756    0.6667    0.6178       177\n",
      "      B-ORG     0.7905    0.8083    0.7993       579\n",
      "      B-PER     0.9512    0.9862    0.9684      1086\n",
      "      E-LOC     0.7773    0.7672    0.7722       232\n",
      "     E-MISC     0.5756    0.6667    0.6178       177\n",
      "      E-ORG     0.8034    0.8187    0.8109       579\n",
      "      E-PER     0.9545    0.9843    0.9692      1086\n",
      "      I-LOC     0.0000    0.0000    0.0000        25\n",
      "     I-MISC     0.6087    0.3590    0.4516        39\n",
      "      I-ORG     0.7537    0.8008    0.7765       256\n",
      "      I-PER     0.9062    0.8286    0.8657        70\n",
      "          O     0.0000    0.0000    0.0000       292\n",
      "      S-LOC     0.9333    0.9157    0.9244      1436\n",
      "     S-MISC     0.8589    0.7886    0.8222       525\n",
      "      S-ORG     0.8953    0.8299    0.8614      1082\n",
      "      S-PER     0.8807    0.8343    0.8569       531\n",
      "\n",
      "avg / total     0.8408    0.8353    0.8373      8404\n",
      "\n",
      "\n",
      "Starting epoch 3\n",
      "Training completed in 298.49 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8767    0.8607    0.8686      1041\n",
      "     B-MISC     0.8776    0.6515    0.7478       858\n",
      "      B-ORG     0.8469    0.8946    0.8701      2485\n",
      "      B-PER     0.9626    0.9855    0.9739      4284\n",
      "      E-LOC     0.8757    0.8665    0.8711      1041\n",
      "     E-MISC     0.9027    0.6702    0.7692       858\n",
      "      E-ORG     0.8480    0.8978    0.8722      2485\n",
      "      E-PER     0.9653    0.9872    0.9761      4284\n",
      "      I-LOC     0.8800    0.1897    0.3121       116\n",
      "     I-MISC     0.8790    0.4646    0.6079       297\n",
      "      I-ORG     0.7905    0.8573    0.8225      1219\n",
      "      I-PER     0.9091    0.8607    0.8842       244\n",
      "          O     0.0000    0.0000    0.0000       722\n",
      "      S-LOC     0.9345    0.9631    0.9486      6099\n",
      "     S-MISC     0.9178    0.8609    0.8884      2580\n",
      "      S-ORG     0.8731    0.8989    0.8858      3836\n",
      "      S-PER     0.9234    0.9054    0.9143      2316\n",
      "\n",
      "avg / total     0.8896    0.8886    0.8866     34765\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8904    0.8333    0.8609       234\n",
      "     B-MISC     0.7937    0.5837    0.6726       257\n",
      "      B-ORG     0.7808    0.8311    0.8052       450\n",
      "      B-PER     0.9774    0.9814    0.9794      1234\n",
      "      E-LOC     0.8824    0.8333    0.8571       234\n",
      "     E-MISC     0.8477    0.6498    0.7357       257\n",
      "      E-ORG     0.8029    0.8511    0.8263       450\n",
      "      E-PER     0.9798    0.9814    0.9806      1234\n",
      "      I-LOC     1.0000    0.1739    0.2963        23\n",
      "     I-MISC     0.7561    0.3483    0.4769        89\n",
      "      I-ORG     0.8281    0.7841    0.8055       301\n",
      "      I-PER     0.9107    0.6986    0.7907        73\n",
      "          O     0.0000    0.0000    0.0000       138\n",
      "      S-LOC     0.9374    0.9713    0.9540      1603\n",
      "     S-MISC     0.9130    0.8677    0.8897       665\n",
      "      S-ORG     0.8855    0.9113    0.8982       891\n",
      "      S-PER     0.8868    0.9276    0.9068       608\n",
      "\n",
      "avg / total     0.8933    0.8830    0.8853      8741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8009    0.7974    0.7991       232\n",
      "     B-MISC     0.6532    0.6384    0.6457       177\n",
      "      B-ORG     0.7473    0.8377    0.7899       579\n",
      "      B-PER     0.9656    0.9834    0.9745      1086\n",
      "      E-LOC     0.7741    0.7974    0.7856       232\n",
      "     E-MISC     0.6744    0.6554    0.6648       177\n",
      "      E-ORG     0.7593    0.8497    0.8020       579\n",
      "      E-PER     0.9683    0.9834    0.9758      1086\n",
      "      I-LOC     0.0000    0.0000    0.0000        25\n",
      "     I-MISC     0.7778    0.5385    0.6364        39\n",
      "      I-ORG     0.7209    0.8477    0.7792       256\n",
      "      I-PER     0.9355    0.8286    0.8788        70\n",
      "          O     0.0000    0.0000    0.0000       349\n",
      "      S-LOC     0.9033    0.9304    0.9166      1436\n",
      "     S-MISC     0.8720    0.8171    0.8437       525\n",
      "      S-ORG     0.8763    0.8771    0.8767      1082\n",
      "      S-PER     0.9202    0.8475    0.8824       531\n",
      "\n",
      "avg / total     0.8326    0.8477    0.8393      8461\n",
      "\n",
      "\n",
      "Starting epoch 4\n",
      "Training completed in 301.45 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8003    0.9087    0.8511      1041\n",
      "     B-MISC     0.8843    0.6772    0.7670       858\n",
      "      B-ORG     0.9004    0.8515    0.8753      2485\n",
      "      B-PER     0.9601    0.9876    0.9737      4284\n",
      "      E-LOC     0.8015    0.9078    0.8514      1041\n",
      "     E-MISC     0.9015    0.6935    0.7839       858\n",
      "      E-ORG     0.8986    0.8527    0.8751      2485\n",
      "      E-PER     0.9648    0.9907    0.9775      4284\n",
      "      I-LOC     0.8148    0.3793    0.5176       116\n",
      "     I-MISC     0.8480    0.4882    0.6197       297\n",
      "      I-ORG     0.8755    0.7555    0.8111      1219\n",
      "      I-PER     0.9188    0.8811    0.8996       244\n",
      "          O     0.0000    0.0000    0.0000       381\n",
      "      S-LOC     0.9536    0.9603    0.9569      6099\n",
      "     S-MISC     0.9102    0.8725    0.8910      2580\n",
      "      S-ORG     0.9299    0.8892    0.9091      3836\n",
      "      S-PER     0.9350    0.9188    0.9268      2316\n",
      "\n",
      "avg / total     0.9136    0.8932    0.9015     34424\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7675    0.8889    0.8238       234\n",
      "     B-MISC     0.8032    0.5875    0.6787       257\n",
      "      B-ORG     0.8333    0.7444    0.7864       450\n",
      "      B-PER     0.9760    0.9870    0.9815      1234\n",
      "      E-LOC     0.7593    0.8761    0.8135       234\n",
      "     E-MISC     0.8367    0.6381    0.7241       257\n",
      "      E-ORG     0.8469    0.7622    0.8023       450\n",
      "      E-PER     0.9775    0.9862    0.9818      1234\n",
      "      I-LOC     0.9167    0.4783    0.6286        23\n",
      "     I-MISC     0.7143    0.3371    0.4580        89\n",
      "      I-ORG     0.8777    0.6678    0.7585       301\n",
      "      I-PER     0.9434    0.6849    0.7937        73\n",
      "          O     0.0000    0.0000    0.0000        97\n",
      "      S-LOC     0.9424    0.9688    0.9554      1603\n",
      "     S-MISC     0.9018    0.8842    0.8929       665\n",
      "      S-ORG     0.9196    0.8855    0.9022       891\n",
      "      S-PER     0.9042    0.9161    0.9101       608\n",
      "\n",
      "avg / total     0.9014    0.8759    0.8857      8700\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.6508    0.8836    0.7495       232\n",
      "     B-MISC     0.6788    0.6328    0.6550       177\n",
      "      B-ORG     0.8292    0.7547    0.7902       579\n",
      "      B-PER     0.9675    0.9862    0.9767      1086\n",
      "      E-LOC     0.6463    0.8664    0.7403       232\n",
      "     E-MISC     0.6909    0.6441    0.6667       177\n",
      "      E-ORG     0.8453    0.7737    0.8079       579\n",
      "      E-PER     0.9692    0.9853    0.9772      1086\n",
      "      I-LOC     0.4545    0.2000    0.2778        25\n",
      "     I-MISC     0.7407    0.5128    0.6061        39\n",
      "      I-ORG     0.8043    0.7383    0.7699       256\n",
      "      I-PER     0.9683    0.8714    0.9173        70\n",
      "          O     0.0000    0.0000    0.0000       235\n",
      "      S-LOC     0.9146    0.9318    0.9231      1436\n",
      "     S-MISC     0.8552    0.8324    0.8436       525\n",
      "      S-ORG     0.9080    0.8577    0.8821      1082\n",
      "      S-PER     0.9326    0.8343    0.8807       531\n",
      "\n",
      "avg / total     0.8590    0.8481    0.8517      8347\n",
      "\n",
      "\n",
      "Starting epoch 5\n",
      "Training completed in 292.59 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9571    0.8357    0.8923      1041\n",
      "     B-MISC     0.9044    0.7716    0.8327       858\n",
      "      B-ORG     0.8623    0.9348    0.8971      2485\n",
      "      B-PER     0.9688    0.9869    0.9778      4284\n",
      "      E-LOC     0.9614    0.8377    0.8953      1041\n",
      "     E-MISC     0.9179    0.7821    0.8446       858\n",
      "      E-ORG     0.8628    0.9340    0.8970      2485\n",
      "      E-PER     0.9736    0.9904    0.9819      4284\n",
      "      I-LOC     0.9302    0.3448    0.5031       116\n",
      "     I-MISC     0.8726    0.6229    0.7269       297\n",
      "      I-ORG     0.8463    0.8811    0.8633      1219\n",
      "      I-PER     0.9073    0.9221    0.9146       244\n",
      "          O     0.0000    0.0000    0.0000       433\n",
      "      S-LOC     0.9641    0.9629    0.9635      6099\n",
      "     S-MISC     0.9626    0.8674    0.9125      2580\n",
      "      S-ORG     0.9198    0.9239    0.9218      3836\n",
      "      S-PER     0.9276    0.9344    0.9310      2316\n",
      "\n",
      "avg / total     0.9232    0.9146    0.9174     34476\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9588    0.7949    0.8692       234\n",
      "     B-MISC     0.7944    0.6615    0.7219       257\n",
      "      B-ORG     0.7545    0.8467    0.7979       450\n",
      "      B-PER     0.9815    0.9862    0.9838      1234\n",
      "      E-LOC     0.9531    0.7821    0.8592       234\n",
      "     E-MISC     0.8194    0.6887    0.7484       257\n",
      "      E-ORG     0.7663    0.8600    0.8105       450\n",
      "      E-PER     0.9814    0.9846    0.9830      1234\n",
      "      I-LOC     1.0000    0.3043    0.4667        23\n",
      "     I-MISC     0.7500    0.4382    0.5532        89\n",
      "      I-ORG     0.8504    0.7741    0.8104       301\n",
      "      I-PER     0.9444    0.6986    0.8031        73\n",
      "          O     0.0000    0.0000    0.0000       111\n",
      "      S-LOC     0.9560    0.9626    0.9593      1603\n",
      "     S-MISC     0.9519    0.8632    0.9054       665\n",
      "      S-ORG     0.8967    0.9259    0.9111       891\n",
      "      S-PER     0.9059    0.9342    0.9198       608\n",
      "\n",
      "avg / total     0.9064    0.8901    0.8959      8714\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8462    0.7586    0.8000       232\n",
      "     B-MISC     0.6270    0.6554    0.6409       177\n",
      "      B-ORG     0.7608    0.8515    0.8036       579\n",
      "      B-PER     0.9746    0.9880    0.9813      1086\n",
      "      E-LOC     0.8517    0.7672    0.8073       232\n",
      "     E-MISC     0.6522    0.6780    0.6648       177\n",
      "      E-ORG     0.7728    0.8636    0.8157       579\n",
      "      E-PER     0.9763    0.9871    0.9817      1086\n",
      "      I-LOC     0.4545    0.2000    0.2778        25\n",
      "     I-MISC     0.6316    0.6154    0.6234        39\n",
      "      I-ORG     0.7474    0.8438    0.7927       256\n",
      "      I-PER     0.9559    0.9286    0.9420        70\n",
      "          O     0.0000    0.0000    0.0000       299\n",
      "      S-LOC     0.9243    0.9262    0.9252      1436\n",
      "     S-MISC     0.8879    0.8000    0.8417       525\n",
      "      S-ORG     0.8899    0.9039    0.8968      1082\n",
      "      S-PER     0.9273    0.8644    0.8947       531\n",
      "\n",
      "avg / total     0.8524    0.8590    0.8548      8411\n",
      "\n",
      "\n",
      "Starting epoch 6\n",
      "Training completed in 293.37 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9085    0.8963    0.9023      1041\n",
      "     B-MISC     0.9188    0.7646    0.8346       858\n",
      "      B-ORG     0.9220    0.8893    0.9054      2485\n",
      "      B-PER     0.9585    0.9916    0.9748      4284\n",
      "      E-LOC     0.9102    0.8953    0.9027      1041\n",
      "     E-MISC     0.9274    0.7739    0.8437       858\n",
      "      E-ORG     0.9215    0.8885    0.9047      2485\n",
      "      E-PER     0.9629    0.9942    0.9783      4284\n",
      "      I-LOC     0.8356    0.5259    0.6455       116\n",
      "     I-MISC     0.8664    0.6330    0.7315       297\n",
      "      I-ORG     0.7728    0.9434    0.8496      1219\n",
      "      I-PER     0.9106    0.9180    0.9143       244\n",
      "          O     0.0000    0.0000    0.0000       480\n",
      "      S-LOC     0.9686    0.9659    0.9672      6099\n",
      "     S-MISC     0.9214    0.9047    0.9130      2580\n",
      "      S-ORG     0.9696    0.8968    0.9317      3836\n",
      "      S-PER     0.8718    0.9598    0.9137      2316\n",
      "\n",
      "avg / total     0.9220    0.9159    0.9176     34523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8655    0.8803    0.8729       234\n",
      "     B-MISC     0.8137    0.6459    0.7202       257\n",
      "      B-ORG     0.8213    0.7867    0.8036       450\n",
      "      B-PER     0.9745    0.9911    0.9827      1234\n",
      "      E-LOC     0.8589    0.8846    0.8716       234\n",
      "     E-MISC     0.8689    0.6965    0.7732       257\n",
      "      E-ORG     0.8472    0.8133    0.8299       450\n",
      "      E-PER     0.9752    0.9887    0.9819      1234\n",
      "      I-LOC     0.9474    0.7826    0.8571        23\n",
      "     I-MISC     0.8571    0.4719    0.6087        89\n",
      "      I-ORG     0.7346    0.8738    0.7982       301\n",
      "      I-PER     0.9623    0.6986    0.8095        73\n",
      "          O     0.0000    0.0000    0.0000       141\n",
      "      S-LOC     0.9641    0.9713    0.9677      1603\n",
      "     S-MISC     0.9134    0.8887    0.9009       665\n",
      "      S-ORG     0.9352    0.8743    0.9037       891\n",
      "      S-PER     0.8455    0.9539    0.8964       608\n",
      "\n",
      "avg / total     0.9015    0.8923    0.8949      8744\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7605    0.8621    0.8081       232\n",
      "     B-MISC     0.6464    0.6610    0.6536       177\n",
      "      B-ORG     0.8148    0.7979    0.8063       579\n",
      "      B-PER     0.9651    0.9926    0.9787      1086\n",
      "      E-LOC     0.7567    0.8578    0.8040       232\n",
      "     E-MISC     0.6796    0.6949    0.6872       177\n",
      "      E-ORG     0.8272    0.8100    0.8185       579\n",
      "      E-PER     0.9633    0.9899    0.9764      1086\n",
      "      I-LOC     0.3846    0.4000    0.3922        25\n",
      "     I-MISC     0.6757    0.6410    0.6579        39\n",
      "      I-ORG     0.6196    0.8906    0.7308       256\n",
      "      I-PER     0.9429    0.9429    0.9429        70\n",
      "          O     0.0000    0.0000    0.0000       338\n",
      "      S-LOC     0.9374    0.9283    0.9328      1436\n",
      "     S-MISC     0.8309    0.8514    0.8410       525\n",
      "      S-ORG     0.9271    0.8577    0.8910      1082\n",
      "      S-PER     0.8646    0.9021    0.8829       531\n",
      "\n",
      "avg / total     0.8446    0.8567    0.8494      8450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bad_counter = 0  # number of epochs with no improvement on the validation test in terms of F1-score\n",
    "previous_best_valid_f1_score = 0\n",
    "epoch_number = -1\n",
    "\n",
    "while True:\n",
    "\n",
    "    step = 0\n",
    "    epoch_number += 1\n",
    "    print('\\nStarting epoch {0}'.format(epoch_number))\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    if epoch_number != 0:\n",
    "        # Train model: loop over all sequences of training set with shuffling\n",
    "        sequence_numbers = list(range(len(dataset.token_indices['train'])))\n",
    "        random.shuffle(sequence_numbers)\n",
    "        for sequence_number in sequence_numbers:\n",
    "            transition_params_trained = train.train_step(sess, dataset, sequence_number, model, parameters['dropout_rate'])\n",
    "            step += 1\n",
    "            if step % 10 == 0:\n",
    "                print('Training {0:.2f}% done'.format(step / len(sequence_numbers) * 100), end='\\r', flush=True)\n",
    "\n",
    "    epoch_elapsed_training_time = time.time() - epoch_start_time\n",
    "    print('Training completed in {0:.2f} seconds'.format(epoch_elapsed_training_time), flush=True)\n",
    "\n",
    "    y_pred, y_true, output_filepaths = train.predict_labels_lite(sess=sess,model= model,transition_params_trained= transition_params_trained,\n",
    "                                                                         dataset=dataset,epoch_number= epoch_number,\n",
    "                                                                        stats_graph_folder= stats_graph_folder,dataset_filepaths= dataset_filepaths,\n",
    "                                                                        tagging_format= parameters['tagging_format'], main_evaluation_mode=parameters['main_evaluation_mode'],use_crf=parameters['use_crf'])\n",
    "\n",
    "       \n",
    "    if epoch_number % 3 ==0:\n",
    "        model.saver.save(sess, os.path.join(model_folder, 'model_{0:05d}.ckpt'.format(epoch_number)))\n",
    "        \n",
    "    if epoch_number > 5 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prediction_count=0\n",
    "\n",
    "\n",
    "def predict(text):\n",
    "    #         if prediction_count == 1:\n",
    "    parameters['dataset_text_folder'] = os.path.join('..', 'data', 'temp')\n",
    "    stats_graph_folder, _ = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "    # Update the deploy folder, file, and dataset\n",
    "    dataset_type = 'deploy'\n",
    "    ### Delete all deployment data\n",
    "    for filepath in glob.glob(os.path.join(parameters['dataset_text_folder'], '{0}*'.format(dataset_type))):\n",
    "        if os.path.isdir(filepath):\n",
    "            shutil.rmtree(filepath)\n",
    "        else:\n",
    "            os.remove(filepath)\n",
    "    ### Create brat folder and file\n",
    "    dataset_brat_deploy_folder = os.path.join(parameters['dataset_text_folder'], dataset_type)\n",
    "    utils.create_folder_if_not_exists(dataset_brat_deploy_folder)\n",
    "    dataset_brat_deploy_filepath = os.path.join(dataset_brat_deploy_folder, 'temp_{0}.txt'.format(\n",
    "        str(prediction_count).zfill(5)))  # self._get_dataset_brat_deploy_filepath(dataset_brat_deploy_folder)\n",
    "    with codecs.open(dataset_brat_deploy_filepath, 'w', 'UTF-8') as f:\n",
    "        f.write(text)\n",
    "    ### Update deploy filepaths\n",
    "    dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters,\n",
    "                                                                           dataset_types=[dataset_type])\n",
    "    dataset_filepaths.update(dataset_filepaths)\n",
    "    dataset_brat_folders.update(dataset_brat_folders)\n",
    "    ### Update the dataset for the new deploy set\n",
    "    dataset.update_dataset(dataset_filepaths, [dataset_type])\n",
    "\n",
    "    # Predict labels and output brat\n",
    "    output_filepaths = {}\n",
    "    prediction_output = train.prediction_step_lite(sess, dataset, dataset_type, model,\n",
    "                                              transition_params_trained, stats_graph_folder,\n",
    "                                              prediction_count, dataset_filepaths, parameters['tagging_format'],\n",
    "                                              parameters['main_evaluation_mode'])\n",
    "    predictions , _, output_filepaths[dataset_type] = prediction_output\n",
    "    \n",
    "    print([dataset.index_to_label[prediction] for prediction in predictions])\n",
    "    conll2brat.output_brat(output_filepaths, dataset_brat_folders, stats_graph_folder, overwrite=True)\n",
    "\n",
    "    # Print and output result\n",
    "    text_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy',\n",
    "                                 os.path.basename(dataset_brat_deploy_filepath))\n",
    "    annotation_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy', '{0}.ann'.format(\n",
    "        utils.get_basename_without_extension(dataset_brat_deploy_filepath)))\n",
    "    text2, entities = brat2conll.get_entities_from_brat(text_filepath, annotation_filepath, verbose=True)\n",
    "    assert (text == text2)\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting deploy set from BRAT to CONLL... Done.\n",
      "Converting CONLL from BIO to BIOES format... Done.\n",
      "Predict labels for the deploy set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0000    0.0000    0.0000         0\n",
      "     B-MISC     0.0000    0.0000    0.0000         0\n",
      "      B-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-PER     0.0000    0.0000    0.0000         3\n",
      "\n",
      "avg / total     0.0000    0.0000    0.0000         3\n",
      "\n",
      "['O', 'O', 'O', 'B-PER', 'I-PER', 'E-PER']\n",
      "Formatting 000_deploy set from CONLL to BRAT... Done.\n",
      "\n",
      "text:\n",
      "her name is Pham Ngoc Linh\n",
      "\n",
      "entity: {'id': 'T1', 'type': 'PER', 'start': 12, 'end': 26, 'text': 'Pham Ngoc Linh'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 26, 'id': 'T1', 'start': 12, 'text': 'Pham Ngoc Linh', 'type': 'PER'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('her name is Pham Ngoc Linh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "def get_sentences(text):\n",
    "    doc =nlp(text)\n",
    "    sentences = []\n",
    "    for span in doc.sents:\n",
    "        sentence = [doc[i] for i in range(span.start, span.end)]\n",
    "        sentence_tokens = []\n",
    "        for token in sentence:\n",
    "            token_dict = {}\n",
    "            token_dict['start'] = token.idx\n",
    "            token_dict['end'] = token.idx + len(token)\n",
    "            token_dict['text'] = text[token_dict['start']:token_dict['end']]\n",
    "            if token_dict['text'].strip() in ['\\n', '\\t', ' ', '']:\n",
    "                continue\n",
    "            # Make sure that the token text does not contain any space\n",
    "            if len(token_dict['text'].split(' ')) != 1:\n",
    "                print(\n",
    "                    \"WARNING: the text of the token contains space character, replaced with hyphen\\n\\t{0}\\n\\t{1}\".format(\n",
    "                        token_dict['text'],\n",
    "                        token_dict['text'].replace(' ', '-')))\n",
    "                token_dict['text'] = token_dict['text'].replace(' ', '-')\n",
    "            sentence_tokens.append(token_dict)\n",
    "        sentences.append(sentence_tokens)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'end': 3, 'start': 0, 'text': 'her'},\n",
       "  {'end': 8, 'start': 4, 'text': 'name'},\n",
       "  {'end': 11, 'start': 9, 'text': 'is'},\n",
       "  {'end': 16, 'start': 12, 'text': 'Pham'},\n",
       "  {'end': 21, 'start': 17, 'text': 'Ngoc'},\n",
       "  {'end': 26, 'start': 22, 'text': 'Linh'}]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentences('her name is Pham Ngoc Linh')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
