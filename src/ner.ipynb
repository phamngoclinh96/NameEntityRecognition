{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import ner\n",
    "import os\n",
    "path_model = '../model/en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_characters: Tensor(\"character_embedding/embedded_characters:0\", shape=(?, ?, 25), dtype=float32)\n",
      "embedded_tokens: Tensor(\"token_embedding/embedding_lookup:0\", shape=(?, 100), dtype=float32)\n",
      "token_lstm_input: Tensor(\"concatenate_token_and_character_vectors/token_lstm_input:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop: Tensor(\"dropout/token_lstm_input_drop/mul:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop_expanded: Tensor(\"dropout/token_lstm_input_drop_expanded:0\", shape=(1, ?, 163), dtype=float32)\n",
      "unary_scores_expanded: Tensor(\"crf/unary_scores_expanded:0\", shape=(1, ?, 19), dtype=float32)\n",
      "input_label_indices_flat_batch: Tensor(\"crf/input_label_indices_flat_batch:0\", shape=(1, ?), dtype=int32)\n",
      "sequence_lengths: Tensor(\"crf/sequence_lengths:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (0.18 seconds)\n",
      "number_of_token_original_case_found: 14618\n",
      "number_of_token_lowercase_found: 11723\n",
      "number_of_token_digits_replaced_with_zeros_found: 119\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 16\n",
      "number_of_loaded_word_vectors: 26476\n",
      "dataset.vocabulary_size: 28984\n",
      "INFO:tensorflow:Restoring parameters from ../model/en\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = ner.restore_model_trained(model_folder = path_model,\n",
    "                                        embedding_filepath='../../../ML_EntityData/embedding/en/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {#'pretrained_model_folder':'../model', \n",
    "                      'dataset_text_folder':'../../../ML_EntityData/data/en', \n",
    "                      'character_embedding_dimension':25, \n",
    "                      'character_lstm_hidden_state_dimension':25, \n",
    "                      'check_for_digits_replaced_with_zeros':True, \n",
    "                      'check_for_lowercase':True, \n",
    "#                       'debug':False,\n",
    "#                       'dropout_rate':0.5,\n",
    "#                       'experiment_name':'test',\n",
    "                      'freeze_token_embeddings':False,\n",
    "                      'gradient_clipping_value':5.0,\n",
    "                      'learning_rate':0.005,\n",
    "#                       'load_only_pretrained_token_embeddings':False,\n",
    "#                       'load_all_pretrained_token_embeddings':False,\n",
    "#                       'main_evaluation_mode':'conll',\n",
    "                      'maximum_number_of_epochs':500,\n",
    "#                       'number_of_cpu_threads':8,\n",
    "#                       'number_of_gpus':0,\n",
    "                      'optimizer':'sgd',\n",
    "#                       'output_folder':'../../../ML_EntityData/output',\n",
    "#                       'patience':10,\n",
    "#                       'plot_format':'pdf',\n",
    "#                       'reload_character_embeddings':True,\n",
    "#                       'reload_character_lstm':True,\n",
    "#                       'reload_crf':True,\n",
    "#                       'reload_feedforward':True,\n",
    "#                       'reload_token_embeddings':True,\n",
    "#                       'reload_token_lstm':True,\n",
    "#                       'remap_unknown_tokens_to_unk':True,\n",
    "#                       'spacylanguage':'en',\n",
    "#                       'tagging_format':'bioes',\n",
    "                      'token_embedding_dimension':100,\n",
    "                      'token_lstm_hidden_state_dimension':100,\n",
    "                      'token_pretrained_embedding_filepath':'../../../ML_EntityData/embedding/en/glove.6B.100d.txt',\n",
    "#                       'tokenizer':'spacy',\n",
    "#                       'train_model':True,\n",
    "#                       'use_character_lstm':True,\n",
    "#                       'use_crf':True,\n",
    "#                       'use_pretrained_model':False,\n",
    "                      'verbose':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils_nlp\n",
    "import pickle\n",
    "# dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters)\n",
    "# dataset = ds.DatasetP(verbose=False, debug=False)\n",
    "token_to_vector = utils_nlp.load_pretrained_token_embeddings(parameters['token_pretrained_embedding_filepath'])\n",
    "dataset = pickle.load(open('../../../ML_EntityData/output/en/model/dataset.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_characters: Tensor(\"character_embedding/embedded_characters:0\", shape=(?, ?, 25), dtype=float32)\n",
      "embedded_tokens: Tensor(\"token_embedding/embedding_lookup:0\", shape=(?, 100), dtype=float32)\n",
      "token_lstm_input: Tensor(\"concatenate_token_and_character_vectors/token_lstm_input:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop: Tensor(\"dropout/token_lstm_input_drop/mul:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop_expanded: Tensor(\"dropout/token_lstm_input_drop_expanded:0\", shape=(1, ?, 163), dtype=float32)\n",
      "unary_scores_expanded: Tensor(\"crf/unary_scores_expanded:0\", shape=(1, ?, 19), dtype=float32)\n",
      "input_label_indices_flat_batch: Tensor(\"crf/input_label_indices_flat_batch:0\", shape=(1, ?), dtype=int32)\n",
      "sequence_lengths: Tensor(\"crf/sequence_lengths:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (35.45 seconds)\n",
      "number_of_token_original_case_found: 14618\n",
      "number_of_token_lowercase_found: 11723\n",
      "number_of_token_digits_replaced_with_zeros_found: 119\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 16\n",
      "number_of_loaded_word_vectors: 26476\n",
      "dataset.vocabulary_size: 28984\n"
     ]
    }
   ],
   "source": [
    "model = ner.NER(parameters,dataset = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 0\n",
      "Training completed in 0.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9942    0.9810    0.9875      7140\n",
      "     B-MISC     0.9871    0.9567    0.9716      3438\n",
      "      B-ORG     0.9878    0.9747    0.9812      6321\n",
      "      B-PER     0.9889    0.9898    0.9894      6600\n",
      "      I-LOC     0.9920    0.9611    0.9763      1157\n",
      "     I-MISC     0.9827    0.9368    0.9592      1155\n",
      "      I-ORG     0.9871    0.9727    0.9799      3704\n",
      "      I-PER     0.9921    0.9969    0.9945      4528\n",
      "          O     0.0000    0.0000    0.0000        70\n",
      "\n",
      "avg / total     0.9877    0.9761    0.9818     34113\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9794    0.9586    0.9689      1837\n",
      "     B-MISC     0.9266    0.8764    0.9008       922\n",
      "      B-ORG     0.9287    0.9224    0.9256      1341\n",
      "      B-PER     0.9588    0.9729    0.9658      1842\n",
      "      I-LOC     0.9737    0.8638    0.9155       257\n",
      "     I-MISC     0.8543    0.7457    0.7963       346\n",
      "      I-ORG     0.9048    0.8855    0.8950       751\n",
      "      I-PER     0.9883    0.9717    0.9799      1307\n",
      "          O     0.0000    0.0000    0.0000        73\n",
      "\n",
      "avg / total     0.9431    0.9236    0.9329      8676\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9480    0.9179    0.9327      1668\n",
      "     B-MISC     0.8366    0.8020    0.8189       702\n",
      "      B-ORG     0.8942    0.8952    0.8947      1661\n",
      "      B-PER     0.9590    0.9549    0.9569      1617\n",
      "      I-LOC     0.8719    0.8210    0.8457       257\n",
      "     I-MISC     0.6892    0.7083    0.6986       216\n",
      "      I-ORG     0.8400    0.8862    0.8625       835\n",
      "      I-PER     0.9745    0.9922    0.9833      1156\n",
      "          O     0.0000    0.0000    0.0000       227\n",
      "\n",
      "avg / total     0.8880    0.8845    0.8861      8339\n",
      "\n",
      "\n",
      "Starting epoch 1\n",
      "Training completed in 276.55 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9844    0.9923    0.9884      7140\n",
      "     B-MISC     0.9904    0.9575    0.9737      3438\n",
      "      B-ORG     0.9849    0.9799    0.9824      6321\n",
      "      B-PER     0.9879    0.9909    0.9894      6600\n",
      "      I-LOC     0.9836    0.9836    0.9836      1157\n",
      "     I-MISC     0.9794    0.9489    0.9639      1155\n",
      "      I-ORG     0.9772    0.9854    0.9813      3704\n",
      "      I-PER     0.9912    0.9985    0.9948      4528\n",
      "          O     0.0000    0.0000    0.0000       144\n",
      "\n",
      "avg / total     0.9816    0.9804    0.9809     34187\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9671    0.9750    0.9710      1837\n",
      "     B-MISC     0.9137    0.8839    0.8986       922\n",
      "      B-ORG     0.9293    0.9314    0.9304      1341\n",
      "      B-PER     0.9644    0.9707    0.9675      1842\n",
      "      I-LOC     0.9368    0.9222    0.9294       257\n",
      "     I-MISC     0.8526    0.7688    0.8085       346\n",
      "      I-ORG     0.8960    0.8948    0.8954       751\n",
      "      I-PER     0.9846    0.9801    0.9824      1307\n",
      "          O     0.0000    0.0000    0.0000       113\n",
      "\n",
      "avg / total     0.9336    0.9292    0.9313      8716\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9148    0.9400    0.9273      1668\n",
      "     B-MISC     0.8187    0.7977    0.8081       702\n",
      "      B-ORG     0.8958    0.8952    0.8955      1661\n",
      "      B-PER     0.9601    0.9536    0.9569      1617\n",
      "      I-LOC     0.7915    0.8716    0.8296       257\n",
      "     I-MISC     0.6525    0.7130    0.6814       216\n",
      "      I-ORG     0.8343    0.8802    0.8566       835\n",
      "      I-PER     0.9745    0.9922    0.9833      1156\n",
      "          O     0.0000    0.0000    0.0000       308\n",
      "\n",
      "avg / total     0.8680    0.8809    0.8742      8420\n",
      "\n",
      "\n",
      "Starting epoch 2\n",
      "Training completed in 271.48 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9879    0.9910    0.9894      7140\n",
      "     B-MISC     0.9843    0.9674    0.9758      3438\n",
      "      B-ORG     0.9858    0.9796    0.9827      6321\n",
      "      B-PER     0.9769    0.9941    0.9854      6600\n",
      "      I-LOC     0.9827    0.9844    0.9836      1157\n",
      "     I-MISC     0.9813    0.9524    0.9666      1155\n",
      "      I-ORG     0.9752    0.9868    0.9809      3704\n",
      "      I-PER     0.9886    0.9987    0.9936      4528\n",
      "          O     0.0000    0.0000    0.0000       227\n",
      "\n",
      "avg / total     0.9768    0.9796    0.9782     34270\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9616    0.9690    0.9653      1837\n",
      "     B-MISC     0.9102    0.8905    0.9002       922\n",
      "      B-ORG     0.9337    0.9142    0.9239      1341\n",
      "      B-PER     0.9520    0.9799    0.9658      1842\n",
      "      I-LOC     0.9023    0.8988    0.9006       257\n",
      "     I-MISC     0.8400    0.7890    0.8137       346\n",
      "      I-ORG     0.8964    0.8868    0.8916       751\n",
      "      I-PER     0.9868    0.9732    0.9800      1307\n",
      "          O     0.0000    0.0000    0.0000       112\n",
      "\n",
      "avg / total     0.9291    0.9264    0.9277      8715\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9182    0.9359    0.9270      1668\n",
      "     B-MISC     0.8098    0.8006    0.8052       702\n",
      "      B-ORG     0.8920    0.8952    0.8936      1661\n",
      "      B-PER     0.9495    0.9647    0.9571      1617\n",
      "      I-LOC     0.7828    0.8833    0.8300       257\n",
      "     I-MISC     0.6407    0.6852    0.6622       216\n",
      "      I-ORG     0.8170    0.8874    0.8507       835\n",
      "      I-PER     0.9728    0.9905    0.9816      1156\n",
      "          O     0.0000    0.0000    0.0000       348\n",
      "\n",
      "avg / total     0.8586    0.8784    0.8682      8460\n",
      "\n",
      "\n",
      "Starting epoch 3\n",
      "Training completed in 272.24 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9957    0.9835    0.9896      7140\n",
      "     B-MISC     0.9796    0.9764    0.9780      3438\n",
      "      B-ORG     0.9787    0.9872    0.9829      6321\n",
      "      B-PER     0.9873    0.9923    0.9898      6600\n",
      "      I-LOC     0.9947    0.9801    0.9874      1157\n",
      "     I-MISC     0.9774    0.9749    0.9762      1155\n",
      "      I-ORG     0.9820    0.9870    0.9845      3704\n",
      "      I-PER     0.9914    0.9982    0.9948      4528\n",
      "          O     0.0000    0.0000    0.0000       170\n",
      "\n",
      "avg / total     0.9817    0.9822    0.9819     34213\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9752    0.9641    0.9696      1837\n",
      "     B-MISC     0.8898    0.9024    0.8961       922\n",
      "      B-ORG     0.9325    0.9269    0.9297      1341\n",
      "      B-PER     0.9641    0.9777    0.9709      1842\n",
      "      I-LOC     0.9573    0.8716    0.9124       257\n",
      "     I-MISC     0.7939    0.8237    0.8085       346\n",
      "      I-ORG     0.9027    0.9015    0.9021       751\n",
      "      I-PER     0.9876    0.9770    0.9823      1307\n",
      "          O     0.0000    0.0000    0.0000       125\n",
      "\n",
      "avg / total     0.9312    0.9292    0.9301      8728\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9389    0.9299    0.9343      1668\n",
      "     B-MISC     0.8025    0.8219    0.8121       702\n",
      "      B-ORG     0.8916    0.9013    0.8964      1661\n",
      "      B-PER     0.9609    0.9579    0.9594      1617\n",
      "      I-LOC     0.8415    0.8677    0.8544       257\n",
      "     I-MISC     0.6582    0.7222    0.6887       216\n",
      "      I-ORG     0.8274    0.8898    0.8575       835\n",
      "      I-PER     0.9754    0.9939    0.9846      1156\n",
      "          O     0.0000    0.0000    0.0000       308\n",
      "\n",
      "avg / total     0.8719    0.8842    0.8778      8420\n",
      "\n",
      "\n",
      "Starting epoch 4\n",
      "Training completed in 271.67 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9872    0.9909    0.9890      7140\n",
      "     B-MISC     0.9852    0.9695    0.9773      3438\n",
      "      B-ORG     0.9822    0.9851    0.9837      6321\n",
      "      B-PER     0.9878    0.9927    0.9903      6600\n",
      "      I-LOC     0.9728    0.9879    0.9803      1157\n",
      "     I-MISC     0.9902    0.9584    0.9740      1155\n",
      "      I-ORG     0.9883    0.9816    0.9850      3704\n",
      "      I-PER     0.9949    0.9982    0.9966      4528\n",
      "          O     0.0000    0.0000    0.0000       155\n",
      "\n",
      "avg / total     0.9825    0.9823    0.9824     34198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9568    0.9760    0.9663      1837\n",
      "     B-MISC     0.9242    0.8861    0.9048       922\n",
      "      B-ORG     0.9315    0.9232    0.9273      1341\n",
      "      B-PER     0.9636    0.9761    0.9698      1842\n",
      "      I-LOC     0.8787    0.9300    0.9036       257\n",
      "     I-MISC     0.8571    0.7803    0.8169       346\n",
      "      I-ORG     0.9116    0.8655    0.8880       751\n",
      "      I-PER     0.9907    0.9755    0.9830      1307\n",
      "          O     0.0000    0.0000    0.0000        92\n",
      "\n",
      "avg / total     0.9357    0.9293    0.9322      8695\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9094    0.9388    0.9239      1668\n",
      "     B-MISC     0.8321    0.8048    0.8182       702\n",
      "      B-ORG     0.8783    0.8910    0.8846      1661\n",
      "      B-PER     0.9638    0.9549    0.9593      1617\n",
      "      I-LOC     0.7397    0.9066    0.8147       257\n",
      "     I-MISC     0.6712    0.6898    0.6804       216\n",
      "      I-ORG     0.8355    0.8455    0.8405       835\n",
      "      I-PER     0.9794    0.9879    0.9836      1156\n",
      "          O     0.0000    0.0000    0.0000       302\n",
      "\n",
      "avg / total     0.8656    0.8777    0.8713      8414\n",
      "\n",
      "\n",
      "Starting epoch 5\n",
      "Training completed in 267.43 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9895    0.9931    0.9913      7140\n",
      "     B-MISC     0.9873    0.9756    0.9814      3438\n",
      "      B-ORG     0.9861    0.9848    0.9854      6321\n",
      "      B-PER     0.9809    0.9938    0.9873      6600\n",
      "      I-LOC     0.9896    0.9827    0.9861      1157\n",
      "     I-MISC     0.9886    0.9723    0.9804      1155\n",
      "      I-ORG     0.9855    0.9889    0.9872      3704\n",
      "      I-PER     0.9917    0.9987    0.9952      4528\n",
      "          O     0.0000    0.0000    0.0000       188\n",
      "\n",
      "avg / total     0.9814    0.9837    0.9825     34231\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9639    0.9739    0.9689      1837\n",
      "     B-MISC     0.9147    0.8959    0.9052       922\n",
      "      B-ORG     0.9347    0.9180    0.9263      1341\n",
      "      B-PER     0.9535    0.9788    0.9660      1842\n",
      "      I-LOC     0.9355    0.9027    0.9188       257\n",
      "     I-MISC     0.8394    0.8006    0.8195       346\n",
      "      I-ORG     0.9074    0.8868    0.8970       751\n",
      "      I-PER     0.9839    0.9793    0.9816      1307\n",
      "          O     0.0000    0.0000    0.0000       108\n",
      "\n",
      "avg / total     0.9324    0.9303    0.9312      8711\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9192    0.9347    0.9269      1668\n",
      "     B-MISC     0.8223    0.8177    0.8200       702\n",
      "      B-ORG     0.8917    0.8922    0.8920      1661\n",
      "      B-PER     0.9544    0.9586    0.9565      1617\n",
      "      I-LOC     0.8396    0.8755    0.8571       257\n",
      "     I-MISC     0.6996    0.7222    0.7107       216\n",
      "      I-ORG     0.8298    0.8874    0.8576       835\n",
      "      I-PER     0.9705    0.9948    0.9825      1156\n",
      "          O     0.0000    0.0000    0.0000       301\n",
      "\n",
      "avg / total     0.8697    0.8840    0.8767      8413\n",
      "\n",
      "\n",
      "Starting epoch 6\n",
      "Training completed in 268.38 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9900    0.9894    0.9897      7140\n",
      "     B-MISC     0.9790    0.9785    0.9788      3438\n",
      "      B-ORG     0.9898    0.9807    0.9852      6321\n",
      "      B-PER     0.9841    0.9932    0.9886      6600\n",
      "      I-LOC     0.9796    0.9939    0.9867      1157\n",
      "     I-MISC     0.9877    0.9723    0.9799      1155\n",
      "      I-ORG     0.9945    0.9784    0.9864      3704\n",
      "      I-PER     0.9919    0.9989    0.9954      4528\n",
      "          O     0.0000    0.0000    0.0000       115\n",
      "\n",
      "avg / total     0.9847    0.9837    0.9842     34158\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9659    0.9701    0.9680      1837\n",
      "     B-MISC     0.9043    0.9024    0.9034       922\n",
      "      B-ORG     0.9426    0.9180    0.9301      1341\n",
      "      B-PER     0.9559    0.9761    0.9659      1842\n",
      "      I-LOC     0.9147    0.9183    0.9165       257\n",
      "     I-MISC     0.8369    0.8006    0.8183       346\n",
      "      I-ORG     0.9247    0.8509    0.8863       751\n",
      "      I-PER     0.9793    0.9770    0.9782      1307\n",
      "          O     0.0000    0.0000    0.0000        96\n",
      "\n",
      "avg / total     0.9348    0.9279    0.9312      8699\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9113    0.9359    0.9234      1668\n",
      "     B-MISC     0.8274    0.8262    0.8268       702\n",
      "      B-ORG     0.8996    0.8904    0.8950      1661\n",
      "      B-PER     0.9568    0.9579    0.9574      1617\n",
      "      I-LOC     0.7209    0.9144    0.8062       257\n",
      "     I-MISC     0.7083    0.7083    0.7083       216\n",
      "      I-ORG     0.8707    0.8551    0.8628       835\n",
      "      I-PER     0.9703    0.9905    0.9803      1156\n",
      "          O     0.0000    0.0000    0.0000       282\n",
      "\n",
      "avg / total     0.8732    0.8835    0.8779      8394\n",
      "\n",
      "\n",
      "Starting epoch 7\n",
      "Training completed in 268.26 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9945    0.9910    0.9928      7140\n",
      "     B-MISC     0.9877    0.9802    0.9839      3438\n",
      "      B-ORG     0.9863    0.9896    0.9879      6321\n",
      "      B-PER     0.9913    0.9897    0.9905      6600\n",
      "      I-LOC     0.9931    0.9896    0.9913      1157\n",
      "     I-MISC     0.9861    0.9818    0.9839      1155\n",
      "      I-ORG     0.9895    0.9908    0.9902      3704\n",
      "      I-PER     0.9917    0.9989    0.9953      4528\n",
      "          O     0.0000    0.0000    0.0000       129\n",
      "\n",
      "avg / total     0.9867    0.9863    0.9865     34172\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9737    0.9684    0.9711      1837\n",
      "     B-MISC     0.9010    0.8883    0.8946       922\n",
      "      B-ORG     0.9191    0.9321    0.9256      1341\n",
      "      B-PER     0.9677    0.9756    0.9716      1842\n",
      "      I-LOC     0.9363    0.9144    0.9252       257\n",
      "     I-MISC     0.8144    0.7861    0.8000       346\n",
      "      I-ORG     0.9118    0.8948    0.9032       751\n",
      "      I-PER     0.9891    0.9755    0.9823      1307\n",
      "          O     0.0000    0.0000    0.0000       116\n",
      "\n",
      "avg / total     0.9330    0.9289    0.9309      8719\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9315    0.9371    0.9342      1668\n",
      "     B-MISC     0.8103    0.8091    0.8097       702\n",
      "      B-ORG     0.8842    0.9055    0.8947      1661\n",
      "      B-PER     0.9600    0.9511    0.9556      1617\n",
      "      I-LOC     0.8125    0.9105    0.8587       257\n",
      "     I-MISC     0.6524    0.7037    0.6771       216\n",
      "      I-ORG     0.8506    0.8659    0.8582       835\n",
      "      I-PER     0.9727    0.9879    0.9803      1156\n",
      "          O     0.0000    0.0000    0.0000       302\n",
      "\n",
      "avg / total     0.8709    0.8823    0.8765      8414\n",
      "\n",
      "\n",
      "Starting epoch 8\n",
      "Training completed in 269.03 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9791    0.9972    0.9881      7140\n",
      "     B-MISC     0.9874    0.9770    0.9822      3438\n",
      "      B-ORG     0.9810    0.9864    0.9837      6321\n",
      "      B-PER     0.9930    0.9911    0.9920      6600\n",
      "      I-LOC     0.9746    0.9931    0.9837      1157\n",
      "     I-MISC     0.9835    0.9810    0.9822      1155\n",
      "      I-ORG     0.9823    0.9889    0.9856      3704\n",
      "      I-PER     0.9969    0.9976    0.9972      4528\n",
      "          O     0.0000    0.0000    0.0000       236\n",
      "\n",
      "avg / total     0.9789    0.9836    0.9812     34279\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9558    0.9771    0.9664      1837\n",
      "     B-MISC     0.9022    0.9002    0.9012       922\n",
      "      B-ORG     0.9354    0.9172    0.9262      1341\n",
      "      B-PER     0.9677    0.9750    0.9713      1842\n",
      "      I-LOC     0.8967    0.9455    0.9205       257\n",
      "     I-MISC     0.8249    0.8035    0.8141       346\n",
      "      I-ORG     0.9026    0.8881    0.8953       751\n",
      "      I-PER     0.9899    0.9763    0.9831      1307\n",
      "          O     0.0000    0.0000    0.0000       122\n",
      "\n",
      "avg / total     0.9297    0.9301    0.9298      8725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8976    0.9460    0.9212      1668\n",
      "     B-MISC     0.8051    0.8120    0.8085       702\n",
      "      B-ORG     0.8964    0.8910    0.8937      1661\n",
      "      B-PER     0.9668    0.9536    0.9601      1617\n",
      "      I-LOC     0.7508    0.9377    0.8339       257\n",
      "     I-MISC     0.6667    0.7130    0.6890       216\n",
      "      I-ORG     0.8404    0.8766    0.8581       835\n",
      "      I-PER     0.9793    0.9844    0.9819      1156\n",
      "          O     0.0000    0.0000    0.0000       328\n",
      "\n",
      "avg / total     0.8632    0.8809    0.8716      8440\n",
      "\n",
      "\n",
      "Starting epoch 9\n",
      "Training completed in 268.39 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9878    0.9951    0.9914      7140\n",
      "     B-MISC     0.9941    0.9750    0.9844      3438\n",
      "      B-ORG     0.9906    0.9845    0.9875      6321\n",
      "      B-PER     0.9918    0.9914    0.9916      6600\n",
      "      I-LOC     0.9721    0.9939    0.9829      1157\n",
      "     I-MISC     0.9879    0.9879    0.9879      1155\n",
      "      I-ORG     0.9964    0.9849    0.9906      3704\n",
      "      I-PER     0.9954    0.9982    0.9968      4528\n",
      "          O     0.0000    0.0000    0.0000        78\n",
      "\n",
      "avg / total     0.9889    0.9871    0.9880     34121\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9532    0.9755    0.9642      1837\n",
      "     B-MISC     0.9143    0.8905    0.9022       922\n",
      "      B-ORG     0.9479    0.9083    0.9276      1341\n",
      "      B-PER     0.9551    0.9805    0.9676      1842\n",
      "      I-LOC     0.8679    0.9455    0.9050       257\n",
      "     I-MISC     0.8431    0.7919    0.8167       346\n",
      "      I-ORG     0.9362    0.8602    0.8966       751\n",
      "      I-PER     0.9868    0.9755    0.9811      1307\n",
      "          O     0.0000    0.0000    0.0000        89\n",
      "\n",
      "avg / total     0.9356    0.9290    0.9319      8692\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9093    0.9436    0.9262      1668\n",
      "     B-MISC     0.8260    0.8048    0.8153       702\n",
      "      B-ORG     0.9060    0.8874    0.8966      1661\n",
      "      B-PER     0.9598    0.9604    0.9601      1617\n",
      "      I-LOC     0.7524    0.9222    0.8287       257\n",
      "     I-MISC     0.6638    0.7037    0.6831       216\n",
      "      I-ORG     0.8656    0.8563    0.8609       835\n",
      "      I-PER     0.9761    0.9913    0.9837      1156\n",
      "          O     0.0000    0.0000    0.0000       276\n",
      "\n",
      "avg / total     0.8752    0.8841    0.8793      8388\n",
      "\n",
      "\n",
      "Starting epoch 10\n",
      "Training completed in 269.09 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9930    0.9930    0.9930      7140\n",
      "     B-MISC     0.9880    0.9811    0.9845      3438\n",
      "      B-ORG     0.9955    0.9818    0.9886      6321\n",
      "      B-PER     0.9969    0.9894    0.9932      6600\n",
      "      I-LOC     0.9897    0.9939    0.9918      1157\n",
      "     I-MISC     0.9870    0.9827    0.9848      1155\n",
      "      I-ORG     0.9895    0.9938    0.9916      3704\n",
      "      I-PER     0.9976    0.9985    0.9980      4528\n",
      "          O     0.0000    0.0000    0.0000        79\n",
      "\n",
      "avg / total     0.9913    0.9872    0.9893     34122\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9680    0.9722    0.9701      1837\n",
      "     B-MISC     0.9125    0.8937    0.9030       922\n",
      "      B-ORG     0.9373    0.9247    0.9309      1341\n",
      "      B-PER     0.9727    0.9685    0.9706      1842\n",
      "      I-LOC     0.9264    0.9300    0.9282       257\n",
      "     I-MISC     0.8174    0.8150    0.8162       346\n",
      "      I-ORG     0.8903    0.9188    0.9043       751\n",
      "      I-PER     0.9892    0.9793    0.9842      1307\n",
      "          O     0.0000    0.0000    0.0000       113\n",
      "\n",
      "avg / total     0.9351    0.9322    0.9336      8716\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9252    0.9347    0.9299      1668\n",
      "     B-MISC     0.7981    0.8162    0.8070       702\n",
      "      B-ORG     0.8959    0.8862    0.8910      1661\n",
      "      B-PER     0.9764    0.9474    0.9617      1617\n",
      "      I-LOC     0.8049    0.8988    0.8493       257\n",
      "     I-MISC     0.6402    0.7083    0.6725       216\n",
      "      I-ORG     0.8077    0.8850    0.8446       835\n",
      "      I-PER     0.9837    0.9896    0.9866      1156\n",
      "          O     0.0000    0.0000    0.0000       322\n",
      "\n",
      "avg / total     0.8688    0.8778    0.8729      8434\n",
      "\n",
      "\n",
      "Starting epoch 11\n",
      "Training completed in 268.98 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9945    0.9937    0.9941      7140\n",
      "     B-MISC     0.9906    0.9805    0.9855      3438\n",
      "      B-ORG     0.9913    0.9894    0.9903      6321\n",
      "      B-PER     0.9915    0.9936    0.9926      6600\n",
      "      I-LOC     0.9957    0.9914    0.9935      1157\n",
      "     I-MISC     0.9895    0.9792    0.9843      1155\n",
      "      I-ORG     0.9967    0.9895    0.9931      3704\n",
      "      I-PER     0.9938    0.9989    0.9964      4528\n",
      "          O     0.0000    0.0000    0.0000        67\n",
      "\n",
      "avg / total     0.9910    0.9893    0.9901     34110\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9691    0.9733    0.9712      1837\n",
      "     B-MISC     0.9123    0.8915    0.9018       922\n",
      "      B-ORG     0.9339    0.9381    0.9360      1341\n",
      "      B-PER     0.9625    0.9767    0.9695      1842\n",
      "      I-LOC     0.9447    0.9300    0.9373       257\n",
      "     I-MISC     0.8571    0.7803    0.8169       346\n",
      "      I-ORG     0.9260    0.8828    0.9039       751\n",
      "      I-PER     0.9891    0.9763    0.9827      1307\n",
      "          O     0.0000    0.0000    0.0000        91\n",
      "\n",
      "avg / total     0.9402    0.9334    0.9367      8694\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9319    0.9347    0.9333      1668\n",
      "     B-MISC     0.8094    0.8105    0.8100       702\n",
      "      B-ORG     0.8878    0.9055    0.8966      1661\n",
      "      B-PER     0.9639    0.9579    0.9609      1617\n",
      "      I-LOC     0.8419    0.8911    0.8658       257\n",
      "     I-MISC     0.6463    0.6852    0.6652       216\n",
      "      I-ORG     0.8641    0.8683    0.8662       835\n",
      "      I-PER     0.9779    0.9931    0.9854      1156\n",
      "          O     0.0000    0.0000    0.0000       267\n",
      "\n",
      "avg / total     0.8788    0.8869    0.8828      8379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(140,'../../../ML_EntityData/output/en/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0000000e+03 -1.0000000e+03 -1.0000000e+03 -1.0000000e+03\n",
      "  -1.0000000e+03 -1.0000000e+03 -1.0000000e+03 -1.0000000e+03\n",
      "  -1.0000000e+03 -1.0000000e+03 -1.0000000e+03 -1.0000000e+03\n",
      "  -1.0000000e+03 -1.0000000e+03 -1.0000000e+03 -1.0000000e+03\n",
      "  -1.0000000e+03  0.0000000e+00 -1.0000000e+03]\n",
      " [ 4.4824171e-01  1.3811344e+00  2.8690879e+00  1.8973861e+00\n",
      "  -3.6798949e+00 -1.4526252e+00 -5.4023414e+00 -4.8910131e+00\n",
      "   1.2902298e+00  3.0320547e+00  1.0711594e+00  2.2385778e+00\n",
      "   1.3077450e+01 -3.5590715e+00 -5.6222944e+00 -3.3302381e+00\n",
      "   1.2518853e+00 -1.0000000e+03 -1.0000000e+03]\n",
      " [-8.0370450e-01  3.8774961e-01  1.6575676e+00 -9.3987036e-01\n",
      "  -2.6080201e+00 -4.0487280e-01 -1.9416164e+00 -4.5721440e+00\n",
      "   2.9652715e+00  3.8389003e+00  2.5222325e+00  3.2293916e+00\n",
      "   1.3339716e+01 -7.9012651e+00 -3.3105242e+00 -6.5285640e+00\n",
      "  -3.0955122e+00 -1.0000000e+03 -1.0000000e+03]\n",
      " [-3.1161299e-01  5.8760476e-01  3.0338973e-01 -1.5935638e+00\n",
      "  -1.0220983e+00 -1.1101817e+00 -1.7641180e+00 -4.5371079e+00\n",
      "   4.6896358e+00  5.8062701e+00  4.6504593e+00  3.8971593e+00\n",
      "   1.2539639e+01 -6.7981157e+00 -8.1117134e+00 -7.2841535e+00\n",
      "  -5.1574569e+00 -1.0000000e+03 -1.0000000e+03]\n",
      " [ 1.6749699e+00  2.8397839e+00  2.1252313e+00  2.0215716e+00\n",
      "  -2.6252947e+00 -8.1496119e-01 -3.6980476e+00 -5.4696617e+00\n",
      "   1.6818608e+00  8.4919310e-01 -4.9733451e-01  1.0139592e+00\n",
      "   1.8209212e+00 -1.2928743e+00  1.8887467e+00 -1.7374536e+00\n",
      "  -3.5223846e+00 -1.0000000e+03 -1.0000000e+03]\n",
      " [-9.7090137e-01 -3.5296547e-01 -1.0337470e+00  2.1366149e-02\n",
      "   2.7577600e-01  1.6478876e+00 -1.3392322e+00 -2.3276749e+00\n",
      "   2.5926123e+00  1.6259235e+00  3.7610120e-01  2.4150448e+00\n",
      "   1.8640778e+00 -2.3917294e+00  4.0543947e-01 -2.8825204e+00\n",
      "  -3.3439353e+00 -1.0000000e+03 -1.0000000e+03]\n",
      " [-1.6322643e+00 -9.8048443e-01 -2.3124018e+00 -2.3270235e+00\n",
      "   6.4589298e-01  2.5280435e+00 -1.0257417e+00 -2.7338836e+00\n",
      "   3.4785252e+00  4.3991547e+00  2.1836839e+00  3.8475821e+00\n",
      "   5.7859821e+00 -3.7191014e+00 -2.3244791e+00 -5.1213613e+00\n",
      "  -4.5327759e+00 -1.0000000e+03 -1.0000000e+03]\n",
      " [-6.3557374e-01 -9.3750399e-01 -1.0805587e+00 -7.3757058e-01\n",
      "   5.1974022e-01  7.6134360e-01 -1.4650441e+00 -2.2659681e+00\n",
      "   3.0530605e+00  2.1552532e+00  1.3083119e+00  3.1364424e+00\n",
      "   3.9655561e+00 -2.8200336e+00 -1.3356298e+00 -2.5837207e+00\n",
      "  -3.7116830e+00 -1.0000000e+03 -1.0000000e+03]\n",
      " [-2.2275367e+00 -2.5553885e+00 -2.6615939e+00 -3.4402914e+00\n",
      "   2.4220605e+00  2.3582783e+00  1.0868179e+00  3.7703678e-01\n",
      "   1.7508847e+00  1.7604538e+00  1.6478775e+00  1.5902513e+00\n",
      "   4.4810605e+00 -2.3115485e+00 -1.8702023e+00 -1.3826319e+00\n",
      "  -2.7199798e+00 -1.0000000e+03 -1.0000000e+03]\n",
      " [-7.4049158e+00 -8.2530975e+00 -7.3614740e+00 -8.0078793e+00\n",
      "   7.9667716e+00  6.4721375e+00  6.5454330e+00  4.2240620e+00\n",
      "  -9.3624532e-02  1.9631277e+00  1.2943631e+00 -6.8259127e-02\n",
      "   1.0212331e+01 -3.8713661e-01 -4.8590121e+00 -2.8031471e+00\n",
      "  -2.1014559e+00 -1.0000000e+03 -1.0000000e+03]\n",
      " [-1.0000000e+03 -1.0000000e+03 -1.0000000e+03 -1.0000000e+03\n",
      "  -1.0000000e+03 -1.0000000e+03 -1.0000000e+03 -1.0000000e+03\n",
      "  -1.0000000e+03 -1.0000000e+03 -1.0000000e+03 -1.0000000e+03\n",
      "  -1.0000000e+03 -1.0000000e+03 -1.0000000e+03 -1.0000000e+03\n",
      "  -1.0000000e+03 -1.0000000e+03  0.0000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Ngoc Linh', 'MISC')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ , entitys = model.quick_predict('my name is Ngoc Linh ha Hss Hj')\n",
    "entitys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Ho Chi Minh Vietnamese', 'ORG'),\n",
       "  ('Chu n√¥m', 'MISC'),\n",
       "  ('Nguyen Sinh Cung', 'PER'),\n",
       "  ('Nguyen tat Thanh', 'MISC'),\n",
       "  ('Nguyen Ai Quoc', 'PER'),\n",
       "  ('Vietnamese Communist', 'MISC'),\n",
       "  (\"Workers ' Party of Vietnam\", 'ORG'),\n",
       "  ('Democratic Republic of Vietnam', 'ORG'),\n",
       "  ('North Vietnam', 'LOC'),\n",
       "  ('Democratic Republic of Vietnam', 'ORG'),\n",
       "  (\"People 's Army of Vietnam\", 'ORG'),\n",
       "  ('PAVN', 'ORG'),\n",
       "  ('NLF', 'ORG'),\n",
       "  ('Vietnam War', 'MISC'),\n",
       "  ('Ho Chi Minh', 'PER'),\n",
       "  ('Viet Minh', 'ORG'),\n",
       "  ('Communist', 'MISC'),\n",
       "  ('Democratic Republic of Vietnam', 'ORG'),\n",
       "  ('French Union', 'ORG'),\n",
       "  ('Dien Bien Phu', 'LOC'),\n",
       "  ('Saigon', 'PER'),\n",
       "  ('Republic of Vietnam', 'LOC'),\n",
       "  ('Ho Chi Minh City', 'ORG'),\n",
       "  ('Ho', 'ORG'),\n",
       "  ('Vietnam', 'LOC')],\n",
       " [['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-MISC',\n",
       "   'I-MISC',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-PER',\n",
       "   'I-PER',\n",
       "   'I-PER',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-MISC',\n",
       "   'I-MISC',\n",
       "   'I-MISC',\n",
       "   'O',\n",
       "   'B-PER',\n",
       "   'I-PER',\n",
       "   'I-PER',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-MISC',\n",
       "   'I-MISC',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O'],\n",
       "  ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'B-LOC',\n",
       "   'I-LOC',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-MISC',\n",
       "   'I-MISC',\n",
       "   'O'],\n",
       "  ['B-PER',\n",
       "   'I-PER',\n",
       "   'I-PER',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-MISC',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-LOC',\n",
       "   'I-LOC',\n",
       "   'I-LOC',\n",
       "   'O'],\n",
       "  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-PER',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-LOC',\n",
       "   'I-LOC',\n",
       "   'I-LOC',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O'],\n",
       "  ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-LOC',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['O', 'O', 'O', 'O', 'O', 'O', 'O']])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "text_filepath = '../data/test/bac_ho.txt'\n",
    "with codecs.open(text_filepath, 'r', 'UTF-8') as f:\n",
    "    text = f.read()\n",
    "a,entitys = model.quick_predict(text)\n",
    "entitys,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1=[1,2,3,4,2,3,4]\n",
    "y2=[2,1,3,3,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62, 0.57, 0.56, 7.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[float(t) for t in [t for t in metrics.classification_report(y1,y2).split('\\n')[-2].split(' ') if len(t)>0][-4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float('1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
