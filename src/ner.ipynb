{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import ner\n",
    "import os\n",
    "path_model = '../model/en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_characters: Tensor(\"character_embedding/embedded_characters:0\", shape=(?, ?, 25), dtype=float32)\n",
      "embedded_tokens: Tensor(\"token_embedding/embedding_lookup:0\", shape=(?, 100), dtype=float32)\n",
      "token_lstm_input: Tensor(\"concatenate_token_and_character_vectors/token_lstm_input:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop: Tensor(\"dropout/token_lstm_input_drop/mul:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop_expanded: Tensor(\"dropout/token_lstm_input_drop_expanded:0\", shape=(1, ?, 163), dtype=float32)\n",
      "unary_scores_expanded: Tensor(\"crf/unary_scores_expanded:0\", shape=(1, ?, 19), dtype=float32)\n",
      "input_label_indices_flat_batch: Tensor(\"crf/input_label_indices_flat_batch:0\", shape=(1, ?), dtype=int32)\n",
      "sequence_lengths: Tensor(\"crf/sequence_lengths:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (0.15 seconds)\n",
      "number_of_token_original_case_found: 14618\n",
      "number_of_token_lowercase_found: 11723\n",
      "number_of_token_digits_replaced_with_zeros_found: 119\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 16\n",
      "number_of_loaded_word_vectors: 26476\n",
      "dataset.vocabulary_size: 28984\n",
      "INFO:tensorflow:Restoring parameters from ../model/en\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = ner.restore_model_trained(model_folder = path_model,\n",
    "                                        embedding_filepath='../../../ML_EntityData/embedding/en/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'pretrained_model_folder':'../model', \n",
    "#                       'dataset_text_folder':'../../../ML_EntityData/data/en', \n",
    "                      'character_embedding_dimension':25, \n",
    "                      'character_lstm_hidden_state_dimension':25, \n",
    "                      'check_for_digits_replaced_with_zeros':True, \n",
    "                      'check_for_lowercase':True, \n",
    "                      'debug':False,\n",
    "                      'dropout_rate':0.5,\n",
    "                      'experiment_name':'test',\n",
    "                      'freeze_token_embeddings':False,\n",
    "                      'gradient_clipping_value':5.0,\n",
    "                      'learning_rate':0.005,\n",
    "                      'load_only_pretrained_token_embeddings':False,\n",
    "                      'load_all_pretrained_token_embeddings':False,\n",
    "#                       'main_evaluation_mode':'conll',\n",
    "                      'maximum_number_of_epochs':500,\n",
    "#                       'number_of_cpu_threads':8,\n",
    "#                       'number_of_gpus':0,\n",
    "                      'optimizer':'sgd',\n",
    "                      'output_folder':'../../../ML_EntityData/output',\n",
    "                      'patience':10,\n",
    "#                       'plot_format':'pdf',\n",
    "#                       'reload_character_embeddings':True,\n",
    "#                       'reload_character_lstm':True,\n",
    "#                       'reload_crf':True,\n",
    "#                       'reload_feedforward':True,\n",
    "#                       'reload_token_embeddings':True,\n",
    "#                       'reload_token_lstm':True,\n",
    "#                       'remap_unknown_tokens_to_unk':True,\n",
    "#                       'spacylanguage':'en',\n",
    "#                       'tagging_format':'bioes',\n",
    "                      'token_embedding_dimension':100,\n",
    "                      'token_lstm_hidden_state_dimension':100,\n",
    "                      'token_pretrained_embedding_filepath':'../../../ML_EntityData/embedding/en/glove.6B.100d.txt',\n",
    "#                       'tokenizer':'spacy',\n",
    "                      'train_model':True,\n",
    "#                       'use_character_lstm':True,\n",
    "#                       'use_crf':True,\n",
    "#                       'use_pretrained_model':False,\n",
    "                      'verbose':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils_nlp\n",
    "import pickle\n",
    "# dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters)\n",
    "# dataset = ds.DatasetP(verbose=False, debug=False)\n",
    "token_to_vector = utils_nlp.load_pretrained_token_embeddings(parameters['token_pretrained_embedding_filepath'])\n",
    "dataset = pickle.load(open('../model/en/dataset.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_characters: Tensor(\"character_embedding/embedded_characters:0\", shape=(?, ?, 25), dtype=float32)\n",
      "embedded_tokens: Tensor(\"token_embedding/embedding_lookup:0\", shape=(?, 100), dtype=float32)\n",
      "token_lstm_input: Tensor(\"concatenate_token_and_character_vectors/token_lstm_input:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop: Tensor(\"dropout/token_lstm_input_drop/mul:0\", shape=(?, 163), dtype=float32)\n",
      "token_lstm_input_drop_expanded: Tensor(\"dropout/token_lstm_input_drop_expanded:0\", shape=(1, ?, 163), dtype=float32)\n",
      "unary_scores_expanded: Tensor(\"crf/unary_scores_expanded:0\", shape=(1, ?, 19), dtype=float32)\n",
      "input_label_indices_flat_batch: Tensor(\"crf/input_label_indices_flat_batch:0\", shape=(1, ?), dtype=int32)\n",
      "sequence_lengths: Tensor(\"crf/sequence_lengths:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (0.15 seconds)\n",
      "number_of_token_original_case_found: 14618\n",
      "number_of_token_lowercase_found: 11723\n",
      "number_of_token_digits_replaced_with_zeros_found: 119\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 16\n",
      "number_of_loaded_word_vectors: 26476\n",
      "dataset.vocabulary_size: 28984\n"
     ]
    }
   ],
   "source": [
    "ner = NER(parameters,dataset,token_to_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/en/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "ner.restore_model_trained(model_pathfile=('../model/en/model.ckpt'),\n",
    "                                        dataset_pathfile=('../model/en/dataset.pickle'),\n",
    "                                        embedding_filepath= parameters['token_pretrained_embedding_filepath'],\n",
    "                                        character_dimension = parameters['character_embedding_dimension'],\n",
    "                                        token_dimension=parameters['token_embedding_dimension'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 0\n",
      "Training completed in 0.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9965    0.9972    0.9968      7140\n",
      "     B-MISC     0.9985    0.9933    0.9959      3438\n",
      "      B-ORG     0.9945    0.9970    0.9957      6321\n",
      "      B-PER     0.9982    0.9967    0.9974      6600\n",
      "      I-LOC     0.9983    0.9983    0.9983      1157\n",
      "     I-MISC     0.9965    0.9974    0.9970      1155\n",
      "      I-ORG     0.9997    0.9968    0.9982      3704\n",
      "      I-PER     0.9989    0.9996    0.9992      4528\n",
      "          O     0.0000    0.0000    0.0000        30\n",
      "\n",
      "avg / total     0.9965    0.9961    0.9963     34073\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9659    0.9717    0.9688      1837\n",
      "     B-MISC     0.9283    0.8850    0.9062       922\n",
      "      B-ORG     0.9313    0.9299    0.9306      1341\n",
      "      B-PER     0.9620    0.9767    0.9693      1842\n",
      "      I-LOC     0.9237    0.8949    0.9091       257\n",
      "     I-MISC     0.8746    0.7861    0.8280       346\n",
      "      I-ORG     0.9161    0.9015    0.9087       751\n",
      "      I-PER     0.9852    0.9709    0.9780      1307\n",
      "          O     0.0000    0.0000    0.0000        86\n",
      "\n",
      "avg / total     0.9399    0.9316    0.9356      8689\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9173    0.9376    0.9274      1668\n",
      "     B-MISC     0.8277    0.8077    0.8176       702\n",
      "      B-ORG     0.8909    0.8898    0.8904      1661\n",
      "      B-PER     0.9609    0.9579    0.9594      1617\n",
      "      I-LOC     0.7751    0.8716    0.8205       257\n",
      "     I-MISC     0.6579    0.6944    0.6757       216\n",
      "      I-ORG     0.8335    0.8575    0.8453       835\n",
      "      I-PER     0.9770    0.9913    0.9841      1156\n",
      "          O     0.0000    0.0000    0.0000       287\n",
      "\n",
      "avg / total     0.8705    0.8803    0.8753      8399\n",
      "\n",
      "\n",
      "Starting epoch 1\n",
      "Training completed in 288.16 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9962    0.9979    0.9971      7140\n",
      "     B-MISC     0.9988    0.9945    0.9966      3438\n",
      "      B-ORG     0.9968    0.9954    0.9961      6321\n",
      "      B-PER     0.9947    0.9977    0.9962      6600\n",
      "      I-LOC     0.9991    0.9991    0.9991      1157\n",
      "     I-MISC     0.9965    0.9991    0.9978      1155\n",
      "      I-ORG     0.9978    0.9976    0.9977      3704\n",
      "      I-PER     0.9985    0.9996    0.9990      4528\n",
      "          O     0.0000    0.0000    0.0000        49\n",
      "\n",
      "avg / total     0.9955    0.9959    0.9957     34092\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9597    0.9733    0.9665      1837\n",
      "     B-MISC     0.9274    0.8872    0.9069       922\n",
      "      B-ORG     0.9341    0.9299    0.9320      1341\n",
      "      B-PER     0.9683    0.9799    0.9741      1842\n",
      "      I-LOC     0.8966    0.9105    0.9035       257\n",
      "     I-MISC     0.8754    0.7919    0.8316       346\n",
      "      I-ORG     0.9114    0.8908    0.9010       751\n",
      "      I-PER     0.9816    0.9793    0.9805      1307\n",
      "          O     0.0000    0.0000    0.0000        96\n",
      "\n",
      "avg / total     0.9375    0.9329    0.9350      8699\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9130    0.9371    0.9249      1668\n",
      "     B-MISC     0.8265    0.8077    0.8170       702\n",
      "      B-ORG     0.8860    0.8934    0.8897      1661\n",
      "      B-PER     0.9662    0.9542    0.9602      1617\n",
      "      I-LOC     0.7651    0.8872    0.8216       257\n",
      "     I-MISC     0.6580    0.7037    0.6801       216\n",
      "      I-ORG     0.8180    0.8611    0.8390       835\n",
      "      I-PER     0.9771    0.9948    0.9859      1156\n",
      "          O     0.0000    0.0000    0.0000       323\n",
      "\n",
      "avg / total     0.8640    0.8780    0.8708      8435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ner.train(1,'../../../ML_EntityData/output/en/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jon Jgo Linh', 'PER')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ , entitys = model.quick_predict('my name is Jon Jgo Linh.')\n",
    "entitys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Birth', 'PER'),\n",
       " ('Sex Male Address', 'ORG'),\n",
       " ('Thai Hoc Street', 'LOC'),\n",
       " ('Ba Dinh', 'LOC'),\n",
       " ('Hanoi', 'LOC'),\n",
       " ('iOS Developer', 'ORG'),\n",
       " ('iOS', 'LOC'),\n",
       " ('watchOS', 'LOC'),\n",
       " ('OS X & tvOS', 'ORG'),\n",
       " ('Swift', 'MISC'),\n",
       " ('iOS', 'MISC'),\n",
       " ('ITSOL JSC', 'ORG'),\n",
       " ('Emotiv', 'LOC'),\n",
       " ('Silicon Valley', 'LOC'),\n",
       " ('iOS', 'ORG'),\n",
       " ('Metal Commands', 'ORG'),\n",
       " ('SDK', 'ORG'),\n",
       " ('Swift', 'MISC'),\n",
       " ('iOS Intern', 'ORG'),\n",
       " ('FPT Software', 'ORG'),\n",
       " ('Vietnam', 'LOC'),\n",
       " ('Core', 'ORG'),\n",
       " ('Swift', 'PER'),\n",
       " ('Event Organizer', 'PER'),\n",
       " ('CSSA', 'ORG'),\n",
       " ('iOS', 'MISC'),\n",
       " ('Techmaster', 'ORG'),\n",
       " ('iOS', 'ORG'),\n",
       " ('iOS', 'MISC'),\n",
       " ('Techmaster Vietnam', 'LOC'),\n",
       " ('Vietnam', 'LOC'),\n",
       " ('Trinh Minh Cuong', 'PER'),\n",
       " ('Swift', 'MISC'),\n",
       " ('iOS', 'LOC'),\n",
       " ('Projects Freelancer', 'PER'),\n",
       " ('US', 'LOC'),\n",
       " ('Japanese', 'MISC'),\n",
       " ('UI', 'ORG'),\n",
       " ('Presena', 'LOC'),\n",
       " ('Hubnami', 'LOC'),\n",
       " ('WIXI', 'ORG'),\n",
       " ('Skills iOS Development', 'ORG'),\n",
       " ('MVC', 'ORG'),\n",
       " ('MVC', 'ORG'),\n",
       " ('MVC', 'ORG'),\n",
       " ('RS', 'ORG'),\n",
       " ('MVVM', 'ORG'),\n",
       " ('Singleton', 'ORG'),\n",
       " ('Pool', 'ORG'),\n",
       " ('Memento', 'ORG'),\n",
       " ('SOLID', 'ORG'),\n",
       " ('DRY', 'ORG'),\n",
       " ('Debugging', 'LOC'),\n",
       " ('Optimization', 'LOC'),\n",
       " ('Instrumenting', 'LOC'),\n",
       " ('Unit Testing', 'ORG'),\n",
       " ('CI', 'ORG'),\n",
       " ('CoreData', 'LOC'),\n",
       " ('SQLite', 'LOC'),\n",
       " ('Realm', 'LOC'),\n",
       " ('Cocoa', 'LOC'),\n",
       " ('UIKit', 'ORG'),\n",
       " ('AutoLayout', 'LOC'),\n",
       " ('Storyboards', 'LOC'),\n",
       " ('CoreServices', 'LOC'),\n",
       " ('API', 'ORG'),\n",
       " ('OAuth2.0', 'ORG'),\n",
       " ('JSON', 'LOC'),\n",
       " ('XML', 'LOC'),\n",
       " ('HMTL', 'LOC'),\n",
       " ('Delegation', 'LOC'),\n",
       " ('Protocol', 'ORG'),\n",
       " ('Functional Programming', 'PER'),\n",
       " ('React', 'LOC'),\n",
       " ('Cocoapods', 'LOC'),\n",
       " ('Carthage', 'LOC'),\n",
       " ('Alamofire', 'PER'),\n",
       " ('SwiftyJSON', 'LOC'),\n",
       " ('KeychainAcess', 'LOC'),\n",
       " ('LockSmith', 'LOC'),\n",
       " ('Charts', 'LOC'),\n",
       " ('FBSDK', 'LOC'),\n",
       " ('Google API', 'ORG'),\n",
       " ('AppStore', 'MISC'),\n",
       " ('Tools Postman', 'PER'),\n",
       " ('Google Chrome', 'PER'),\n",
       " ('HTTP', 'ORG'),\n",
       " ('Balsamiq', 'LOC'),\n",
       " ('Sketch', 'LOC'),\n",
       " ('Ninjamocks', 'LOC'),\n",
       " ('SourceTree', 'LOC'),\n",
       " ('Github', 'LOC'),\n",
       " ('Git', 'MISC'),\n",
       " ('NewRelic', 'LOC'),\n",
       " ('Fabric', 'LOC'),\n",
       " ('Sentry', 'LOC'),\n",
       " ('Slack', 'LOC'),\n",
       " ('Trello', 'LOC'),\n",
       " ('Moxtra', 'LOC'),\n",
       " ('Asana', 'LOC'),\n",
       " ('PivotalTracker', 'MISC'),\n",
       " ('English', 'MISC'),\n",
       " ('English', 'MISC'),\n",
       " ('Vietnamese', 'MISC'),\n",
       " ('Vietnam', 'LOC'),\n",
       " ('iOS Developer', 'ORG'),\n",
       " ('Hanoi University of Science and Technology', 'ORG'),\n",
       " ('Electronics and Telecommunications', 'ORG')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "text_filepath = '../data/test/cv.txt'\n",
    "with codecs.open(text_filepath, 'r', 'UTF-8') as f:\n",
    "    text = f.read()\n",
    "_,entitys = model.quick_predict(text)\n",
    "entitys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1=[1,2,3,4,2,3,4]\n",
    "y2=[2,1,3,3,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62, 0.57, 0.56, 7.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[float(t) for t in [t for t in metrics.classification_report(y1,y2).split('\\n')[-2].split(' ') if len(t)>0][-4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float('1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
